{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BnlLdtj3lHBl"
   },
   "source": [
    "Download database if database does not exist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "![ ! -d \"physionet.org\" ] && wget -r -N -c -np -q https://physionet.org/files/slpdb/1.0.0/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bn4kzr6KmE6B"
   },
   "source": [
    "Download libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BtOCDXRemGNN",
    "outputId": "3bef8850-c9d9-4779-d9d8-a2948f9e65bb",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Ignoring invalid distribution -atplotlib (/usr/local/lib/python3.9/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -atplotlib (/usr/local/lib/python3.9/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -atplotlib (/usr/local/lib/python3.9/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -atplotlib (/usr/local/lib/python3.9/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -atplotlib (/usr/local/lib/python3.9/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -atplotlib (/usr/local/lib/python3.9/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: You are using pip version 22.0.3; however, version 22.0.4 is available.\n",
      "You should consider upgrading via the '/usr/local/opt/python@3.9/bin/python3.9 -m pip install --upgrade pip' command.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -atplotlib (/usr/local/lib/python3.9/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -atplotlib (/usr/local/lib/python3.9/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: matplotlib==3.1.3 in /usr/local/lib/python3.9/site-packages (3.1.3)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.9/site-packages (from matplotlib==3.1.3) (2.8.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.9/site-packages (from matplotlib==3.1.3) (0.10.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.9/site-packages (from matplotlib==3.1.3) (1.3.1)\n",
      "Requirement already satisfied: numpy>=1.11 in /usr/local/lib/python3.9/site-packages (from matplotlib==3.1.3) (1.19.4)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.9/site-packages (from matplotlib==3.1.3) (2.4.7)\n",
      "Requirement already satisfied: six in /Users/hoseoklee/Library/Python/3.9/lib/python/site-packages (from cycler>=0.10->matplotlib==3.1.3) (1.15.0)\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -atplotlib (/usr/local/lib/python3.9/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -atplotlib (/usr/local/lib/python3.9/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -atplotlib (/usr/local/lib/python3.9/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -atplotlib (/usr/local/lib/python3.9/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: You are using pip version 22.0.3; however, version 22.0.4 is available.\n",
      "You should consider upgrading via the '/usr/local/opt/python@3.9/bin/python3.9 -m pip install --upgrade pip' command.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install -q wfdb tinymlgen --user\n",
    "!{sys.executable} -m pip install matplotlib==3.1.3 --user"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XTUxPlAylstP"
   },
   "source": [
    "Import libraries and set random seed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 475,
   "metadata": {
    "id": "lZt8rqnwluy1"
   },
   "outputs": [],
   "source": [
    "# For reading database\n",
    "import wfdb\n",
    "import os\n",
    "import copy\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import models, layers\n",
    "from tensorflow.keras import utils\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa\n",
    "import librosa.display\n",
    "\n",
    "np.random.seed(1)\n",
    "tf.random.set_seed(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CP7JEBwSmfCj"
   },
   "source": [
    "## **1. Import Database**\n",
    "Accessing data and basic data processing.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "uBcKJYsz5jo5"
   },
   "outputs": [],
   "source": [
    "class PatientData (object):\n",
    "    ECG_signal = None\n",
    "    EEG_signal = None\n",
    "    sleep_stages = None\n",
    "\n",
    "    record_length = None\n",
    "    sampling_frequency = None\n",
    "\n",
    "    def __init__ (self, patient_name):\n",
    "        self.patient_name = patient_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "acnTzNBz3co0"
   },
   "outputs": [],
   "source": [
    "DATABASE_PATH = 'physionet.org/files/slpdb/1.0.0'\n",
    "\n",
    "with open(os.path.join(DATABASE_PATH, 'RECORDS'), 'r') as file:\n",
    "    PATIENT_NAMES = file.read().split('\\n')[:-1]\n",
    "  \n",
    "PATIENTS = {\n",
    "    patient_name: PatientData(patient_name)\n",
    "    for patient_name in PATIENT_NAMES\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "q4tscNYw7RCf"
   },
   "outputs": [],
   "source": [
    "# 0 Awake\n",
    "# 1 NREM stage 1\n",
    "# 2 NREM stage 2\n",
    "# 3 NREM stage 3 and 4\n",
    "# 4 REM\n",
    "def annotation_sleep_stage (annotation):\n",
    "    if annotation.startswith('W'):\n",
    "        return 0\n",
    "    elif annotation.startswith('1'):\n",
    "        return 1\n",
    "    elif annotation.startswith('2'):\n",
    "        return 2\n",
    "    elif annotation.startswith('3') or annotation.startswith('4'):\n",
    "        return 3\n",
    "    elif annotation.startswith('R'):\n",
    "        return 4\n",
    "    # Ideally, all annotations are classified into one of the above 5\n",
    "    else:\n",
    "        return -1\n",
    "\n",
    "# Since annotations only have labels and the time at which they occur,\n",
    "# interpolate all the data so there's always a label at each time step\n",
    "def step_interpolation (data, locations, total_length):\n",
    "    step_interpolated_data = np.zeros(total_length)\n",
    "\n",
    "    for i in range(len(locations) - 1):\n",
    "        start_range = locations[i]\n",
    "        end_range = locations[i + 1]\n",
    "\n",
    "        # Convert string annotation into sleep stage\n",
    "        step_interpolated_data[(start_range - 1) : end_range] = annotation_sleep_stage(data[i])\n",
    "\n",
    "    return step_interpolated_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "x15jx_LYmmA6"
   },
   "outputs": [],
   "source": [
    "for patient_name in PATIENT_NAMES:\n",
    "    patient = PATIENTS[patient_name]\n",
    "\n",
    "    # Retrieve raw signals and annotations\n",
    "    record_path = os.path.join(DATABASE_PATH, patient_name)\n",
    "    record = wfdb.io.rdrecord(record_path)\n",
    "    annotation = wfdb.rdann(record_path, extension='st')\n",
    "\n",
    "    # Sampling frequency\n",
    "    # This might differ for each record\n",
    "    patient.sampling_frequency = record.fs\n",
    "\n",
    "    # 0 ECG\n",
    "    # 1 BP\n",
    "    # 2 EEG\n",
    "    # 3 Resp (not available for all)\n",
    "    patient.ECG_signal = record.p_signal[:, 0]\n",
    "    patient.EEG_signal = record.p_signal[:, 2]\n",
    "    patient.record_length = record.sig_len\n",
    "\n",
    "    patient.sleep_stages = step_interpolation(annotation.aux_note, annotation.sample, patient.record_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DUsBEQGz7wL5",
    "outputId": "b45f5740-7388-456e-ff70-778b5f800c16"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.085 0.08  0.125 ... 0.23  0.235 0.225]\n",
      "[-0.03919129 -0.03888025 -0.03856921 ...  0.14727838  0.14681182\n",
      "  0.14261275]\n",
      "[3. 3. 3. ... 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "# Example patient\n",
    "patient_slp01a = PATIENTS['slp01a']\n",
    "print(patient_slp01a.ECG_signal)\n",
    "print(patient_slp01a.EEG_signal)\n",
    "print(patient_slp01a.sleep_stages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "G2eqrZjt0K4Z"
   },
   "outputs": [],
   "source": [
    "# Splitting the dataset into train, validation, test set\n",
    "# Will be split in terms of patients, not sleep data\n",
    "num_patients = len(PATIENTS)\n",
    "\n",
    "# Shuffle patients\n",
    "randomized_patients = copy.deepcopy(list(PATIENTS.keys()))\n",
    "np.random.shuffle(randomized_patients)\n",
    "\n",
    "# 80 / 10 / 10 split of 18 patients will be roughly 14 / 2 / 2\n",
    "# Don't need test_end, since it'll be until the end of data\n",
    "train_end = 14\n",
    "valid_end = train_end + 2\n",
    "\n",
    "# Split data using keys\n",
    "train_patients = randomized_patients[ : train_end]\n",
    "valid_patients = randomized_patients[train_end : valid_end]\n",
    "test_patients = randomized_patients[valid_end : ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EYu2d3lFn33a"
   },
   "source": [
    "## **2. Building the Neural Network**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 499,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "D--JGvLr1E9b",
    "outputId": "b3cc854c-c876-4776-b148-750889344129"
   },
   "outputs": [],
   "source": [
    "def create_dataset(patient_set, window_size=15, batch_size=10, diagnostic=False):\n",
    "    inputs = []\n",
    "    labels = []\n",
    "    \n",
    "    i = 0\n",
    "    for patient_name in patient_set:\n",
    "        patient = PATIENTS[patient_name]\n",
    "        total_samples = patient.EEG_signal.shape[0]\n",
    "\n",
    "        # Represents the number of samples (individual numbers) in one window of time (measured in seconds)\n",
    "        samples_per_window = int(window_size * patient.sampling_frequency)\n",
    "        \n",
    "        # Represents how many data points is generated after division with windows\n",
    "        # If the window size is larger, there will be less data points (but more samples per data point)\n",
    "        windows = np.round(total_samples / samples_per_window).astype(np.int64)\n",
    "        \n",
    "        # Calculate the number of batches, dependent on the number of data points and batch size\n",
    "        batches = np.ceil(windows / batch_size).astype(np.int64)\n",
    "        \n",
    "        \n",
    "        \n",
    "        if diagnostic:\n",
    "            print(\"Gathering {} patient data...\".format(patient_name))\n",
    "            print(\"> Total number of samples = {}\".format(total_samples))\n",
    "            print(\"  Samples per window size of {} seconds = {}\".format(window_size, samples_per_window))\n",
    "            print(\"  Number of windows = {}\".format(windows))\n",
    "            print(\"  Number of batches for batch size {} = {}\".format(batch_size, batches))\n",
    "\n",
    "            \n",
    "            \n",
    "        for datum in range(windows):\n",
    "            '''\n",
    "            current_batch_inputs = []\n",
    "            current_batch_labels = []\n",
    "            \n",
    "            for datum in range(batch_size):\n",
    "            '''\n",
    "            # Determine start and end of current batch\n",
    "            # Function assumes that batch sizes match the number of samples perfectly\n",
    "            start = (datum * samples_per_window)\n",
    "            end = (start + samples_per_window)\n",
    "\n",
    "            '''\n",
    "            EEG_MFCC = librosa.feature.melspectrogram(\n",
    "                y=patient.EEG_signal[start : end], \n",
    "                sr=patient.sampling_frequency)\n",
    "            ECG_MFCC = librosa.feature.melspectrogram(\n",
    "                y=patient.ECG_signal[start : end], \n",
    "                sr=patient.sampling_frequency)\n",
    "\n",
    "            sample = np.expand_dims(\n",
    "                np.stack([ EEG_MFCC, ECG_MFCC ], axis=2), \n",
    "                axis=0)\n",
    "            '''\n",
    "\n",
    "            sample = [\n",
    "                patient.EEG_signal[start : end],\n",
    "                patient.ECG_signal[start : end]\n",
    "            ]\n",
    "\n",
    "            # Only grab the label at the end of the current batch\n",
    "            # This is such that we're using all of the data in the current batch\n",
    "            # in order to predict the sleep stage by the end of the batch\n",
    "            sample_labels = patient.sleep_stages[end - 1]\n",
    "            '''\n",
    "                current_batch_inputs.append(sample)\n",
    "                current_batch_labels.append(sample_labels)\n",
    "            '''\n",
    "            inputs.append(sample)\n",
    "            labels.append(sample_labels)\n",
    "            \n",
    "        i += 1\n",
    "        if i == 6:\n",
    "            #break\n",
    "            pass\n",
    "\n",
    "    return np.expand_dims(np.array(inputs), axis=-1), np.expand_dims(np.array(labels), axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 500,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Create training and validationdataset\n",
    "train_data, train_labels = create_dataset(train_patients, diagnostic=False)\n",
    "valid_data, valid_labels = create_dataset(train_patients, diagnostic=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 501,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14788, 2, 3750, 1)\n",
      "(14788, 1)\n"
     ]
    }
   ],
   "source": [
    "print(train_data.shape)\n",
    "print(train_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 502,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.00451128 -0.00032223  0.00440387 ...  0.00622986  0.00708915\n",
      "  0.00816327]\n"
     ]
    }
   ],
   "source": [
    "print(train_data[0][0].squeeze())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 503,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.23491255e-05 1.98725237e-05 2.21443075e-05 1.44586918e-05\n",
      " 3.21054769e-06 3.45698864e-06 3.21245844e-06 4.32837294e-06\n",
      " 3.99676860e-06 2.84017592e-06 2.91300789e-06 2.06101717e-06\n",
      " 2.65155779e-06 4.20651795e-06 1.69255641e-06]\n"
     ]
    }
   ],
   "source": [
    "x = train_data[0][0].squeeze()\n",
    "sf = 250\n",
    "\n",
    "low, high = 0.5, 4\n",
    "\n",
    "freqs, psd = sp.signal.welch(x, sf, nperseg=(4 * sf))\n",
    "delta = psd[np.logical_and(freqs >= low, freqs <= high)]\n",
    "print(delta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 504,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inception layer\n",
    "# Two 1D convolution layers in parallel concatenate at the end\n",
    "# Left and right filter amounts can be modified\n",
    "class Inception1D (layers.Layer):\n",
    "\n",
    "    def __init__ (self, left_filter, right_filter):\n",
    "        super(Inception1D, self).__init__()\n",
    "\n",
    "        # Left-side convolution\n",
    "        self.left_conv = layers.Conv1D(\n",
    "            filters=left_filter, \n",
    "            kernel_size=1,\n",
    "            padding='same',\n",
    "            activation='relu')\n",
    "\n",
    "        # Right-side convolution\n",
    "        self.right_conv = layers.Conv1D(\n",
    "            filters=right_filter, \n",
    "            kernel_size=3,\n",
    "            padding='same',\n",
    "            activation='relu')\n",
    "\n",
    "    def call (self, inputs, training=False):\n",
    "        left = self.left_conv(inputs)\n",
    "        right = self.right_conv(inputs)\n",
    "        x = layers.Concatenate()([left, right])\n",
    "        x = layers.MaxPool1D(pool_size=2)(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 505,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yo5vb_3VJXKC",
    "outputId": "31a97c49-f62c-47b2-b045-5c6be97fe94d"
   },
   "outputs": [],
   "source": [
    "class PCNN (tf.keras.Model):\n",
    "    \n",
    "    def __init__ (self):\n",
    "        super(PCNN, self).__init__()\n",
    "        \n",
    "        self.EEG = [\n",
    "            Inception1D(4, 4), \n",
    "            layers.Dropout(0.5),\n",
    "            Inception1D(8, 8)\n",
    "        ]\n",
    "        \n",
    "        self.rnn = layers.LSTM(16)\n",
    "        \n",
    "        self.ANN = [\n",
    "            layers.Dense(32, activation='relu'),\n",
    "            layers.Dense(16, activation='relu'),\n",
    "            layers.Dense(5, activation='softmax')\n",
    "        ]\n",
    "    \n",
    "    def call (self, inputs, training=False):\n",
    "        eeg = inputs[:,0]\n",
    "        ecg = inputs[:,1]\n",
    "        \n",
    "        # Parallel convolutional networks\n",
    "        for conv in self.EEG:\n",
    "            eeg = conv(eeg)\n",
    "            ecg = conv(ecg)\n",
    "            \n",
    "        # Concatenate convolutional embedding\n",
    "        # Perform dropouts and batch normalization for ANN classifier\n",
    "        x = layers.Concatenate()([eeg, ecg])\n",
    "        # Only include dropouts during trainning\n",
    "        if training:\n",
    "            x = layers.Dropout(0.5)(x)\n",
    "        # Flatten embedding\n",
    "        x = layers.Flatten()(x)\n",
    "        \n",
    "        # Fully-connected classifier\n",
    "        for layer in self.ANN:\n",
    "            x = layer(x)\n",
    "            \n",
    "        return x\n",
    "        \n",
    "\n",
    "\n",
    "model = PCNN()\n",
    "\n",
    "# Compile the model\n",
    "model.compile(\n",
    "    optimizer = tf.keras.optimizers.Adam(\n",
    "        learning_rate=0.005,\n",
    "        epsilon=1e-7\n",
    "    ),\n",
    "    loss      = tf.keras.losses.CategoricalCrossentropy(),\n",
    "    metrics   = tf.keras.metrics.CategoricalAccuracy()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 506,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "H9Ll4Jj4SEDJ",
    "outputId": "f841a15f-02b0-4c4a-df0d-daf429e10294"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "463/463 [==============================] - 35s 75ms/step - loss: 1.4307 - categorical_accuracy: 0.3516 - val_loss: 1.4087 - val_categorical_accuracy: 0.3405\n",
      "Epoch 2/10\n",
      "463/463 [==============================] - 33s 72ms/step - loss: 1.3831 - categorical_accuracy: 0.3783 - val_loss: 1.5128 - val_categorical_accuracy: 0.3426\n",
      "Epoch 3/10\n",
      "463/463 [==============================] - 33s 72ms/step - loss: 1.3658 - categorical_accuracy: 0.3852 - val_loss: 1.4325 - val_categorical_accuracy: 0.3946\n",
      "Epoch 4/10\n",
      "463/463 [==============================] - 33s 72ms/step - loss: 1.3451 - categorical_accuracy: 0.4051 - val_loss: 1.4109 - val_categorical_accuracy: 0.4118\n",
      "Epoch 5/10\n",
      "463/463 [==============================] - 34s 73ms/step - loss: 1.3215 - categorical_accuracy: 0.4212 - val_loss: 1.3874 - val_categorical_accuracy: 0.4109\n",
      "Epoch 6/10\n",
      "463/463 [==============================] - 33s 72ms/step - loss: 1.2957 - categorical_accuracy: 0.4307 - val_loss: 1.3516 - val_categorical_accuracy: 0.4160\n",
      "Epoch 7/10\n",
      "463/463 [==============================] - 34s 72ms/step - loss: 1.2678 - categorical_accuracy: 0.4416 - val_loss: 1.3628 - val_categorical_accuracy: 0.3979\n",
      "Epoch 8/10\n",
      "463/463 [==============================] - 34s 73ms/step - loss: 1.2406 - categorical_accuracy: 0.4582 - val_loss: 1.3802 - val_categorical_accuracy: 0.4032\n",
      "Epoch 9/10\n",
      "463/463 [==============================] - 34s 73ms/step - loss: 1.2097 - categorical_accuracy: 0.4704 - val_loss: 1.3785 - val_categorical_accuracy: 0.4118\n",
      "Epoch 10/10\n",
      "463/463 [==============================] - 34s 73ms/step - loss: 1.1884 - categorical_accuracy: 0.4833 - val_loss: 1.3398 - val_categorical_accuracy: 0.4149\n"
     ]
    }
   ],
   "source": [
    "# Train the neural network\n",
    "\n",
    "history = model.fit(\n",
    "    x               = train_data,\n",
    "    y               = utils.to_categorical(train_labels),\n",
    "    epochs          = 10,\n",
    "    validation_data = (\n",
    "        valid_data,\n",
    "        utils.to_categorical(valid_labels)\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 507,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 300
    },
    "id": "sTZp9NLH94p1",
    "outputId": "23603d9c-6cb1-4840-8839-5ef177036029"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1918fc5b0>"
      ]
     },
     "execution_count": 507,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Graph training accuracy\n",
    "plt.plot(history.history['categorical_accuracy'], label='Training Accuracy')\n",
    "plt.plot(history.history['val_categorical_accuracy'], label='Validation Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim([0, 1])\n",
    "plt.legend(loc='lower right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {
    "id": "ik3D0W5PSP8v"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "463/463 [==============================] - 11s 24ms/step - loss: 0.0534 - accuracy: 0.9824\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.05341473966836929, 0.9824181795120239]"
      ]
     },
     "execution_count": 331,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get accuracy of the network\n",
    "model.evaluate(valid_data, utils.to_categorical(valid_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kpfOB_6t6B0k"
   },
   "outputs": [],
   "source": [
    "# implementing the class of conv net -- incompleted\n",
    "class CNN_sleep_stages(tf.Module):\n",
    "  def __init__(self, number_of_channels = , number_of_classes =):\n",
    "    self.conv1 = models.Sequential(layers.Conv2D(, (, ), activation='relu', input_shape=(, , )))\n",
    "    self.conv2 = models.Sequential(layers.Conv2D(, (, ), activation='relu'))\n",
    "    self.pool =  models.Sequential(layers.MaxPool2D( 2 , 2 ))\n",
    "    self.flat = models.Sequential(layers.Flatten())\n",
    "    self.dense = models.Sequential(layers.Dense(, activation = 'Sigmoid'))\n",
    "  \n",
    "  def __call__(self, x):\n",
    "    x = self.pool(self.conv1(x))\n",
    "    return x\n",
    "\n",
    "# Could improve the accuracy by:\n",
    "# 1. Increasing the depth (adding more convolutional layer)\n",
    "# 2. Adding dropout layer\n",
    "# 3. Add fully-connected layers\n",
    "# 4. Strides? Padding?"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Rough Implementation",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
