{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BnlLdtj3lHBl"
   },
   "source": [
    "Download database if database does not exist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "![ ! -d \"physionet.org\" ] && wget -r -N -c -np -q https://physionet.org/files/slpdb/1.0.0/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bn4kzr6KmE6B"
   },
   "source": [
    "Download libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BtOCDXRemGNN",
    "outputId": "3bef8850-c9d9-4779-d9d8-a2948f9e65bb",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mDEPRECATION: Configuring installation scheme with distutils config files is deprecated and will no longer work in the near future. If you are using a Homebrew or Linuxbrew Python, please see discussion at https://github.com/Homebrew/homebrew-core/issues/76621\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -atplotlib (/usr/local/lib/python3.9/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -atplotlib (/usr/local/lib/python3.9/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: pip in /usr/local/lib/python3.9/site-packages (22.0.4)\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -atplotlib (/usr/local/lib/python3.9/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mDEPRECATION: Configuring installation scheme with distutils config files is deprecated and will no longer work in the near future. If you are using a Homebrew or Linuxbrew Python, please see discussion at https://github.com/Homebrew/homebrew-core/issues/76621\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -atplotlib (/usr/local/lib/python3.9/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -atplotlib (/usr/local/lib/python3.9/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -atplotlib (/usr/local/lib/python3.9/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -atplotlib (/usr/local/lib/python3.9/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -atplotlib (/usr/local/lib/python3.9/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -atplotlib (/usr/local/lib/python3.9/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -atplotlib (/usr/local/lib/python3.9/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -atplotlib (/usr/local/lib/python3.9/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -atplotlib (/usr/local/lib/python3.9/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -atplotlib (/usr/local/lib/python3.9/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -atplotlib (/usr/local/lib/python3.9/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -atplotlib (/usr/local/lib/python3.9/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install --upgrade pip\n",
    "!{sys.executable} -m pip install -q wfdb tinymlgen --user\n",
    "!{sys.executable} -m pip install -q matplotlib==3.1.3 --user"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XTUxPlAylstP"
   },
   "source": [
    "Import libraries and set random seed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "id": "lZt8rqnwluy1"
   },
   "outputs": [],
   "source": [
    "# For reading database\n",
    "import wfdb\n",
    "import os\n",
    "import copy\n",
    "import pickle\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "from scipy import signal\n",
    "from scipy.integrate import simps\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import models, layers\n",
    "from tensorflow.keras import utils\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "np.random.seed(1)\n",
    "tf.random.set_seed(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CP7JEBwSmfCj"
   },
   "source": [
    "## **1. Import Database**\n",
    "Accessing data and basic data processing.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "uBcKJYsz5jo5"
   },
   "outputs": [],
   "source": [
    "class PatientData (object):\n",
    "    ECG_signal = None\n",
    "    EEG_signal = None\n",
    "    sleep_stages = None\n",
    "\n",
    "    record_length = None\n",
    "    sampling_frequency = None\n",
    "\n",
    "    def __init__ (self, patient_name):\n",
    "        self.patient_name = patient_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "acnTzNBz3co0"
   },
   "outputs": [],
   "source": [
    "DATABASE_PATH = 'physionet.org/files/slpdb/1.0.0'\n",
    "\n",
    "with open(os.path.join(DATABASE_PATH, 'RECORDS'), 'r') as file:\n",
    "    PATIENT_NAMES = file.read().split('\\n')[:-1]\n",
    "  \n",
    "PATIENTS = {\n",
    "    patient_name: PatientData(patient_name)\n",
    "    for patient_name in PATIENT_NAMES\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "q4tscNYw7RCf"
   },
   "outputs": [],
   "source": [
    "# 0 Awake\n",
    "# 1 NREM stage 1\n",
    "# 2 NREM stage 2\n",
    "# 3 NREM stage 3 and 4\n",
    "# 4 REM\n",
    "# 5 Movement time (unknown)\n",
    "\n",
    "SLEEP_STAGES = {\n",
    "    \"W\": 0,\n",
    "    \"1\": 1,\n",
    "    \"2\": 2,\n",
    "    \"3\": 3,\n",
    "    \"4\": 3,\n",
    "    \"R\": 4,\n",
    "    \"M\": 5\n",
    "}\n",
    "\n",
    "NUM_CLASSES = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since annotations only have labels and the time at which they occur,\n",
    "# interpolate all the data so there's always a label at each time step\n",
    "def step_interpolation (data, locations, total_length):\n",
    "    step_interpolated_data = np.zeros(total_length)\n",
    "\n",
    "    for i in range(len(locations) - 1):\n",
    "        start_range = locations[i]\n",
    "        end_range = locations[i + 1]\n",
    "\n",
    "        # Convert string annotation into sleep stage\n",
    "        step_interpolated_data[(start_range - 1) : end_range] = SLEEP_STAGES[data[i][0]]\n",
    "\n",
    "    return step_interpolated_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "x15jx_LYmmA6"
   },
   "outputs": [],
   "source": [
    "for patient_name in PATIENT_NAMES:\n",
    "    patient = PATIENTS[patient_name]\n",
    "\n",
    "    # Retrieve raw signals and annotations\n",
    "    record_path = os.path.join(DATABASE_PATH, patient_name)\n",
    "    record = wfdb.io.rdrecord(record_path)\n",
    "    annotation = wfdb.rdann(record_path, extension='st')\n",
    "\n",
    "    # Sampling frequency\n",
    "    # This might differ for each record\n",
    "    patient.sampling_frequency = record.fs\n",
    "\n",
    "    # 0 ECG\n",
    "    # 1 BP\n",
    "    # 2 EEG\n",
    "    # 3 Resp (not available for all)\n",
    "    patient.ECG_signal = record.p_signal[:, 0]\n",
    "    patient.EEG_signal = record.p_signal[:, 2]\n",
    "    patient.record_length = record.sig_len\n",
    "\n",
    "    patient.sleep_stages = step_interpolation(annotation.aux_note, annotation.sample, patient.record_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DUsBEQGz7wL5",
    "outputId": "b45f5740-7388-456e-ff70-778b5f800c16"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.085 0.08  0.125 ... 0.23  0.235 0.225]\n",
      "[-0.03919129 -0.03888025 -0.03856921 ...  0.14727838  0.14681182\n",
      "  0.14261275]\n",
      "[3. 3. 3. ... 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "# Example patient\n",
    "patient_slp01a = PATIENTS['slp01a']\n",
    "print(patient_slp01a.ECG_signal)\n",
    "print(patient_slp01a.EEG_signal)\n",
    "print(patient_slp01a.sleep_stages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "G2eqrZjt0K4Z"
   },
   "outputs": [],
   "source": [
    "# Splitting the dataset into train, validation, test set\n",
    "# Will be split in terms of patients, not sleep data\n",
    "num_patients = len(PATIENTS)\n",
    "\n",
    "# Shuffle patients\n",
    "randomized_patients = copy.deepcopy(PATIENT_NAMES)\n",
    "np.random.shuffle(randomized_patients)\n",
    "\n",
    "# 80 / 10 / 10 split of 18 patients will be roughly 14 / 2 / 2\n",
    "# Don't need test_end, since it'll be until the end of data\n",
    "train_end = 14\n",
    "valid_end = train_end + 2\n",
    "\n",
    "# Split data using keys\n",
    "train_patients = randomized_patients[ : train_end]\n",
    "train_patients.reverse()\n",
    "valid_patients = randomized_patients[train_end : valid_end]\n",
    "test_patients = randomized_patients[valid_end : ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set patients = ['slp37', 'slp66', 'slp67x', 'slp01a', 'slp41', 'slp01b', 'slp03', 'slp61', 'slp16', 'slp60', 'slp02a', 'slp59', 'slp02b', 'slp14']\n",
      "Validation set patients = ['slp32', 'slp48']\n",
      "Testing set patients = ['slp45', 'slp04']\n"
     ]
    }
   ],
   "source": [
    "print(\"Training set patients = {}\".format(train_patients))\n",
    "print(\"Validation set patients = {}\".format(valid_patients))\n",
    "print(\"Testing set patients = {}\".format(test_patients))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EYu2d3lFn33a"
   },
   "source": [
    "## **2. Building the Neural Network**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "eeg_bandwidths = {\n",
    "    \"delta\": (0.25, 4),\n",
    "    \"theta\": (4, 8),\n",
    "    \"alpha\": (8, 12),\n",
    "    \"sigma\": (12, 16),\n",
    "    \"beta\": (16, 40)\n",
    "}\n",
    "\n",
    "ecg_bandwidths = {\n",
    "    \"ulf\": (0, 0.003),\n",
    "    \"vlf\": (0.003, 0.04),\n",
    "    \"lf\": (0.04, 0.15),\n",
    "    \"hf\": (0.15, 0.4),\n",
    "    \"lf/hf\": (0.4, 1)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "D--JGvLr1E9b",
    "outputId": "b3cc854c-c876-4776-b148-750889344129"
   },
   "outputs": [],
   "source": [
    "def welch_relative_powers (bandwidths, signal, sf, nperseg, lfhf_ratio=False):\n",
    "    # Perform power spectral decomposition with Welch's method\n",
    "    freqs, psd = sp.signal.welch(signal, fs=sf, nperseg=nperseg)\n",
    "\n",
    "    # Frequency resolution\n",
    "    resolution = freqs[1] - freqs[0]\n",
    "\n",
    "    # Relative powers\n",
    "    relative_powers = []\n",
    "\n",
    "    # Calculate the relative powers given the power spectral decomposition\n",
    "    total_power = simps(psd, dx=resolution)\n",
    "    for band, (low, high) in bandwidths.items():\n",
    "        index = np.logical_and(freqs >= low, freqs < high)\n",
    "        power = simps(psd[index], dx=resolution)\n",
    "        rel_power = power / total_power\n",
    "        relative_powers.append(rel_power)\n",
    "        \n",
    "    # This will only be enabled for ECG\n",
    "    # This replaces the last relative power with the LF/HF ratio\n",
    "    if lfhf_ratio:\n",
    "        relative_powers[-1] = relative_powers[2] / relative_powers[3]\n",
    "        \n",
    "    return relative_powers\n",
    "\n",
    "\n",
    "\n",
    "def create_dataset (patient_name, window_size=30, diagnostic=False):\n",
    "    inputs = []\n",
    "    labels = []\n",
    "    \n",
    "    patient = PATIENTS[patient_name]\n",
    "    total_samples = patient.EEG_signal.shape[0]\n",
    "    sampling_frequency = patient.sampling_frequency\n",
    "\n",
    "    # Represents the number of samples (individual numbers) in one window of time (measured in seconds)\n",
    "    samples_per_window = int(window_size * sampling_frequency)\n",
    "\n",
    "    # Represents how many data points is generated after division with windows\n",
    "    # If the window size is larger, there will be less data points (but more samples per data point)\n",
    "    windows = np.round(total_samples / samples_per_window).astype(np.int64)\n",
    "\n",
    "\n",
    "\n",
    "    if diagnostic:\n",
    "        print(\"Gathering {} patient data...\".format(patient_name))\n",
    "        print(\"> Total number of samples = {}\".format(total_samples))\n",
    "        print(\"  Samples per window size of {} seconds = {}\".format(window_size, samples_per_window))\n",
    "        print(\"  Number of windows = {}\".format(windows))\n",
    "        print(\"  Number of batches for batch size {} = {}\".format(batch_size, batches))\n",
    "\n",
    "\n",
    "\n",
    "    for datum in range(windows):\n",
    "        '''\n",
    "        current_batch_inputs = []\n",
    "        current_batch_labels = []\n",
    "\n",
    "        for datum in range(batch_size):\n",
    "        '''\n",
    "        # Determine start and end of current batch\n",
    "        # Function assumes that batch sizes match the number of samples perfectly\n",
    "        start = (datum * samples_per_window)\n",
    "        end = (start + samples_per_window)\n",
    "\n",
    "        '''\n",
    "        EEG_MFCC = librosa.feature.melspectrogram(\n",
    "            y=patient.EEG_signal[start : end], \n",
    "            sr=patient.sampling_frequency)\n",
    "        ECG_MFCC = librosa.feature.melspectrogram(\n",
    "            y=patient.ECG_signal[start : end], \n",
    "            sr=patient.sampling_frequency)\n",
    "\n",
    "        sample = np.expand_dims(\n",
    "            np.stack([ EEG_MFCC, ECG_MFCC ], axis=2), \n",
    "            axis=0)\n",
    "        '''\n",
    "\n",
    "        # ORIGINAL \n",
    "        #EEG = patient.EEG_signal[start : end]\n",
    "        #ECG = patient.ECG_signal[start : end]\n",
    "\n",
    "        eeg = welch_relative_powers(\n",
    "            bandwidths = eeg_bandwidths,\n",
    "            signal     = patient.EEG_signal[start : end],\n",
    "            sf         = sampling_frequency,\n",
    "            nperseg    = samples_per_window\n",
    "        )\n",
    "        \n",
    "        ecg = welch_relative_powers(\n",
    "            bandwidths = ecg_bandwidths,\n",
    "            signal     = patient.ECG_signal[start : end],\n",
    "            sf         = sampling_frequency,\n",
    "            nperseg    = samples_per_window,\n",
    "            lfhf_ratio = True\n",
    "        )\n",
    "\n",
    "        '''\n",
    "        sample = [\n",
    "            patient.EEG_signal[start : end],\n",
    "            patient.ECG_signal[start : end]\n",
    "        ]\n",
    "        '''\n",
    "        sample = eeg + ecg\n",
    "        \n",
    "        # Only grab the label at the end of the current batch\n",
    "        # This is such that we're using all of the data in the current batch\n",
    "        # in order to predict the sleep stage by the end of the batch\n",
    "        sample_labels = patient.sleep_stages[end - 1]\n",
    "        '''\n",
    "            current_batch_inputs.append(sample)\n",
    "            current_batch_labels.append(sample_labels)\n",
    "        '''\n",
    "        inputs.append(sample)\n",
    "        labels.append(sample_labels)\n",
    "\n",
    "    return np.expand_dims(np.array(inputs), axis=(-1, -2)), np.expand_dims(np.array(labels), axis=(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inception layer\n",
    "# Three 1D convolution layers in parallel concatenate at the end\n",
    "# Left and right filter amounts can be modified\n",
    "class Inception1D (layers.Layer):\n",
    "\n",
    "    def __init__ (self, num_filter):\n",
    "        super(Inception1D, self).__init__()\n",
    "        \n",
    "        # Left-side convolution\n",
    "        self.left_conv = layers.Conv2D(\n",
    "            filters=num_filter, \n",
    "            kernel_size=(1, 1),\n",
    "            padding='same',\n",
    "            activation='relu'\n",
    "        )\n",
    "        \n",
    "        # Right convolution\n",
    "        self.right_conv = tf.keras.Sequential([\n",
    "            layers.Conv2D(\n",
    "                filters=num_filter,\n",
    "                kernel_size=(1, 1),\n",
    "                padding='same',\n",
    "                activation='relu'\n",
    "            ),\n",
    "            layers.Conv2D(\n",
    "                filters=num_filter,\n",
    "                kernel_size=(3, 1),\n",
    "                padding='same',\n",
    "                activation='relu'\n",
    "            )\n",
    "        ])\n",
    "        \n",
    "        # Pooling\n",
    "        self.pool = tf.keras.Sequential([\n",
    "            layers.MaxPooling2D(\n",
    "                pool_size=(2, 1),\n",
    "                strides=1,\n",
    "                padding='same'\n",
    "            ),\n",
    "            layers.Conv2D(\n",
    "                filters=num_filter,\n",
    "                kernel_size=(1, 1),\n",
    "                padding='same',\n",
    "                activation='relu'\n",
    "            )\n",
    "        ])\n",
    "        \n",
    "        \n",
    "        \n",
    "    def call (self, inputs, training=False):\n",
    "        left = self.left_conv(inputs)\n",
    "        right = self.right_conv(inputs)\n",
    "        pool = self.pool(inputs)\n",
    "        \n",
    "        x = layers.Concatenate()([left, right, pool])\n",
    "        if training:\n",
    "            x = layers.SpatialDropout2D(0.1)(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yo5vb_3VJXKC",
    "outputId": "31a97c49-f62c-47b2-b045-5c6be97fe94d"
   },
   "outputs": [],
   "source": [
    "class PCNN (tf.keras.Model):\n",
    "    \n",
    "    def __init__ (self):\n",
    "        super(PCNN, self).__init__()\n",
    "        \n",
    "        \n",
    "        \n",
    "    def build (self, input_shape):\n",
    "        self.base_cnn = tf.keras.Sequential([\n",
    "            Inception1D(32),\n",
    "            Inception1D(32)\n",
    "        ])\n",
    "        \n",
    "        self.post_cnn = tf.keras.Sequential([\n",
    "            layers.Conv2D(\n",
    "                filters=128,\n",
    "                kernel_size=(3, 1),\n",
    "                padding='same',\n",
    "                activation='relu'\n",
    "            ),\n",
    "            layers.Conv2D(\n",
    "                filters=128,\n",
    "                kernel_size=(3, 1),\n",
    "                padding='same',\n",
    "                activation='relu'\n",
    "            ),\n",
    "            layers.Conv2D(\n",
    "                filters=128,\n",
    "                kernel_size=(3, 1),\n",
    "                padding='same',\n",
    "                activation='relu'\n",
    "            )\n",
    "        ])\n",
    "        \n",
    "        self.ANN = tf.keras.Sequential([\n",
    "            layers.Flatten(),\n",
    "            layers.Dense(64, activation='relu'),\n",
    "            layers.Dense(32, activation='relu'),\n",
    "            layers.Dense(NUM_CLASSES, activation='softmax')\n",
    "        ], name='ann_classifier')\n",
    "        \n",
    "        super(PCNN, self).build(input_shape)\n",
    "    \n",
    "    \n",
    "    \n",
    "    def call (self, inputs, training=False):\n",
    "        eeg = inputs[:,:5]\n",
    "        ecg = inputs[:,5:]\n",
    "        \n",
    "        \n",
    "        # Parallel convolutional networks\n",
    "        eeg = self.base_cnn(eeg)\n",
    "        ecg = self.base_cnn(ecg)\n",
    "        \n",
    "        eeg = self.post_cnn(eeg)\n",
    "        ecg = self.post_cnn(ecg)\n",
    "        \n",
    "        # Concatenate convolutional embedding\n",
    "        x = layers.Concatenate()([ eeg, ecg ])\n",
    "        \n",
    "        # Dropout layers\n",
    "        if training:\n",
    "            x = layers.Dropout(0.5)(x)\n",
    "        \n",
    "        # Fully-connected classifier\n",
    "        x = self.ANN(x)\n",
    "            \n",
    "        return x\n",
    "        \n",
    "\n",
    "\n",
    "model = PCNN()\n",
    "\n",
    "# Compile the model\n",
    "model.compile(\n",
    "    optimizer = tf.keras.optimizers.Adam(0.001),\n",
    "    loss      = tf.keras.losses.CategoricalCrossentropy(),\n",
    "    metrics   = tf.keras.metrics.CategoricalAccuracy()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "H9Ll4Jj4SEDJ",
    "outputId": "f841a15f-02b0-4c4a-df0d-daf429e10294",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training slp37 (0/14)...\n",
      "22/22 [==============================] - 2s 19ms/step - loss: 1.1719 - categorical_accuracy: 0.7786 - val_loss: 2.2191 - val_categorical_accuracy: 0.2484\n",
      "22/22 [==============================] - 1s 39ms/step - loss: 0.6454 - categorical_accuracy: 0.8443 - val_loss: 2.4165 - val_categorical_accuracy: 0.2484\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.5742 - categorical_accuracy: 0.8443 - val_loss: 2.4514 - val_categorical_accuracy: 0.2484\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 0.5667 - categorical_accuracy: 0.8443 - val_loss: 2.2384 - val_categorical_accuracy: 0.2484\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.5435 - categorical_accuracy: 0.8443 - val_loss: 2.1461 - val_categorical_accuracy: 0.2484\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.5322 - categorical_accuracy: 0.8457 - val_loss: 1.8451 - val_categorical_accuracy: 0.6062\n",
      "22/22 [==============================] - 0s 13ms/step - loss: 0.5314 - categorical_accuracy: 0.8500 - val_loss: 1.7343 - val_categorical_accuracy: 0.6219\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.5201 - categorical_accuracy: 0.8529 - val_loss: 1.5990 - val_categorical_accuracy: 0.7031\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.4826 - categorical_accuracy: 0.8643 - val_loss: 1.5979 - val_categorical_accuracy: 0.7469\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 0.4670 - categorical_accuracy: 0.8743 - val_loss: 1.5029 - val_categorical_accuracy: 0.7328\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 0.4687 - categorical_accuracy: 0.8714 - val_loss: 1.6165 - val_categorical_accuracy: 0.7500\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 0.4576 - categorical_accuracy: 0.8700 - val_loss: 1.5200 - val_categorical_accuracy: 0.7672\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 0.4391 - categorical_accuracy: 0.8729 - val_loss: 1.5170 - val_categorical_accuracy: 0.7750\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.4317 - categorical_accuracy: 0.8743 - val_loss: 1.6250 - val_categorical_accuracy: 0.7766\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.4237 - categorical_accuracy: 0.8786 - val_loss: 1.6627 - val_categorical_accuracy: 0.7688\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.4112 - categorical_accuracy: 0.8771 - val_loss: 1.4694 - val_categorical_accuracy: 0.7797\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.4020 - categorical_accuracy: 0.8800 - val_loss: 1.8178 - val_categorical_accuracy: 0.7844\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 0.3889 - categorical_accuracy: 0.8886 - val_loss: 1.4805 - val_categorical_accuracy: 0.7906\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.3796 - categorical_accuracy: 0.8886 - val_loss: 1.6809 - val_categorical_accuracy: 0.7937\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.3672 - categorical_accuracy: 0.8843 - val_loss: 1.6208 - val_categorical_accuracy: 0.7891\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.3899 - categorical_accuracy: 0.8857 - val_loss: 1.7582 - val_categorical_accuracy: 0.7906\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 0.3663 - categorical_accuracy: 0.8914 - val_loss: 1.8269 - val_categorical_accuracy: 0.8016\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 0.3787 - categorical_accuracy: 0.8814 - val_loss: 1.5817 - val_categorical_accuracy: 0.7891\n",
      "22/22 [==============================] - 0s 12ms/step - loss: 0.3779 - categorical_accuracy: 0.8900 - val_loss: 1.7482 - val_categorical_accuracy: 0.7969\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 0.3592 - categorical_accuracy: 0.8843 - val_loss: 1.8963 - val_categorical_accuracy: 0.8031\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 0.3568 - categorical_accuracy: 0.8957 - val_loss: 1.8690 - val_categorical_accuracy: 0.7828\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 0.3528 - categorical_accuracy: 0.9000 - val_loss: 1.6478 - val_categorical_accuracy: 0.7984\n",
      "22/22 [==============================] - 0s 12ms/step - loss: 0.3541 - categorical_accuracy: 0.8957 - val_loss: 1.4081 - val_categorical_accuracy: 0.8062\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.3562 - categorical_accuracy: 0.8929 - val_loss: 2.2876 - val_categorical_accuracy: 0.5984\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.3475 - categorical_accuracy: 0.8957 - val_loss: 1.6940 - val_categorical_accuracy: 0.7844\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 0.3275 - categorical_accuracy: 0.8986 - val_loss: 1.7423 - val_categorical_accuracy: 0.7812\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 0.3288 - categorical_accuracy: 0.9114 - val_loss: 2.0907 - val_categorical_accuracy: 0.6578\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.3205 - categorical_accuracy: 0.8986 - val_loss: 1.6179 - val_categorical_accuracy: 0.8031\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.3259 - categorical_accuracy: 0.9071 - val_loss: 2.0806 - val_categorical_accuracy: 0.7641\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 0.3219 - categorical_accuracy: 0.8929 - val_loss: 1.9820 - val_categorical_accuracy: 0.7016\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 0.3316 - categorical_accuracy: 0.9014 - val_loss: 2.1182 - val_categorical_accuracy: 0.6766\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 0.3094 - categorical_accuracy: 0.9029 - val_loss: 1.6325 - val_categorical_accuracy: 0.7953\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 0.3210 - categorical_accuracy: 0.9043 - val_loss: 1.9841 - val_categorical_accuracy: 0.7125\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 0.2997 - categorical_accuracy: 0.9086 - val_loss: 2.0972 - val_categorical_accuracy: 0.7172\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 0.3124 - categorical_accuracy: 0.9029 - val_loss: 2.1804 - val_categorical_accuracy: 0.7297\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 0.3163 - categorical_accuracy: 0.9029 - val_loss: 2.2472 - val_categorical_accuracy: 0.7250\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 0.2995 - categorical_accuracy: 0.9057 - val_loss: 2.0909 - val_categorical_accuracy: 0.7437\n",
      "22/22 [==============================] - 0s 13ms/step - loss: 0.3221 - categorical_accuracy: 0.8986 - val_loss: 2.2934 - val_categorical_accuracy: 0.6625\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.3034 - categorical_accuracy: 0.9129 - val_loss: 1.9622 - val_categorical_accuracy: 0.7391\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.3044 - categorical_accuracy: 0.9114 - val_loss: 2.2945 - val_categorical_accuracy: 0.6984\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.2962 - categorical_accuracy: 0.9129 - val_loss: 2.2241 - val_categorical_accuracy: 0.6734\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.2859 - categorical_accuracy: 0.9157 - val_loss: 2.5513 - val_categorical_accuracy: 0.5875\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 0.2988 - categorical_accuracy: 0.9029 - val_loss: 2.1549 - val_categorical_accuracy: 0.7109\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.2942 - categorical_accuracy: 0.9143 - val_loss: 2.8793 - val_categorical_accuracy: 0.6203\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 0.2790 - categorical_accuracy: 0.9129 - val_loss: 1.9406 - val_categorical_accuracy: 0.7063\n",
      "Training slp66 (1/14)...\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 1.1724 - categorical_accuracy: 0.5818 - val_loss: 1.2269 - val_categorical_accuracy: 0.6953\n",
      "14/14 [==============================] - 0s 12ms/step - loss: 0.9287 - categorical_accuracy: 0.6045 - val_loss: 1.1546 - val_categorical_accuracy: 0.7156\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 0.8855 - categorical_accuracy: 0.6136 - val_loss: 0.9709 - val_categorical_accuracy: 0.7437\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 0s 12ms/step - loss: 0.8409 - categorical_accuracy: 0.6295 - val_loss: 0.9278 - val_categorical_accuracy: 0.7547\n",
      "14/14 [==============================] - 0s 12ms/step - loss: 0.7967 - categorical_accuracy: 0.6659 - val_loss: 0.9603 - val_categorical_accuracy: 0.7484\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 0.8036 - categorical_accuracy: 0.6591 - val_loss: 0.8785 - val_categorical_accuracy: 0.7531\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 0.7731 - categorical_accuracy: 0.6750 - val_loss: 0.8933 - val_categorical_accuracy: 0.7500\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 0.7710 - categorical_accuracy: 0.6545 - val_loss: 0.8760 - val_categorical_accuracy: 0.7531\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 0.7729 - categorical_accuracy: 0.6523 - val_loss: 0.9286 - val_categorical_accuracy: 0.7391\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 0.7634 - categorical_accuracy: 0.6659 - val_loss: 0.9383 - val_categorical_accuracy: 0.7359\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 0.7379 - categorical_accuracy: 0.6818 - val_loss: 0.8763 - val_categorical_accuracy: 0.7484\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 0.7224 - categorical_accuracy: 0.6795 - val_loss: 0.9170 - val_categorical_accuracy: 0.7344\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 0.7145 - categorical_accuracy: 0.6818 - val_loss: 0.9163 - val_categorical_accuracy: 0.7297\n",
      "14/14 [==============================] - 0s 12ms/step - loss: 0.7312 - categorical_accuracy: 0.6864 - val_loss: 0.8776 - val_categorical_accuracy: 0.7422\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.7042 - categorical_accuracy: 0.6932 - val_loss: 0.9187 - val_categorical_accuracy: 0.7359\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.6974 - categorical_accuracy: 0.7114 - val_loss: 0.9441 - val_categorical_accuracy: 0.7156\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 0.7018 - categorical_accuracy: 0.6614 - val_loss: 0.9238 - val_categorical_accuracy: 0.7203\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 0.7152 - categorical_accuracy: 0.6795 - val_loss: 0.8974 - val_categorical_accuracy: 0.7391\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 0.6831 - categorical_accuracy: 0.7023 - val_loss: 0.9361 - val_categorical_accuracy: 0.7094\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 0.6536 - categorical_accuracy: 0.7045 - val_loss: 1.0318 - val_categorical_accuracy: 0.6906\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 0.7266 - categorical_accuracy: 0.6636 - val_loss: 0.9713 - val_categorical_accuracy: 0.6828\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 0.6951 - categorical_accuracy: 0.6886 - val_loss: 0.9658 - val_categorical_accuracy: 0.7219\n",
      "14/14 [==============================] - 0s 12ms/step - loss: 0.6737 - categorical_accuracy: 0.7045 - val_loss: 0.9452 - val_categorical_accuracy: 0.7250\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 0.6598 - categorical_accuracy: 0.7114 - val_loss: 0.9287 - val_categorical_accuracy: 0.7141\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 0.6478 - categorical_accuracy: 0.7205 - val_loss: 1.0229 - val_categorical_accuracy: 0.6500\n",
      "14/14 [==============================] - 0s 12ms/step - loss: 0.6781 - categorical_accuracy: 0.6955 - val_loss: 0.9851 - val_categorical_accuracy: 0.6891\n",
      "14/14 [==============================] - 0s 15ms/step - loss: 0.6482 - categorical_accuracy: 0.7159 - val_loss: 0.9819 - val_categorical_accuracy: 0.7328\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 0.6519 - categorical_accuracy: 0.7000 - val_loss: 1.0422 - val_categorical_accuracy: 0.7063\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 0.6776 - categorical_accuracy: 0.6864 - val_loss: 0.9997 - val_categorical_accuracy: 0.7109\n",
      "14/14 [==============================] - 0s 12ms/step - loss: 0.6458 - categorical_accuracy: 0.7091 - val_loss: 1.0567 - val_categorical_accuracy: 0.7000\n",
      "14/14 [==============================] - 0s 12ms/step - loss: 0.6610 - categorical_accuracy: 0.6909 - val_loss: 0.9720 - val_categorical_accuracy: 0.7219\n",
      "14/14 [==============================] - 0s 12ms/step - loss: 0.6369 - categorical_accuracy: 0.7091 - val_loss: 1.0130 - val_categorical_accuracy: 0.7156\n",
      "14/14 [==============================] - 0s 12ms/step - loss: 0.6355 - categorical_accuracy: 0.7045 - val_loss: 1.0262 - val_categorical_accuracy: 0.7031\n",
      "14/14 [==============================] - 0s 12ms/step - loss: 0.6478 - categorical_accuracy: 0.6864 - val_loss: 0.9934 - val_categorical_accuracy: 0.7047\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 0.6227 - categorical_accuracy: 0.7250 - val_loss: 1.0030 - val_categorical_accuracy: 0.7234\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 0.6432 - categorical_accuracy: 0.7227 - val_loss: 1.0122 - val_categorical_accuracy: 0.6812\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 0.6038 - categorical_accuracy: 0.7295 - val_loss: 1.0448 - val_categorical_accuracy: 0.7016\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 0.6113 - categorical_accuracy: 0.7205 - val_loss: 1.1960 - val_categorical_accuracy: 0.6297\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 0.6468 - categorical_accuracy: 0.7136 - val_loss: 0.9959 - val_categorical_accuracy: 0.7375\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 0.6005 - categorical_accuracy: 0.7250 - val_loss: 1.0639 - val_categorical_accuracy: 0.7156\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 0.6051 - categorical_accuracy: 0.7159 - val_loss: 1.1127 - val_categorical_accuracy: 0.6469\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 0.5876 - categorical_accuracy: 0.7341 - val_loss: 1.0853 - val_categorical_accuracy: 0.7000\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 0.5911 - categorical_accuracy: 0.7295 - val_loss: 1.0563 - val_categorical_accuracy: 0.6844\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 0.5952 - categorical_accuracy: 0.7409 - val_loss: 1.0670 - val_categorical_accuracy: 0.6859\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 0.5965 - categorical_accuracy: 0.7068 - val_loss: 1.2415 - val_categorical_accuracy: 0.6594\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 0.5913 - categorical_accuracy: 0.7295 - val_loss: 1.1332 - val_categorical_accuracy: 0.6812\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 0.5939 - categorical_accuracy: 0.7295 - val_loss: 1.1680 - val_categorical_accuracy: 0.6953\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 0.5942 - categorical_accuracy: 0.7295 - val_loss: 1.0355 - val_categorical_accuracy: 0.7453\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 0.5531 - categorical_accuracy: 0.7432 - val_loss: 1.1387 - val_categorical_accuracy: 0.6719\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 0.5807 - categorical_accuracy: 0.7205 - val_loss: 1.1910 - val_categorical_accuracy: 0.6500\n",
      "Training slp67x (2/14)...\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 0.9578 - categorical_accuracy: 0.5584 - val_loss: 1.0805 - val_categorical_accuracy: 0.6391\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 0.7616 - categorical_accuracy: 0.6818 - val_loss: 0.9363 - val_categorical_accuracy: 0.7453\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 0.6858 - categorical_accuracy: 0.7013 - val_loss: 0.9143 - val_categorical_accuracy: 0.7859\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 0.6369 - categorical_accuracy: 0.7338 - val_loss: 0.9968 - val_categorical_accuracy: 0.7766\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 0.6023 - categorical_accuracy: 0.7338 - val_loss: 1.0924 - val_categorical_accuracy: 0.7641\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 0.6130 - categorical_accuracy: 0.7727 - val_loss: 1.1343 - val_categorical_accuracy: 0.7625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 23ms/step - loss: 0.5771 - categorical_accuracy: 0.7468 - val_loss: 1.1745 - val_categorical_accuracy: 0.7594\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.5572 - categorical_accuracy: 0.7468 - val_loss: 1.1480 - val_categorical_accuracy: 0.7734\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 0.5612 - categorical_accuracy: 0.7208 - val_loss: 1.1166 - val_categorical_accuracy: 0.7781\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 0.5345 - categorical_accuracy: 0.7468 - val_loss: 1.1307 - val_categorical_accuracy: 0.7859\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 0.5082 - categorical_accuracy: 0.7727 - val_loss: 1.2157 - val_categorical_accuracy: 0.7688\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 0.4943 - categorical_accuracy: 0.7727 - val_loss: 1.3177 - val_categorical_accuracy: 0.7484\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 0.5119 - categorical_accuracy: 0.7532 - val_loss: 1.3064 - val_categorical_accuracy: 0.7719\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 0.4670 - categorical_accuracy: 0.7727 - val_loss: 1.2896 - val_categorical_accuracy: 0.7672\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 0.4698 - categorical_accuracy: 0.8182 - val_loss: 1.2705 - val_categorical_accuracy: 0.7703\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 0.4697 - categorical_accuracy: 0.8247 - val_loss: 1.3533 - val_categorical_accuracy: 0.7656\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 0.4836 - categorical_accuracy: 0.7792 - val_loss: 1.3728 - val_categorical_accuracy: 0.7641\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 0.4406 - categorical_accuracy: 0.8052 - val_loss: 1.3783 - val_categorical_accuracy: 0.7937\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 0.4198 - categorical_accuracy: 0.8052 - val_loss: 1.4428 - val_categorical_accuracy: 0.7531\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 0.4655 - categorical_accuracy: 0.7727 - val_loss: 1.4193 - val_categorical_accuracy: 0.7328\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.4389 - categorical_accuracy: 0.7922 - val_loss: 1.4751 - val_categorical_accuracy: 0.7391\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 0.4172 - categorical_accuracy: 0.8052 - val_loss: 1.5279 - val_categorical_accuracy: 0.7656\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.4077 - categorical_accuracy: 0.8182 - val_loss: 1.4938 - val_categorical_accuracy: 0.7672\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 0.4650 - categorical_accuracy: 0.7922 - val_loss: 1.4762 - val_categorical_accuracy: 0.7406\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 0.4144 - categorical_accuracy: 0.7987 - val_loss: 1.5100 - val_categorical_accuracy: 0.7563\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 0.3982 - categorical_accuracy: 0.8182 - val_loss: 1.5723 - val_categorical_accuracy: 0.7609\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 0.3695 - categorical_accuracy: 0.8312 - val_loss: 1.5971 - val_categorical_accuracy: 0.7422\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 0.3708 - categorical_accuracy: 0.8312 - val_loss: 1.5935 - val_categorical_accuracy: 0.7297\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 0.3296 - categorical_accuracy: 0.8701 - val_loss: 1.6518 - val_categorical_accuracy: 0.7391\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 0.3545 - categorical_accuracy: 0.8571 - val_loss: 1.6839 - val_categorical_accuracy: 0.7531\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 0.3519 - categorical_accuracy: 0.8377 - val_loss: 1.6987 - val_categorical_accuracy: 0.7359\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 0.3653 - categorical_accuracy: 0.8377 - val_loss: 1.7134 - val_categorical_accuracy: 0.7406\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 0.3286 - categorical_accuracy: 0.8377 - val_loss: 1.8427 - val_categorical_accuracy: 0.7437\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 0.3473 - categorical_accuracy: 0.8312 - val_loss: 1.9360 - val_categorical_accuracy: 0.7375\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 0.3569 - categorical_accuracy: 0.8506 - val_loss: 2.0096 - val_categorical_accuracy: 0.7109\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 0.3821 - categorical_accuracy: 0.8247 - val_loss: 1.8839 - val_categorical_accuracy: 0.7281\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 0.3167 - categorical_accuracy: 0.8506 - val_loss: 1.7571 - val_categorical_accuracy: 0.7625\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 0.3371 - categorical_accuracy: 0.8506 - val_loss: 1.8248 - val_categorical_accuracy: 0.7719\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 0.3202 - categorical_accuracy: 0.8506 - val_loss: 2.0712 - val_categorical_accuracy: 0.7188\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 0.3046 - categorical_accuracy: 0.8766 - val_loss: 2.1782 - val_categorical_accuracy: 0.7031\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 0.3255 - categorical_accuracy: 0.8377 - val_loss: 1.9096 - val_categorical_accuracy: 0.7359\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 0.3157 - categorical_accuracy: 0.8636 - val_loss: 1.8345 - val_categorical_accuracy: 0.7312\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 0.2983 - categorical_accuracy: 0.8766 - val_loss: 1.9937 - val_categorical_accuracy: 0.7344\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 0.3274 - categorical_accuracy: 0.8571 - val_loss: 2.1639 - val_categorical_accuracy: 0.7312\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 0.3247 - categorical_accuracy: 0.8506 - val_loss: 2.1625 - val_categorical_accuracy: 0.7000\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 0.3299 - categorical_accuracy: 0.8506 - val_loss: 2.0605 - val_categorical_accuracy: 0.7031\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 0.3082 - categorical_accuracy: 0.8571 - val_loss: 1.9297 - val_categorical_accuracy: 0.7453\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 0.3009 - categorical_accuracy: 0.8571 - val_loss: 2.0335 - val_categorical_accuracy: 0.7406\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 0.2351 - categorical_accuracy: 0.9091 - val_loss: 2.2310 - val_categorical_accuracy: 0.6938\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 0.3076 - categorical_accuracy: 0.8636 - val_loss: 2.2238 - val_categorical_accuracy: 0.7141\n",
      "Training slp01a (3/14)...\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 3.1764 - categorical_accuracy: 0.5208 - val_loss: 0.9297 - val_categorical_accuracy: 0.7109\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.8600 - categorical_accuracy: 0.6833 - val_loss: 1.4438 - val_categorical_accuracy: 0.3969\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.7578 - categorical_accuracy: 0.7125 - val_loss: 1.4142 - val_categorical_accuracy: 0.4609\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.6842 - categorical_accuracy: 0.7583 - val_loss: 1.3889 - val_categorical_accuracy: 0.5328\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.6833 - categorical_accuracy: 0.7708 - val_loss: 1.1263 - val_categorical_accuracy: 0.6891\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.6457 - categorical_accuracy: 0.7625 - val_loss: 1.0825 - val_categorical_accuracy: 0.6906\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.5865 - categorical_accuracy: 0.7667 - val_loss: 0.9296 - val_categorical_accuracy: 0.7625\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.5281 - categorical_accuracy: 0.7750 - val_loss: 1.0037 - val_categorical_accuracy: 0.7234\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.5062 - categorical_accuracy: 0.8208 - val_loss: 1.0089 - val_categorical_accuracy: 0.7297\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.5375 - categorical_accuracy: 0.7958 - val_loss: 1.1852 - val_categorical_accuracy: 0.5984\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 18ms/step - loss: 0.4985 - categorical_accuracy: 0.8333 - val_loss: 1.0923 - val_categorical_accuracy: 0.6562\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.4946 - categorical_accuracy: 0.8042 - val_loss: 1.1921 - val_categorical_accuracy: 0.6219\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.5079 - categorical_accuracy: 0.8000 - val_loss: 1.1764 - val_categorical_accuracy: 0.6219\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.5055 - categorical_accuracy: 0.7958 - val_loss: 1.2333 - val_categorical_accuracy: 0.5656\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.4942 - categorical_accuracy: 0.8208 - val_loss: 1.2080 - val_categorical_accuracy: 0.5984\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.5228 - categorical_accuracy: 0.8042 - val_loss: 1.1926 - val_categorical_accuracy: 0.6234\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.4851 - categorical_accuracy: 0.8208 - val_loss: 1.2307 - val_categorical_accuracy: 0.6062\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.4820 - categorical_accuracy: 0.8167 - val_loss: 1.1080 - val_categorical_accuracy: 0.6781\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.4857 - categorical_accuracy: 0.8083 - val_loss: 1.1686 - val_categorical_accuracy: 0.6406\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.4883 - categorical_accuracy: 0.8125 - val_loss: 1.0715 - val_categorical_accuracy: 0.6969\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.4616 - categorical_accuracy: 0.8250 - val_loss: 1.3080 - val_categorical_accuracy: 0.5906\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.4674 - categorical_accuracy: 0.8333 - val_loss: 1.2481 - val_categorical_accuracy: 0.6172\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.4939 - categorical_accuracy: 0.8083 - val_loss: 1.3567 - val_categorical_accuracy: 0.5797\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.4667 - categorical_accuracy: 0.8125 - val_loss: 1.3384 - val_categorical_accuracy: 0.5875\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.4554 - categorical_accuracy: 0.8083 - val_loss: 1.2729 - val_categorical_accuracy: 0.6453\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.4444 - categorical_accuracy: 0.8375 - val_loss: 1.5454 - val_categorical_accuracy: 0.5203\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.4126 - categorical_accuracy: 0.8458 - val_loss: 1.3451 - val_categorical_accuracy: 0.5906\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.4227 - categorical_accuracy: 0.8417 - val_loss: 1.3871 - val_categorical_accuracy: 0.6016\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.4264 - categorical_accuracy: 0.8083 - val_loss: 1.3094 - val_categorical_accuracy: 0.6516\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.4586 - categorical_accuracy: 0.8125 - val_loss: 1.2697 - val_categorical_accuracy: 0.6391\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.4111 - categorical_accuracy: 0.8417 - val_loss: 1.4846 - val_categorical_accuracy: 0.5719\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.4149 - categorical_accuracy: 0.8417 - val_loss: 1.6177 - val_categorical_accuracy: 0.5297\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.3994 - categorical_accuracy: 0.8458 - val_loss: 1.4606 - val_categorical_accuracy: 0.5766\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.4450 - categorical_accuracy: 0.8208 - val_loss: 1.6754 - val_categorical_accuracy: 0.4781\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.4198 - categorical_accuracy: 0.8292 - val_loss: 1.4509 - val_categorical_accuracy: 0.5641\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.4133 - categorical_accuracy: 0.8167 - val_loss: 1.7358 - val_categorical_accuracy: 0.4891\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.3779 - categorical_accuracy: 0.8417 - val_loss: 1.5496 - val_categorical_accuracy: 0.5547\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.4139 - categorical_accuracy: 0.8250 - val_loss: 1.4345 - val_categorical_accuracy: 0.6062\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.3987 - categorical_accuracy: 0.8292 - val_loss: 1.3960 - val_categorical_accuracy: 0.6203\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.3885 - categorical_accuracy: 0.8333 - val_loss: 1.5594 - val_categorical_accuracy: 0.5672\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.4043 - categorical_accuracy: 0.8167 - val_loss: 1.5138 - val_categorical_accuracy: 0.5813\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.4012 - categorical_accuracy: 0.8333 - val_loss: 1.4855 - val_categorical_accuracy: 0.5734\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.4007 - categorical_accuracy: 0.8458 - val_loss: 1.4690 - val_categorical_accuracy: 0.5813\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.3929 - categorical_accuracy: 0.8458 - val_loss: 1.5666 - val_categorical_accuracy: 0.5578\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.3843 - categorical_accuracy: 0.8375 - val_loss: 1.5373 - val_categorical_accuracy: 0.5891\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.3743 - categorical_accuracy: 0.8458 - val_loss: 1.5718 - val_categorical_accuracy: 0.6031\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.3627 - categorical_accuracy: 0.8625 - val_loss: 1.5614 - val_categorical_accuracy: 0.6141\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.3696 - categorical_accuracy: 0.8417 - val_loss: 1.4916 - val_categorical_accuracy: 0.6453\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.4008 - categorical_accuracy: 0.8375 - val_loss: 1.8228 - val_categorical_accuracy: 0.5531\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.3628 - categorical_accuracy: 0.8583 - val_loss: 1.9985 - val_categorical_accuracy: 0.4844\n",
      "Training slp41 (4/14)...\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 1.6815 - categorical_accuracy: 0.3372 - val_loss: 1.1487 - val_categorical_accuracy: 0.6469\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 1.2290 - categorical_accuracy: 0.4154 - val_loss: 0.9881 - val_categorical_accuracy: 0.7641\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 1.1193 - categorical_accuracy: 0.4885 - val_loss: 1.0193 - val_categorical_accuracy: 0.6797\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 1.0952 - categorical_accuracy: 0.4705 - val_loss: 0.9627 - val_categorical_accuracy: 0.7078\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 1.0652 - categorical_accuracy: 0.4962 - val_loss: 1.0075 - val_categorical_accuracy: 0.6906\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 1.0470 - categorical_accuracy: 0.5141 - val_loss: 0.9941 - val_categorical_accuracy: 0.6938\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 1.0284 - categorical_accuracy: 0.5141 - val_loss: 0.9728 - val_categorical_accuracy: 0.7188\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 1.0262 - categorical_accuracy: 0.5269 - val_loss: 1.0191 - val_categorical_accuracy: 0.6859\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 1.0065 - categorical_accuracy: 0.5244 - val_loss: 1.0615 - val_categorical_accuracy: 0.6672\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 1.0024 - categorical_accuracy: 0.5256 - val_loss: 1.0906 - val_categorical_accuracy: 0.6656\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.9804 - categorical_accuracy: 0.5385 - val_loss: 1.1087 - val_categorical_accuracy: 0.6687\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.9922 - categorical_accuracy: 0.5397 - val_loss: 1.0612 - val_categorical_accuracy: 0.6797\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.9834 - categorical_accuracy: 0.5282 - val_loss: 1.0301 - val_categorical_accuracy: 0.6797\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.9721 - categorical_accuracy: 0.5474 - val_loss: 1.0218 - val_categorical_accuracy: 0.6938\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/25 [==============================] - 0s 8ms/step - loss: 0.9662 - categorical_accuracy: 0.5449 - val_loss: 1.0590 - val_categorical_accuracy: 0.6859\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.9673 - categorical_accuracy: 0.5333 - val_loss: 1.0822 - val_categorical_accuracy: 0.6891\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.9484 - categorical_accuracy: 0.5397 - val_loss: 1.0599 - val_categorical_accuracy: 0.6938\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.9428 - categorical_accuracy: 0.5679 - val_loss: 1.1525 - val_categorical_accuracy: 0.6812\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.9451 - categorical_accuracy: 0.5372 - val_loss: 1.1564 - val_categorical_accuracy: 0.6672\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.9600 - categorical_accuracy: 0.5256 - val_loss: 1.1766 - val_categorical_accuracy: 0.6875\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.9315 - categorical_accuracy: 0.5577 - val_loss: 1.1372 - val_categorical_accuracy: 0.6703\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.9269 - categorical_accuracy: 0.5577 - val_loss: 1.1421 - val_categorical_accuracy: 0.7047\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.9409 - categorical_accuracy: 0.5436 - val_loss: 1.1534 - val_categorical_accuracy: 0.7016\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.8895 - categorical_accuracy: 0.5654 - val_loss: 1.2245 - val_categorical_accuracy: 0.6953\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.9095 - categorical_accuracy: 0.5667 - val_loss: 1.2059 - val_categorical_accuracy: 0.6828\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.9018 - categorical_accuracy: 0.5628 - val_loss: 1.1244 - val_categorical_accuracy: 0.7109\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.8937 - categorical_accuracy: 0.5808 - val_loss: 1.3503 - val_categorical_accuracy: 0.6969\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.8964 - categorical_accuracy: 0.5705 - val_loss: 1.1253 - val_categorical_accuracy: 0.7094\n",
      "25/25 [==============================] - 0s 11ms/step - loss: 0.8928 - categorical_accuracy: 0.5641 - val_loss: 1.0684 - val_categorical_accuracy: 0.7047\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.8985 - categorical_accuracy: 0.5808 - val_loss: 1.1524 - val_categorical_accuracy: 0.6859\n",
      "25/25 [==============================] - 0s 15ms/step - loss: 0.8965 - categorical_accuracy: 0.5718 - val_loss: 1.3482 - val_categorical_accuracy: 0.6969\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.8748 - categorical_accuracy: 0.5910 - val_loss: 1.2698 - val_categorical_accuracy: 0.6891\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.8754 - categorical_accuracy: 0.6077 - val_loss: 1.3908 - val_categorical_accuracy: 0.6797\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.8841 - categorical_accuracy: 0.6000 - val_loss: 1.2823 - val_categorical_accuracy: 0.6844\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.8698 - categorical_accuracy: 0.5910 - val_loss: 1.4313 - val_categorical_accuracy: 0.6906\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.8781 - categorical_accuracy: 0.5821 - val_loss: 1.4118 - val_categorical_accuracy: 0.6594\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.8743 - categorical_accuracy: 0.5923 - val_loss: 1.3475 - val_categorical_accuracy: 0.7125\n",
      "25/25 [==============================] - 0s 11ms/step - loss: 0.8509 - categorical_accuracy: 0.6115 - val_loss: 1.3242 - val_categorical_accuracy: 0.6984\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.8485 - categorical_accuracy: 0.5974 - val_loss: 1.4135 - val_categorical_accuracy: 0.6641\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.8414 - categorical_accuracy: 0.6115 - val_loss: 1.4979 - val_categorical_accuracy: 0.6781\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.8804 - categorical_accuracy: 0.6051 - val_loss: 1.3925 - val_categorical_accuracy: 0.6594\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.8595 - categorical_accuracy: 0.6077 - val_loss: 1.4285 - val_categorical_accuracy: 0.6844\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.8392 - categorical_accuracy: 0.6141 - val_loss: 1.6696 - val_categorical_accuracy: 0.6859\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.8035 - categorical_accuracy: 0.6321 - val_loss: 1.6109 - val_categorical_accuracy: 0.6828\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.8240 - categorical_accuracy: 0.6128 - val_loss: 1.4711 - val_categorical_accuracy: 0.7063\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.8234 - categorical_accuracy: 0.6090 - val_loss: 1.5356 - val_categorical_accuracy: 0.6672\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.8423 - categorical_accuracy: 0.5974 - val_loss: 1.4800 - val_categorical_accuracy: 0.6734\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.8406 - categorical_accuracy: 0.6013 - val_loss: 1.4192 - val_categorical_accuracy: 0.6687\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.8347 - categorical_accuracy: 0.6026 - val_loss: 1.5750 - val_categorical_accuracy: 0.6875\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.8191 - categorical_accuracy: 0.5987 - val_loss: 1.6108 - val_categorical_accuracy: 0.6750\n",
      "Training slp01b (5/14)...\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 1.0409 - categorical_accuracy: 0.6444 - val_loss: 0.7970 - val_categorical_accuracy: 0.7391\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.6582 - categorical_accuracy: 0.7750 - val_loss: 0.6982 - val_categorical_accuracy: 0.7766\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.5830 - categorical_accuracy: 0.7861 - val_loss: 0.7243 - val_categorical_accuracy: 0.7656\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.5907 - categorical_accuracy: 0.8194 - val_loss: 0.7329 - val_categorical_accuracy: 0.7656\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.5087 - categorical_accuracy: 0.8333 - val_loss: 0.7727 - val_categorical_accuracy: 0.7750\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.5078 - categorical_accuracy: 0.8194 - val_loss: 0.7654 - val_categorical_accuracy: 0.7703\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.5057 - categorical_accuracy: 0.8333 - val_loss: 0.7828 - val_categorical_accuracy: 0.7719\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.4418 - categorical_accuracy: 0.8417 - val_loss: 0.8385 - val_categorical_accuracy: 0.7766\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.4762 - categorical_accuracy: 0.8417 - val_loss: 0.8255 - val_categorical_accuracy: 0.7672\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.4285 - categorical_accuracy: 0.8528 - val_loss: 0.8886 - val_categorical_accuracy: 0.7797\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.4527 - categorical_accuracy: 0.8417 - val_loss: 0.8532 - val_categorical_accuracy: 0.7719\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.4169 - categorical_accuracy: 0.8639 - val_loss: 0.8671 - val_categorical_accuracy: 0.7719\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.3935 - categorical_accuracy: 0.8639 - val_loss: 0.8910 - val_categorical_accuracy: 0.7781\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.4124 - categorical_accuracy: 0.8611 - val_loss: 0.9712 - val_categorical_accuracy: 0.7797\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.4454 - categorical_accuracy: 0.8472 - val_loss: 0.9851 - val_categorical_accuracy: 0.7734\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.4083 - categorical_accuracy: 0.8639 - val_loss: 0.9078 - val_categorical_accuracy: 0.7719\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.4001 - categorical_accuracy: 0.8611 - val_loss: 0.8343 - val_categorical_accuracy: 0.7859\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 0s 12ms/step - loss: 0.4006 - categorical_accuracy: 0.8472 - val_loss: 0.9256 - val_categorical_accuracy: 0.7750\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.3702 - categorical_accuracy: 0.8611 - val_loss: 0.9935 - val_categorical_accuracy: 0.7828\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.3668 - categorical_accuracy: 0.8694 - val_loss: 0.9378 - val_categorical_accuracy: 0.7828\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.3882 - categorical_accuracy: 0.8583 - val_loss: 0.9580 - val_categorical_accuracy: 0.7781\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.3546 - categorical_accuracy: 0.8722 - val_loss: 1.0401 - val_categorical_accuracy: 0.7922\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.3464 - categorical_accuracy: 0.8778 - val_loss: 1.0191 - val_categorical_accuracy: 0.7812\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.3515 - categorical_accuracy: 0.8833 - val_loss: 1.0130 - val_categorical_accuracy: 0.7859\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.3586 - categorical_accuracy: 0.8722 - val_loss: 1.0675 - val_categorical_accuracy: 0.7766\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.3567 - categorical_accuracy: 0.8583 - val_loss: 1.1083 - val_categorical_accuracy: 0.7828\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.3087 - categorical_accuracy: 0.8806 - val_loss: 1.2419 - val_categorical_accuracy: 0.7844\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.3535 - categorical_accuracy: 0.8778 - val_loss: 1.3715 - val_categorical_accuracy: 0.7797\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.3173 - categorical_accuracy: 0.8917 - val_loss: 1.4107 - val_categorical_accuracy: 0.7766\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.3466 - categorical_accuracy: 0.8778 - val_loss: 1.5072 - val_categorical_accuracy: 0.7781\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.3521 - categorical_accuracy: 0.8667 - val_loss: 1.2678 - val_categorical_accuracy: 0.7656\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.3154 - categorical_accuracy: 0.8806 - val_loss: 1.1470 - val_categorical_accuracy: 0.7656\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.3665 - categorical_accuracy: 0.8556 - val_loss: 1.1886 - val_categorical_accuracy: 0.7578\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.3155 - categorical_accuracy: 0.8972 - val_loss: 1.2905 - val_categorical_accuracy: 0.7609\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 0.3196 - categorical_accuracy: 0.8944 - val_loss: 1.3066 - val_categorical_accuracy: 0.7641\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.3281 - categorical_accuracy: 0.8694 - val_loss: 1.3809 - val_categorical_accuracy: 0.7875\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.2985 - categorical_accuracy: 0.8861 - val_loss: 1.4651 - val_categorical_accuracy: 0.7594\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.3339 - categorical_accuracy: 0.8750 - val_loss: 1.4699 - val_categorical_accuracy: 0.7672\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.2978 - categorical_accuracy: 0.8917 - val_loss: 1.3450 - val_categorical_accuracy: 0.7672\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.2836 - categorical_accuracy: 0.8833 - val_loss: 1.5369 - val_categorical_accuracy: 0.7609\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.2856 - categorical_accuracy: 0.8833 - val_loss: 1.6770 - val_categorical_accuracy: 0.7531\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.2975 - categorical_accuracy: 0.8750 - val_loss: 1.6688 - val_categorical_accuracy: 0.7625\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.2831 - categorical_accuracy: 0.8917 - val_loss: 1.6458 - val_categorical_accuracy: 0.7516\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.2681 - categorical_accuracy: 0.8917 - val_loss: 1.6677 - val_categorical_accuracy: 0.7375\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.2879 - categorical_accuracy: 0.8944 - val_loss: 1.6127 - val_categorical_accuracy: 0.7797\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.2575 - categorical_accuracy: 0.8972 - val_loss: 1.7865 - val_categorical_accuracy: 0.7625\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.2741 - categorical_accuracy: 0.8944 - val_loss: 1.7828 - val_categorical_accuracy: 0.7578\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.2689 - categorical_accuracy: 0.8944 - val_loss: 1.7142 - val_categorical_accuracy: 0.7781\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.2848 - categorical_accuracy: 0.8833 - val_loss: 2.0063 - val_categorical_accuracy: 0.7703\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.2691 - categorical_accuracy: 0.8778 - val_loss: 2.2716 - val_categorical_accuracy: 0.7859\n",
      "Training slp03 (6/14)...\n",
      "23/23 [==============================] - 0s 9ms/step - loss: 1.6690 - categorical_accuracy: 0.4778 - val_loss: 0.7418 - val_categorical_accuracy: 0.7859\n",
      "23/23 [==============================] - 0s 9ms/step - loss: 1.1662 - categorical_accuracy: 0.5306 - val_loss: 0.6905 - val_categorical_accuracy: 0.8016\n",
      "23/23 [==============================] - 0s 9ms/step - loss: 1.1041 - categorical_accuracy: 0.5583 - val_loss: 0.7019 - val_categorical_accuracy: 0.7984\n",
      "23/23 [==============================] - 0s 9ms/step - loss: 1.0669 - categorical_accuracy: 0.5778 - val_loss: 0.7152 - val_categorical_accuracy: 0.7531\n",
      "23/23 [==============================] - 0s 9ms/step - loss: 1.0477 - categorical_accuracy: 0.5750 - val_loss: 0.7385 - val_categorical_accuracy: 0.7594\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 1.0408 - categorical_accuracy: 0.5944 - val_loss: 0.8183 - val_categorical_accuracy: 0.7469\n",
      "23/23 [==============================] - 0s 9ms/step - loss: 1.0315 - categorical_accuracy: 0.5903 - val_loss: 0.7741 - val_categorical_accuracy: 0.7531\n",
      "23/23 [==============================] - 0s 9ms/step - loss: 1.0191 - categorical_accuracy: 0.5917 - val_loss: 0.7749 - val_categorical_accuracy: 0.7484\n",
      "23/23 [==============================] - 0s 9ms/step - loss: 1.0127 - categorical_accuracy: 0.6000 - val_loss: 0.8418 - val_categorical_accuracy: 0.7063\n",
      "23/23 [==============================] - 0s 9ms/step - loss: 1.0027 - categorical_accuracy: 0.5944 - val_loss: 0.8180 - val_categorical_accuracy: 0.7266\n",
      "23/23 [==============================] - 0s 9ms/step - loss: 0.9922 - categorical_accuracy: 0.5986 - val_loss: 0.8222 - val_categorical_accuracy: 0.7281\n",
      "23/23 [==============================] - 0s 9ms/step - loss: 0.9787 - categorical_accuracy: 0.6028 - val_loss: 0.8753 - val_categorical_accuracy: 0.7000\n",
      "23/23 [==============================] - 0s 9ms/step - loss: 0.9956 - categorical_accuracy: 0.6181 - val_loss: 0.8596 - val_categorical_accuracy: 0.6906\n",
      "23/23 [==============================] - 0s 18ms/step - loss: 0.9876 - categorical_accuracy: 0.6028 - val_loss: 0.9688 - val_categorical_accuracy: 0.6859\n",
      "23/23 [==============================] - 0s 12ms/step - loss: 0.9566 - categorical_accuracy: 0.6194 - val_loss: 0.9642 - val_categorical_accuracy: 0.6969\n",
      "23/23 [==============================] - 0s 14ms/step - loss: 0.9595 - categorical_accuracy: 0.6097 - val_loss: 1.0303 - val_categorical_accuracy: 0.6516\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.9740 - categorical_accuracy: 0.6083 - val_loss: 0.9840 - val_categorical_accuracy: 0.6687\n",
      "23/23 [==============================] - 0s 9ms/step - loss: 0.9663 - categorical_accuracy: 0.6042 - val_loss: 1.0698 - val_categorical_accuracy: 0.6641\n",
      "23/23 [==============================] - 0s 9ms/step - loss: 0.9613 - categorical_accuracy: 0.6111 - val_loss: 1.0432 - val_categorical_accuracy: 0.6875\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 0.9427 - categorical_accuracy: 0.6222 - val_loss: 0.9965 - val_categorical_accuracy: 0.7172\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 0s 9ms/step - loss: 0.9110 - categorical_accuracy: 0.6250 - val_loss: 1.0263 - val_categorical_accuracy: 0.6594\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 0.9262 - categorical_accuracy: 0.6264 - val_loss: 1.0848 - val_categorical_accuracy: 0.6500\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 0.9143 - categorical_accuracy: 0.6250 - val_loss: 1.0031 - val_categorical_accuracy: 0.7172\n",
      "23/23 [==============================] - 0s 9ms/step - loss: 0.9056 - categorical_accuracy: 0.6347 - val_loss: 1.0430 - val_categorical_accuracy: 0.6609\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 0.9206 - categorical_accuracy: 0.6264 - val_loss: 0.9972 - val_categorical_accuracy: 0.6891\n",
      "23/23 [==============================] - 0s 9ms/step - loss: 0.8893 - categorical_accuracy: 0.6431 - val_loss: 1.1843 - val_categorical_accuracy: 0.6422\n",
      "23/23 [==============================] - 0s 9ms/step - loss: 0.8969 - categorical_accuracy: 0.6361 - val_loss: 1.2236 - val_categorical_accuracy: 0.6187\n",
      "23/23 [==============================] - 0s 9ms/step - loss: 0.9039 - categorical_accuracy: 0.6375 - val_loss: 1.2438 - val_categorical_accuracy: 0.6078\n",
      "23/23 [==============================] - 0s 9ms/step - loss: 0.8877 - categorical_accuracy: 0.6542 - val_loss: 1.2409 - val_categorical_accuracy: 0.6062\n",
      "23/23 [==============================] - 0s 9ms/step - loss: 0.8770 - categorical_accuracy: 0.6375 - val_loss: 1.3182 - val_categorical_accuracy: 0.6297\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 0.8667 - categorical_accuracy: 0.6514 - val_loss: 1.3186 - val_categorical_accuracy: 0.6266\n",
      "23/23 [==============================] - 0s 9ms/step - loss: 0.8634 - categorical_accuracy: 0.6542 - val_loss: 1.3140 - val_categorical_accuracy: 0.6297\n",
      "23/23 [==============================] - 0s 9ms/step - loss: 0.8649 - categorical_accuracy: 0.6486 - val_loss: 1.2969 - val_categorical_accuracy: 0.6172\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 0.8340 - categorical_accuracy: 0.6639 - val_loss: 1.2810 - val_categorical_accuracy: 0.6828\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 0.8298 - categorical_accuracy: 0.6569 - val_loss: 1.4157 - val_categorical_accuracy: 0.6266\n",
      "23/23 [==============================] - 0s 12ms/step - loss: 0.8438 - categorical_accuracy: 0.6444 - val_loss: 1.2161 - val_categorical_accuracy: 0.7000\n",
      "23/23 [==============================] - 0s 13ms/step - loss: 0.8509 - categorical_accuracy: 0.6569 - val_loss: 1.5078 - val_categorical_accuracy: 0.5766\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 0.8557 - categorical_accuracy: 0.6597 - val_loss: 1.1235 - val_categorical_accuracy: 0.6187\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 0.8374 - categorical_accuracy: 0.6639 - val_loss: 1.3854 - val_categorical_accuracy: 0.6125\n",
      "23/23 [==============================] - 0s 12ms/step - loss: 0.8540 - categorical_accuracy: 0.6597 - val_loss: 1.2678 - val_categorical_accuracy: 0.6687\n",
      "23/23 [==============================] - 0s 14ms/step - loss: 0.8100 - categorical_accuracy: 0.6806 - val_loss: 1.4183 - val_categorical_accuracy: 0.5562\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 0.8241 - categorical_accuracy: 0.6639 - val_loss: 1.7295 - val_categorical_accuracy: 0.4828\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 0.8111 - categorical_accuracy: 0.6597 - val_loss: 1.4638 - val_categorical_accuracy: 0.6281\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 0.8076 - categorical_accuracy: 0.6750 - val_loss: 1.5853 - val_categorical_accuracy: 0.5547\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 0.8304 - categorical_accuracy: 0.6542 - val_loss: 1.7180 - val_categorical_accuracy: 0.4734\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 0.8281 - categorical_accuracy: 0.6611 - val_loss: 1.4894 - val_categorical_accuracy: 0.6000\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 0.7872 - categorical_accuracy: 0.6764 - val_loss: 1.4398 - val_categorical_accuracy: 0.6047\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 0.7763 - categorical_accuracy: 0.6903 - val_loss: 1.6685 - val_categorical_accuracy: 0.5562\n",
      "23/23 [==============================] - 0s 9ms/step - loss: 0.8162 - categorical_accuracy: 0.6736 - val_loss: 1.4765 - val_categorical_accuracy: 0.5828\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 0.7922 - categorical_accuracy: 0.6861 - val_loss: 1.7511 - val_categorical_accuracy: 0.4828\n",
      "Training slp61 (7/14)...\n",
      "24/24 [==============================] - 0s 13ms/step - loss: 1.3829 - categorical_accuracy: 0.4595 - val_loss: 0.9512 - val_categorical_accuracy: 0.6984\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.9402 - categorical_accuracy: 0.5689 - val_loss: 0.7527 - val_categorical_accuracy: 0.7969\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.8348 - categorical_accuracy: 0.6703 - val_loss: 0.7050 - val_categorical_accuracy: 0.7984\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.8088 - categorical_accuracy: 0.6635 - val_loss: 0.7111 - val_categorical_accuracy: 0.8000\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.7710 - categorical_accuracy: 0.6770 - val_loss: 0.7084 - val_categorical_accuracy: 0.7891\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.7513 - categorical_accuracy: 0.6851 - val_loss: 0.7129 - val_categorical_accuracy: 0.7937\n",
      "24/24 [==============================] - 1s 34ms/step - loss: 0.7499 - categorical_accuracy: 0.6946 - val_loss: 0.7438 - val_categorical_accuracy: 0.7922\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.7110 - categorical_accuracy: 0.7068 - val_loss: 0.7418 - val_categorical_accuracy: 0.8016\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.7058 - categorical_accuracy: 0.7068 - val_loss: 0.7117 - val_categorical_accuracy: 0.7859\n",
      "24/24 [==============================] - 0s 13ms/step - loss: 0.6770 - categorical_accuracy: 0.7149 - val_loss: 0.7578 - val_categorical_accuracy: 0.7875\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.6882 - categorical_accuracy: 0.7081 - val_loss: 0.7514 - val_categorical_accuracy: 0.7859\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 0.6818 - categorical_accuracy: 0.7081 - val_loss: 0.7668 - val_categorical_accuracy: 0.7844\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 0.6666 - categorical_accuracy: 0.7203 - val_loss: 0.7844 - val_categorical_accuracy: 0.7906\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.6761 - categorical_accuracy: 0.7297 - val_loss: 0.7847 - val_categorical_accuracy: 0.7937\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.6469 - categorical_accuracy: 0.7203 - val_loss: 0.9049 - val_categorical_accuracy: 0.7734\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.6530 - categorical_accuracy: 0.7068 - val_loss: 0.8365 - val_categorical_accuracy: 0.7766\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.6604 - categorical_accuracy: 0.7189 - val_loss: 0.8660 - val_categorical_accuracy: 0.7719\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.6401 - categorical_accuracy: 0.7500 - val_loss: 0.8689 - val_categorical_accuracy: 0.7688\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.6294 - categorical_accuracy: 0.7270 - val_loss: 0.8804 - val_categorical_accuracy: 0.7703\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.6180 - categorical_accuracy: 0.7446 - val_loss: 0.9423 - val_categorical_accuracy: 0.7688\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.6223 - categorical_accuracy: 0.7351 - val_loss: 0.9045 - val_categorical_accuracy: 0.7625\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.6190 - categorical_accuracy: 0.7392 - val_loss: 0.9253 - val_categorical_accuracy: 0.7578\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.6335 - categorical_accuracy: 0.7392 - val_loss: 0.9481 - val_categorical_accuracy: 0.7734\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/24 [==============================] - 0s 9ms/step - loss: 0.6059 - categorical_accuracy: 0.7486 - val_loss: 0.9606 - val_categorical_accuracy: 0.7672\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.5866 - categorical_accuracy: 0.7473 - val_loss: 0.9766 - val_categorical_accuracy: 0.7578\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.6054 - categorical_accuracy: 0.7392 - val_loss: 0.9867 - val_categorical_accuracy: 0.7609\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.6079 - categorical_accuracy: 0.7405 - val_loss: 0.9172 - val_categorical_accuracy: 0.7563\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.5966 - categorical_accuracy: 0.7338 - val_loss: 1.0635 - val_categorical_accuracy: 0.7563\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.5924 - categorical_accuracy: 0.7432 - val_loss: 1.0781 - val_categorical_accuracy: 0.7594\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.5784 - categorical_accuracy: 0.7527 - val_loss: 1.0939 - val_categorical_accuracy: 0.7563\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.5721 - categorical_accuracy: 0.7541 - val_loss: 1.0730 - val_categorical_accuracy: 0.7625\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.5754 - categorical_accuracy: 0.7405 - val_loss: 1.0728 - val_categorical_accuracy: 0.7656\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.5372 - categorical_accuracy: 0.7527 - val_loss: 1.1877 - val_categorical_accuracy: 0.7578\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.5673 - categorical_accuracy: 0.7608 - val_loss: 1.1544 - val_categorical_accuracy: 0.7594\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.5666 - categorical_accuracy: 0.7473 - val_loss: 1.2561 - val_categorical_accuracy: 0.7703\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.5238 - categorical_accuracy: 0.7649 - val_loss: 1.3094 - val_categorical_accuracy: 0.7563\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.5305 - categorical_accuracy: 0.7797 - val_loss: 1.2151 - val_categorical_accuracy: 0.7688\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.5609 - categorical_accuracy: 0.7608 - val_loss: 1.1774 - val_categorical_accuracy: 0.7812\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.5713 - categorical_accuracy: 0.7514 - val_loss: 1.1688 - val_categorical_accuracy: 0.7656\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.5286 - categorical_accuracy: 0.7743 - val_loss: 1.2616 - val_categorical_accuracy: 0.7531\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.5319 - categorical_accuracy: 0.7757 - val_loss: 1.3252 - val_categorical_accuracy: 0.7672\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.5113 - categorical_accuracy: 0.7730 - val_loss: 1.3449 - val_categorical_accuracy: 0.7703\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.5044 - categorical_accuracy: 0.7770 - val_loss: 1.3245 - val_categorical_accuracy: 0.7797\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.4996 - categorical_accuracy: 0.7743 - val_loss: 1.3567 - val_categorical_accuracy: 0.7750\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.5142 - categorical_accuracy: 0.7581 - val_loss: 1.3080 - val_categorical_accuracy: 0.7406\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.4871 - categorical_accuracy: 0.7838 - val_loss: 1.5235 - val_categorical_accuracy: 0.7672\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.5212 - categorical_accuracy: 0.7635 - val_loss: 1.3010 - val_categorical_accuracy: 0.7609\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.5396 - categorical_accuracy: 0.7500 - val_loss: 1.3351 - val_categorical_accuracy: 0.7594\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.5053 - categorical_accuracy: 0.7878 - val_loss: 1.2840 - val_categorical_accuracy: 0.7734\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.5068 - categorical_accuracy: 0.7716 - val_loss: 1.3371 - val_categorical_accuracy: 0.7563\n",
      "Training slp16 (8/14)...\n",
      "23/23 [==============================] - 0s 9ms/step - loss: 1.2659 - categorical_accuracy: 0.5889 - val_loss: 0.6614 - val_categorical_accuracy: 0.7906\n",
      "23/23 [==============================] - 0s 9ms/step - loss: 0.8293 - categorical_accuracy: 0.6903 - val_loss: 0.6017 - val_categorical_accuracy: 0.8078\n",
      "23/23 [==============================] - 0s 9ms/step - loss: 0.7204 - categorical_accuracy: 0.7153 - val_loss: 0.6525 - val_categorical_accuracy: 0.7969\n",
      "23/23 [==============================] - 0s 9ms/step - loss: 0.7121 - categorical_accuracy: 0.7278 - val_loss: 0.7086 - val_categorical_accuracy: 0.7969\n",
      "23/23 [==============================] - 0s 9ms/step - loss: 0.6686 - categorical_accuracy: 0.7347 - val_loss: 0.7670 - val_categorical_accuracy: 0.7906\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 0.6646 - categorical_accuracy: 0.7389 - val_loss: 0.7751 - val_categorical_accuracy: 0.7953\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 0.6257 - categorical_accuracy: 0.7556 - val_loss: 0.8002 - val_categorical_accuracy: 0.7906\n",
      "23/23 [==============================] - 0s 9ms/step - loss: 0.6410 - categorical_accuracy: 0.7375 - val_loss: 0.8153 - val_categorical_accuracy: 0.7953\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 0.6209 - categorical_accuracy: 0.7556 - val_loss: 0.8296 - val_categorical_accuracy: 0.7953\n",
      "23/23 [==============================] - 0s 9ms/step - loss: 0.6125 - categorical_accuracy: 0.7556 - val_loss: 0.8078 - val_categorical_accuracy: 0.8016\n",
      "23/23 [==============================] - 0s 9ms/step - loss: 0.5945 - categorical_accuracy: 0.7583 - val_loss: 0.8859 - val_categorical_accuracy: 0.7969\n",
      "23/23 [==============================] - 0s 9ms/step - loss: 0.5919 - categorical_accuracy: 0.7722 - val_loss: 0.9324 - val_categorical_accuracy: 0.7906\n",
      "23/23 [==============================] - 0s 9ms/step - loss: 0.5886 - categorical_accuracy: 0.7597 - val_loss: 0.9782 - val_categorical_accuracy: 0.7922\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 0.5863 - categorical_accuracy: 0.7653 - val_loss: 0.9288 - val_categorical_accuracy: 0.7953\n",
      "23/23 [==============================] - 0s 9ms/step - loss: 0.5942 - categorical_accuracy: 0.7722 - val_loss: 0.9524 - val_categorical_accuracy: 0.7953\n",
      "23/23 [==============================] - 0s 9ms/step - loss: 0.5640 - categorical_accuracy: 0.7708 - val_loss: 0.8787 - val_categorical_accuracy: 0.8000\n",
      "23/23 [==============================] - 0s 9ms/step - loss: 0.5685 - categorical_accuracy: 0.7597 - val_loss: 0.8692 - val_categorical_accuracy: 0.7906\n",
      "23/23 [==============================] - 0s 9ms/step - loss: 0.5949 - categorical_accuracy: 0.7750 - val_loss: 0.8294 - val_categorical_accuracy: 0.8062\n",
      "23/23 [==============================] - 0s 9ms/step - loss: 0.5483 - categorical_accuracy: 0.7722 - val_loss: 0.8953 - val_categorical_accuracy: 0.7937\n",
      "23/23 [==============================] - 0s 9ms/step - loss: 0.5364 - categorical_accuracy: 0.7875 - val_loss: 0.9175 - val_categorical_accuracy: 0.7906\n",
      "23/23 [==============================] - 0s 9ms/step - loss: 0.5151 - categorical_accuracy: 0.7847 - val_loss: 0.9872 - val_categorical_accuracy: 0.7875\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 0.5491 - categorical_accuracy: 0.7764 - val_loss: 0.8748 - val_categorical_accuracy: 0.8031\n",
      "23/23 [==============================] - 0s 9ms/step - loss: 0.5492 - categorical_accuracy: 0.7861 - val_loss: 0.9270 - val_categorical_accuracy: 0.7969\n",
      "23/23 [==============================] - 0s 9ms/step - loss: 0.5268 - categorical_accuracy: 0.7806 - val_loss: 0.8937 - val_categorical_accuracy: 0.7922\n",
      "23/23 [==============================] - 0s 9ms/step - loss: 0.5265 - categorical_accuracy: 0.7792 - val_loss: 0.9231 - val_categorical_accuracy: 0.7937\n",
      "23/23 [==============================] - 0s 12ms/step - loss: 0.5240 - categorical_accuracy: 0.7819 - val_loss: 0.9217 - val_categorical_accuracy: 0.7891\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 0s 11ms/step - loss: 0.5046 - categorical_accuracy: 0.8042 - val_loss: 0.9097 - val_categorical_accuracy: 0.7922\n",
      "23/23 [==============================] - 0s 9ms/step - loss: 0.4981 - categorical_accuracy: 0.7903 - val_loss: 0.9377 - val_categorical_accuracy: 0.7969\n",
      "23/23 [==============================] - 0s 9ms/step - loss: 0.4853 - categorical_accuracy: 0.8042 - val_loss: 0.9218 - val_categorical_accuracy: 0.7906\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 0.4777 - categorical_accuracy: 0.8028 - val_loss: 1.0365 - val_categorical_accuracy: 0.7812\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 0.4532 - categorical_accuracy: 0.8167 - val_loss: 0.9801 - val_categorical_accuracy: 0.7875\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 0.4818 - categorical_accuracy: 0.8042 - val_loss: 0.9934 - val_categorical_accuracy: 0.7906\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 0.4843 - categorical_accuracy: 0.7861 - val_loss: 0.9783 - val_categorical_accuracy: 0.7922\n",
      "23/23 [==============================] - 0s 9ms/step - loss: 0.4753 - categorical_accuracy: 0.8014 - val_loss: 0.9805 - val_categorical_accuracy: 0.7844\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 0.4720 - categorical_accuracy: 0.8000 - val_loss: 1.1048 - val_categorical_accuracy: 0.7906\n",
      "23/23 [==============================] - 0s 12ms/step - loss: 0.4964 - categorical_accuracy: 0.8014 - val_loss: 0.9596 - val_categorical_accuracy: 0.7953\n",
      "23/23 [==============================] - 0s 9ms/step - loss: 0.4671 - categorical_accuracy: 0.8125 - val_loss: 1.0955 - val_categorical_accuracy: 0.7797\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 0.4471 - categorical_accuracy: 0.8236 - val_loss: 1.1048 - val_categorical_accuracy: 0.7812\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 0.4558 - categorical_accuracy: 0.8153 - val_loss: 0.9962 - val_categorical_accuracy: 0.7891\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 0.4361 - categorical_accuracy: 0.8167 - val_loss: 1.0323 - val_categorical_accuracy: 0.7844\n",
      "23/23 [==============================] - 0s 9ms/step - loss: 0.4078 - categorical_accuracy: 0.8444 - val_loss: 1.0820 - val_categorical_accuracy: 0.7922\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 0.4341 - categorical_accuracy: 0.8125 - val_loss: 1.1117 - val_categorical_accuracy: 0.7688\n",
      "23/23 [==============================] - 0s 9ms/step - loss: 0.3934 - categorical_accuracy: 0.8347 - val_loss: 1.1049 - val_categorical_accuracy: 0.7844\n",
      "23/23 [==============================] - 0s 9ms/step - loss: 0.4267 - categorical_accuracy: 0.8236 - val_loss: 1.1985 - val_categorical_accuracy: 0.7797\n",
      "23/23 [==============================] - 0s 9ms/step - loss: 0.4629 - categorical_accuracy: 0.8125 - val_loss: 1.0922 - val_categorical_accuracy: 0.7844\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 0.4121 - categorical_accuracy: 0.8292 - val_loss: 1.1096 - val_categorical_accuracy: 0.7969\n",
      "23/23 [==============================] - 0s 9ms/step - loss: 0.4111 - categorical_accuracy: 0.8361 - val_loss: 1.1294 - val_categorical_accuracy: 0.7766\n",
      "23/23 [==============================] - 0s 9ms/step - loss: 0.4192 - categorical_accuracy: 0.8361 - val_loss: 1.1834 - val_categorical_accuracy: 0.7844\n",
      "23/23 [==============================] - 0s 9ms/step - loss: 0.4173 - categorical_accuracy: 0.8222 - val_loss: 1.1437 - val_categorical_accuracy: 0.7812\n",
      "23/23 [==============================] - 0s 9ms/step - loss: 0.4046 - categorical_accuracy: 0.8264 - val_loss: 1.1742 - val_categorical_accuracy: 0.7797\n",
      "Training slp60 (9/14)...\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 1.4343 - categorical_accuracy: 0.5718 - val_loss: 1.1601 - val_categorical_accuracy: 0.6062\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 0.8204 - categorical_accuracy: 0.6958 - val_loss: 1.1396 - val_categorical_accuracy: 0.6078\n",
      "23/23 [==============================] - 0s 9ms/step - loss: 0.7124 - categorical_accuracy: 0.7408 - val_loss: 0.9890 - val_categorical_accuracy: 0.6281\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 0.6754 - categorical_accuracy: 0.7634 - val_loss: 1.0026 - val_categorical_accuracy: 0.6484\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 0.6670 - categorical_accuracy: 0.7718 - val_loss: 1.0007 - val_categorical_accuracy: 0.6594\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 0.6505 - categorical_accuracy: 0.7577 - val_loss: 0.9362 - val_categorical_accuracy: 0.7125\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 0.6351 - categorical_accuracy: 0.7761 - val_loss: 0.9850 - val_categorical_accuracy: 0.7375\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 0.5828 - categorical_accuracy: 0.7845 - val_loss: 1.0293 - val_categorical_accuracy: 0.7469\n",
      "23/23 [==============================] - 0s 9ms/step - loss: 0.6181 - categorical_accuracy: 0.7775 - val_loss: 1.0374 - val_categorical_accuracy: 0.7484\n",
      "23/23 [==============================] - 0s 9ms/step - loss: 0.6099 - categorical_accuracy: 0.7803 - val_loss: 1.0363 - val_categorical_accuracy: 0.7453\n",
      "23/23 [==============================] - 0s 9ms/step - loss: 0.5822 - categorical_accuracy: 0.7817 - val_loss: 1.0287 - val_categorical_accuracy: 0.7547\n",
      "23/23 [==============================] - 0s 9ms/step - loss: 0.5813 - categorical_accuracy: 0.7831 - val_loss: 1.0197 - val_categorical_accuracy: 0.7703\n",
      "23/23 [==============================] - 0s 9ms/step - loss: 0.5918 - categorical_accuracy: 0.7845 - val_loss: 1.0449 - val_categorical_accuracy: 0.7609\n",
      "23/23 [==============================] - 0s 9ms/step - loss: 0.5694 - categorical_accuracy: 0.7930 - val_loss: 1.1159 - val_categorical_accuracy: 0.7719\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 0.5710 - categorical_accuracy: 0.7845 - val_loss: 1.1377 - val_categorical_accuracy: 0.7547\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 0.5326 - categorical_accuracy: 0.8070 - val_loss: 1.0778 - val_categorical_accuracy: 0.7750\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 0.5550 - categorical_accuracy: 0.7859 - val_loss: 1.0478 - val_categorical_accuracy: 0.7719\n",
      "23/23 [==============================] - 0s 13ms/step - loss: 0.5353 - categorical_accuracy: 0.8014 - val_loss: 1.0405 - val_categorical_accuracy: 0.7734\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 0.5318 - categorical_accuracy: 0.7972 - val_loss: 1.2718 - val_categorical_accuracy: 0.7594\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 0.5411 - categorical_accuracy: 0.8028 - val_loss: 1.1035 - val_categorical_accuracy: 0.7750\n",
      "23/23 [==============================] - 0s 9ms/step - loss: 0.5396 - categorical_accuracy: 0.8127 - val_loss: 1.1330 - val_categorical_accuracy: 0.7734\n",
      "23/23 [==============================] - 0s 13ms/step - loss: 0.5060 - categorical_accuracy: 0.8127 - val_loss: 1.2757 - val_categorical_accuracy: 0.7672\n",
      "23/23 [==============================] - 0s 9ms/step - loss: 0.5284 - categorical_accuracy: 0.8042 - val_loss: 1.3906 - val_categorical_accuracy: 0.7609\n",
      "23/23 [==============================] - 0s 12ms/step - loss: 0.5153 - categorical_accuracy: 0.8042 - val_loss: 1.2255 - val_categorical_accuracy: 0.7641\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.5062 - categorical_accuracy: 0.8070 - val_loss: 1.2913 - val_categorical_accuracy: 0.7719\n",
      "23/23 [==============================] - 0s 12ms/step - loss: 0.4866 - categorical_accuracy: 0.8254 - val_loss: 1.2353 - val_categorical_accuracy: 0.7750\n",
      "23/23 [==============================] - 0s 13ms/step - loss: 0.4901 - categorical_accuracy: 0.8056 - val_loss: 1.2136 - val_categorical_accuracy: 0.7750\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.4678 - categorical_accuracy: 0.8211 - val_loss: 1.4668 - val_categorical_accuracy: 0.7609\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 0.4995 - categorical_accuracy: 0.8028 - val_loss: 1.4931 - val_categorical_accuracy: 0.7703\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 0s 11ms/step - loss: 0.4939 - categorical_accuracy: 0.8099 - val_loss: 1.4115 - val_categorical_accuracy: 0.7578\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 0.4794 - categorical_accuracy: 0.8113 - val_loss: 1.5431 - val_categorical_accuracy: 0.7609\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 0.4617 - categorical_accuracy: 0.7986 - val_loss: 1.4382 - val_categorical_accuracy: 0.7781\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 0.4694 - categorical_accuracy: 0.8197 - val_loss: 1.4932 - val_categorical_accuracy: 0.7703\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 0.4570 - categorical_accuracy: 0.8225 - val_loss: 1.5433 - val_categorical_accuracy: 0.7734\n",
      "23/23 [==============================] - 0s 9ms/step - loss: 0.4351 - categorical_accuracy: 0.8338 - val_loss: 1.5579 - val_categorical_accuracy: 0.7688\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 0.4665 - categorical_accuracy: 0.8380 - val_loss: 1.6171 - val_categorical_accuracy: 0.7672\n",
      "23/23 [==============================] - 0s 9ms/step - loss: 0.4121 - categorical_accuracy: 0.8366 - val_loss: 1.6061 - val_categorical_accuracy: 0.7609\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 0.4637 - categorical_accuracy: 0.8296 - val_loss: 1.6038 - val_categorical_accuracy: 0.7734\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 0.4604 - categorical_accuracy: 0.8070 - val_loss: 1.4284 - val_categorical_accuracy: 0.7766\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 0.4445 - categorical_accuracy: 0.8338 - val_loss: 1.7159 - val_categorical_accuracy: 0.7563\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 0.4034 - categorical_accuracy: 0.8380 - val_loss: 1.6685 - val_categorical_accuracy: 0.7609\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 0.4367 - categorical_accuracy: 0.8239 - val_loss: 1.4711 - val_categorical_accuracy: 0.7672\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 0.4032 - categorical_accuracy: 0.8423 - val_loss: 1.7883 - val_categorical_accuracy: 0.7594\n",
      "23/23 [==============================] - 0s 9ms/step - loss: 0.4609 - categorical_accuracy: 0.8183 - val_loss: 1.5994 - val_categorical_accuracy: 0.7703\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 0.4156 - categorical_accuracy: 0.8352 - val_loss: 1.6063 - val_categorical_accuracy: 0.7719\n",
      "23/23 [==============================] - 0s 9ms/step - loss: 0.4333 - categorical_accuracy: 0.8408 - val_loss: 1.7304 - val_categorical_accuracy: 0.7703\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 0.4108 - categorical_accuracy: 0.8296 - val_loss: 1.7698 - val_categorical_accuracy: 0.7844\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 0.4088 - categorical_accuracy: 0.8352 - val_loss: 1.7173 - val_categorical_accuracy: 0.7719\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 0.4077 - categorical_accuracy: 0.8296 - val_loss: 1.7965 - val_categorical_accuracy: 0.7750\n",
      "23/23 [==============================] - 0s 9ms/step - loss: 0.3834 - categorical_accuracy: 0.8465 - val_loss: 1.7114 - val_categorical_accuracy: 0.7844\n",
      "Training slp02a (10/14)...\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 2.7151 - categorical_accuracy: 0.4389 - val_loss: 1.1746 - val_categorical_accuracy: 0.6547\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.9937 - categorical_accuracy: 0.7139 - val_loss: 0.8531 - val_categorical_accuracy: 0.6938\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.8968 - categorical_accuracy: 0.7194 - val_loss: 0.9015 - val_categorical_accuracy: 0.7250\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.7820 - categorical_accuracy: 0.7694 - val_loss: 0.8919 - val_categorical_accuracy: 0.7297\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.7475 - categorical_accuracy: 0.7778 - val_loss: 1.1334 - val_categorical_accuracy: 0.6531\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.6784 - categorical_accuracy: 0.8111 - val_loss: 1.0237 - val_categorical_accuracy: 0.7328\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.6467 - categorical_accuracy: 0.7944 - val_loss: 0.9690 - val_categorical_accuracy: 0.7656\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.6581 - categorical_accuracy: 0.7917 - val_loss: 0.9646 - val_categorical_accuracy: 0.7484\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.6155 - categorical_accuracy: 0.8194 - val_loss: 0.9097 - val_categorical_accuracy: 0.7750\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.6004 - categorical_accuracy: 0.8167 - val_loss: 0.9444 - val_categorical_accuracy: 0.7766\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.5847 - categorical_accuracy: 0.8194 - val_loss: 1.0512 - val_categorical_accuracy: 0.7563\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.5678 - categorical_accuracy: 0.8083 - val_loss: 1.0891 - val_categorical_accuracy: 0.7516\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.5747 - categorical_accuracy: 0.8167 - val_loss: 1.1132 - val_categorical_accuracy: 0.7672\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.5527 - categorical_accuracy: 0.8194 - val_loss: 1.1243 - val_categorical_accuracy: 0.7375\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.5484 - categorical_accuracy: 0.8167 - val_loss: 1.0855 - val_categorical_accuracy: 0.7688\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.5584 - categorical_accuracy: 0.8222 - val_loss: 1.1761 - val_categorical_accuracy: 0.7578\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.5329 - categorical_accuracy: 0.8250 - val_loss: 1.0837 - val_categorical_accuracy: 0.7750\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.5045 - categorical_accuracy: 0.8444 - val_loss: 1.2371 - val_categorical_accuracy: 0.6984\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.4910 - categorical_accuracy: 0.8333 - val_loss: 1.3445 - val_categorical_accuracy: 0.7141\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.4996 - categorical_accuracy: 0.8333 - val_loss: 1.2030 - val_categorical_accuracy: 0.7375\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.4601 - categorical_accuracy: 0.8528 - val_loss: 1.2517 - val_categorical_accuracy: 0.7344\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.4927 - categorical_accuracy: 0.8444 - val_loss: 1.2522 - val_categorical_accuracy: 0.7328\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.4856 - categorical_accuracy: 0.8306 - val_loss: 1.2815 - val_categorical_accuracy: 0.7422\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.4308 - categorical_accuracy: 0.8611 - val_loss: 1.4163 - val_categorical_accuracy: 0.7094\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.4406 - categorical_accuracy: 0.8472 - val_loss: 1.2085 - val_categorical_accuracy: 0.7188\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.4269 - categorical_accuracy: 0.8333 - val_loss: 1.4138 - val_categorical_accuracy: 0.6969\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.4437 - categorical_accuracy: 0.8472 - val_loss: 1.3746 - val_categorical_accuracy: 0.6828\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.4504 - categorical_accuracy: 0.8417 - val_loss: 1.5847 - val_categorical_accuracy: 0.6547\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.4303 - categorical_accuracy: 0.8389 - val_loss: 1.5358 - val_categorical_accuracy: 0.6469\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.4266 - categorical_accuracy: 0.8417 - val_loss: 1.5138 - val_categorical_accuracy: 0.6438\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.3868 - categorical_accuracy: 0.8667 - val_loss: 1.3389 - val_categorical_accuracy: 0.7281\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.3906 - categorical_accuracy: 0.8722 - val_loss: 1.5170 - val_categorical_accuracy: 0.7250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 0s 12ms/step - loss: 0.4265 - categorical_accuracy: 0.8500 - val_loss: 1.7008 - val_categorical_accuracy: 0.6047\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.3845 - categorical_accuracy: 0.8667 - val_loss: 1.5213 - val_categorical_accuracy: 0.6797\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.3929 - categorical_accuracy: 0.8639 - val_loss: 1.5255 - val_categorical_accuracy: 0.6703\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.3937 - categorical_accuracy: 0.8583 - val_loss: 1.6799 - val_categorical_accuracy: 0.6594\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.3472 - categorical_accuracy: 0.8722 - val_loss: 1.7081 - val_categorical_accuracy: 0.6453\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.3718 - categorical_accuracy: 0.8694 - val_loss: 1.7624 - val_categorical_accuracy: 0.6422\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.3690 - categorical_accuracy: 0.8472 - val_loss: 1.7341 - val_categorical_accuracy: 0.6438\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.3734 - categorical_accuracy: 0.8556 - val_loss: 1.6607 - val_categorical_accuracy: 0.6953\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.3599 - categorical_accuracy: 0.8694 - val_loss: 1.5887 - val_categorical_accuracy: 0.7016\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.3775 - categorical_accuracy: 0.8500 - val_loss: 1.5808 - val_categorical_accuracy: 0.6969\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.3521 - categorical_accuracy: 0.8611 - val_loss: 1.5589 - val_categorical_accuracy: 0.6969\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.3426 - categorical_accuracy: 0.8806 - val_loss: 1.6565 - val_categorical_accuracy: 0.6672\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.3250 - categorical_accuracy: 0.8833 - val_loss: 1.8067 - val_categorical_accuracy: 0.7156\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.3755 - categorical_accuracy: 0.8806 - val_loss: 1.5392 - val_categorical_accuracy: 0.7203\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.3471 - categorical_accuracy: 0.8722 - val_loss: 1.6738 - val_categorical_accuracy: 0.7063\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.3449 - categorical_accuracy: 0.8806 - val_loss: 1.8017 - val_categorical_accuracy: 0.6922\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.4000 - categorical_accuracy: 0.8417 - val_loss: 1.6434 - val_categorical_accuracy: 0.7047\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.3515 - categorical_accuracy: 0.8833 - val_loss: 1.6099 - val_categorical_accuracy: 0.7078\n",
      "Training slp59 (11/14)...\n",
      "15/15 [==============================] - 1s 10ms/step - loss: 1.8264 - categorical_accuracy: 0.4833 - val_loss: 0.8050 - val_categorical_accuracy: 0.6812\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 1.0094 - categorical_accuracy: 0.6042 - val_loss: 0.7585 - val_categorical_accuracy: 0.7141\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.9233 - categorical_accuracy: 0.6500 - val_loss: 0.6739 - val_categorical_accuracy: 0.7672\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.8403 - categorical_accuracy: 0.6812 - val_loss: 0.6856 - val_categorical_accuracy: 0.7781\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.8129 - categorical_accuracy: 0.6833 - val_loss: 0.6707 - val_categorical_accuracy: 0.7672\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.7923 - categorical_accuracy: 0.7021 - val_loss: 0.6509 - val_categorical_accuracy: 0.7812\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.8142 - categorical_accuracy: 0.6938 - val_loss: 0.6559 - val_categorical_accuracy: 0.7688\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.7807 - categorical_accuracy: 0.7063 - val_loss: 0.6411 - val_categorical_accuracy: 0.7734\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.7750 - categorical_accuracy: 0.7063 - val_loss: 0.6545 - val_categorical_accuracy: 0.7703\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.7575 - categorical_accuracy: 0.7042 - val_loss: 0.6696 - val_categorical_accuracy: 0.7719\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.7109 - categorical_accuracy: 0.7104 - val_loss: 0.6462 - val_categorical_accuracy: 0.7766\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.7320 - categorical_accuracy: 0.7167 - val_loss: 0.6577 - val_categorical_accuracy: 0.7797\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.7232 - categorical_accuracy: 0.7104 - val_loss: 0.6257 - val_categorical_accuracy: 0.7859\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.7601 - categorical_accuracy: 0.7083 - val_loss: 0.6554 - val_categorical_accuracy: 0.7750\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.6999 - categorical_accuracy: 0.7229 - val_loss: 0.6358 - val_categorical_accuracy: 0.7797\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.7042 - categorical_accuracy: 0.7125 - val_loss: 0.6674 - val_categorical_accuracy: 0.7797\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.7000 - categorical_accuracy: 0.7229 - val_loss: 0.6698 - val_categorical_accuracy: 0.7828\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.6975 - categorical_accuracy: 0.7083 - val_loss: 0.6834 - val_categorical_accuracy: 0.7750\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.6969 - categorical_accuracy: 0.7208 - val_loss: 0.6718 - val_categorical_accuracy: 0.7859\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.6686 - categorical_accuracy: 0.7208 - val_loss: 0.6843 - val_categorical_accuracy: 0.7828\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.6968 - categorical_accuracy: 0.6979 - val_loss: 0.6936 - val_categorical_accuracy: 0.7750\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.6573 - categorical_accuracy: 0.7229 - val_loss: 0.6928 - val_categorical_accuracy: 0.7828\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.6505 - categorical_accuracy: 0.7271 - val_loss: 0.7005 - val_categorical_accuracy: 0.7797\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.6526 - categorical_accuracy: 0.7250 - val_loss: 0.7001 - val_categorical_accuracy: 0.7781\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.6448 - categorical_accuracy: 0.7479 - val_loss: 0.7111 - val_categorical_accuracy: 0.7766\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.6223 - categorical_accuracy: 0.7292 - val_loss: 0.7256 - val_categorical_accuracy: 0.7719\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.6231 - categorical_accuracy: 0.7354 - val_loss: 0.7302 - val_categorical_accuracy: 0.7656\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.6155 - categorical_accuracy: 0.7396 - val_loss: 0.7511 - val_categorical_accuracy: 0.7516\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.5918 - categorical_accuracy: 0.7542 - val_loss: 0.7780 - val_categorical_accuracy: 0.7375\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.6257 - categorical_accuracy: 0.7271 - val_loss: 0.7556 - val_categorical_accuracy: 0.7594\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.6262 - categorical_accuracy: 0.7437 - val_loss: 0.7284 - val_categorical_accuracy: 0.7531\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.6211 - categorical_accuracy: 0.7437 - val_loss: 0.7788 - val_categorical_accuracy: 0.7469\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.6090 - categorical_accuracy: 0.7542 - val_loss: 0.7390 - val_categorical_accuracy: 0.7594\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.5956 - categorical_accuracy: 0.7583 - val_loss: 0.7694 - val_categorical_accuracy: 0.7359\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.6100 - categorical_accuracy: 0.7458 - val_loss: 0.7664 - val_categorical_accuracy: 0.7406\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 0s 11ms/step - loss: 0.5782 - categorical_accuracy: 0.7521 - val_loss: 0.7563 - val_categorical_accuracy: 0.7547\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.5594 - categorical_accuracy: 0.7375 - val_loss: 0.8353 - val_categorical_accuracy: 0.7219\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.5925 - categorical_accuracy: 0.7312 - val_loss: 0.8003 - val_categorical_accuracy: 0.7359\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.5696 - categorical_accuracy: 0.7500 - val_loss: 0.7774 - val_categorical_accuracy: 0.7484\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.5749 - categorical_accuracy: 0.7604 - val_loss: 0.8794 - val_categorical_accuracy: 0.6938\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.6215 - categorical_accuracy: 0.7292 - val_loss: 0.8147 - val_categorical_accuracy: 0.7078\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.5979 - categorical_accuracy: 0.7417 - val_loss: 0.8316 - val_categorical_accuracy: 0.7078\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.5686 - categorical_accuracy: 0.7708 - val_loss: 0.7872 - val_categorical_accuracy: 0.7453\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.5593 - categorical_accuracy: 0.7729 - val_loss: 0.8038 - val_categorical_accuracy: 0.7188\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.5363 - categorical_accuracy: 0.7750 - val_loss: 0.8449 - val_categorical_accuracy: 0.6969\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.5951 - categorical_accuracy: 0.7354 - val_loss: 0.8270 - val_categorical_accuracy: 0.7437\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.5434 - categorical_accuracy: 0.7729 - val_loss: 0.7761 - val_categorical_accuracy: 0.7609\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.5270 - categorical_accuracy: 0.7625 - val_loss: 0.8464 - val_categorical_accuracy: 0.7078\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.5333 - categorical_accuracy: 0.7771 - val_loss: 0.9097 - val_categorical_accuracy: 0.6734\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.5514 - categorical_accuracy: 0.7667 - val_loss: 0.8448 - val_categorical_accuracy: 0.7047\n",
      "Training slp02b (12/14)...\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.9628 - categorical_accuracy: 0.7444 - val_loss: 0.8184 - val_categorical_accuracy: 0.7281\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.7099 - categorical_accuracy: 0.7741 - val_loss: 0.7495 - val_categorical_accuracy: 0.7641\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.6385 - categorical_accuracy: 0.8037 - val_loss: 0.7426 - val_categorical_accuracy: 0.7734\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.5150 - categorical_accuracy: 0.8259 - val_loss: 0.7359 - val_categorical_accuracy: 0.7828\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.4909 - categorical_accuracy: 0.8481 - val_loss: 0.7484 - val_categorical_accuracy: 0.7891\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.4509 - categorical_accuracy: 0.8556 - val_loss: 0.7518 - val_categorical_accuracy: 0.7891\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.4639 - categorical_accuracy: 0.8556 - val_loss: 0.7648 - val_categorical_accuracy: 0.7797\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.4221 - categorical_accuracy: 0.8519 - val_loss: 0.7911 - val_categorical_accuracy: 0.7922\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.4089 - categorical_accuracy: 0.8519 - val_loss: 0.8182 - val_categorical_accuracy: 0.7781\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.3992 - categorical_accuracy: 0.8667 - val_loss: 0.8138 - val_categorical_accuracy: 0.7906\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.3897 - categorical_accuracy: 0.8926 - val_loss: 0.8152 - val_categorical_accuracy: 0.7812\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.3541 - categorical_accuracy: 0.8852 - val_loss: 0.8429 - val_categorical_accuracy: 0.7891\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.3381 - categorical_accuracy: 0.8704 - val_loss: 0.8890 - val_categorical_accuracy: 0.7906\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 0.3535 - categorical_accuracy: 0.8963 - val_loss: 0.8554 - val_categorical_accuracy: 0.7766\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.3150 - categorical_accuracy: 0.8963 - val_loss: 0.8941 - val_categorical_accuracy: 0.7797\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.3146 - categorical_accuracy: 0.8926 - val_loss: 0.8598 - val_categorical_accuracy: 0.7812\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 0.3124 - categorical_accuracy: 0.8889 - val_loss: 0.9096 - val_categorical_accuracy: 0.7734\n",
      "9/9 [==============================] - 0s 59ms/step - loss: 0.3023 - categorical_accuracy: 0.8926 - val_loss: 0.9109 - val_categorical_accuracy: 0.7906\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.3118 - categorical_accuracy: 0.9037 - val_loss: 0.9101 - val_categorical_accuracy: 0.7703\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.2909 - categorical_accuracy: 0.9000 - val_loss: 0.9340 - val_categorical_accuracy: 0.7750\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.2966 - categorical_accuracy: 0.8889 - val_loss: 0.9890 - val_categorical_accuracy: 0.7719\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.2932 - categorical_accuracy: 0.8889 - val_loss: 0.9769 - val_categorical_accuracy: 0.7766\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 0.2903 - categorical_accuracy: 0.8926 - val_loss: 0.9999 - val_categorical_accuracy: 0.7703\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 0.2588 - categorical_accuracy: 0.9111 - val_loss: 0.9290 - val_categorical_accuracy: 0.7875\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.3129 - categorical_accuracy: 0.8852 - val_loss: 0.9904 - val_categorical_accuracy: 0.7688\n",
      "9/9 [==============================] - 0s 17ms/step - loss: 0.2794 - categorical_accuracy: 0.8926 - val_loss: 0.9846 - val_categorical_accuracy: 0.7812\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 0.2603 - categorical_accuracy: 0.9000 - val_loss: 1.0132 - val_categorical_accuracy: 0.7719\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.2744 - categorical_accuracy: 0.9074 - val_loss: 0.9522 - val_categorical_accuracy: 0.7672\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 0.2914 - categorical_accuracy: 0.8889 - val_loss: 1.0121 - val_categorical_accuracy: 0.7453\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.2254 - categorical_accuracy: 0.9074 - val_loss: 1.0025 - val_categorical_accuracy: 0.7641\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.2511 - categorical_accuracy: 0.9148 - val_loss: 1.1179 - val_categorical_accuracy: 0.7484\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.2488 - categorical_accuracy: 0.9148 - val_loss: 1.0351 - val_categorical_accuracy: 0.7703\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.2401 - categorical_accuracy: 0.9037 - val_loss: 1.0394 - val_categorical_accuracy: 0.7688\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.2255 - categorical_accuracy: 0.9222 - val_loss: 1.0322 - val_categorical_accuracy: 0.7734\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.1968 - categorical_accuracy: 0.9333 - val_loss: 1.0147 - val_categorical_accuracy: 0.7844\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.2314 - categorical_accuracy: 0.9037 - val_loss: 1.1175 - val_categorical_accuracy: 0.7531\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.2125 - categorical_accuracy: 0.9296 - val_loss: 1.0302 - val_categorical_accuracy: 0.7859\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.2393 - categorical_accuracy: 0.9000 - val_loss: 1.1057 - val_categorical_accuracy: 0.7484\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 16ms/step - loss: 0.1697 - categorical_accuracy: 0.9259 - val_loss: 1.1348 - val_categorical_accuracy: 0.7516\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.2353 - categorical_accuracy: 0.9111 - val_loss: 1.1910 - val_categorical_accuracy: 0.7719\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.1896 - categorical_accuracy: 0.9296 - val_loss: 1.1165 - val_categorical_accuracy: 0.7719\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.1829 - categorical_accuracy: 0.9370 - val_loss: 1.1434 - val_categorical_accuracy: 0.7781\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 0.2346 - categorical_accuracy: 0.9111 - val_loss: 1.1362 - val_categorical_accuracy: 0.7781\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.1688 - categorical_accuracy: 0.9370 - val_loss: 1.1823 - val_categorical_accuracy: 0.7750\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.1917 - categorical_accuracy: 0.9222 - val_loss: 1.1996 - val_categorical_accuracy: 0.7828\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 0.1883 - categorical_accuracy: 0.9333 - val_loss: 1.2507 - val_categorical_accuracy: 0.7656\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.1777 - categorical_accuracy: 0.9296 - val_loss: 1.2576 - val_categorical_accuracy: 0.7656\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.1614 - categorical_accuracy: 0.9407 - val_loss: 1.2941 - val_categorical_accuracy: 0.7688\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.1681 - categorical_accuracy: 0.9444 - val_loss: 1.3090 - val_categorical_accuracy: 0.7641\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.1568 - categorical_accuracy: 0.9444 - val_loss: 1.3264 - val_categorical_accuracy: 0.7984\n",
      "Training slp14 (13/14)...\n",
      "23/23 [==============================] - 0s 9ms/step - loss: 1.3981 - categorical_accuracy: 0.5431 - val_loss: 0.9032 - val_categorical_accuracy: 0.7328\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 0.8793 - categorical_accuracy: 0.6375 - val_loss: 0.7978 - val_categorical_accuracy: 0.7609\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 0.8495 - categorical_accuracy: 0.6444 - val_loss: 0.8421 - val_categorical_accuracy: 0.7375\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 0.8371 - categorical_accuracy: 0.6736 - val_loss: 0.9155 - val_categorical_accuracy: 0.7609\n",
      "23/23 [==============================] - 0s 9ms/step - loss: 0.8128 - categorical_accuracy: 0.6472 - val_loss: 0.9116 - val_categorical_accuracy: 0.7547\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 0.7640 - categorical_accuracy: 0.6875 - val_loss: 0.9181 - val_categorical_accuracy: 0.7797\n",
      "23/23 [==============================] - 0s 9ms/step - loss: 0.7753 - categorical_accuracy: 0.6944 - val_loss: 0.9949 - val_categorical_accuracy: 0.7656\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 0.7474 - categorical_accuracy: 0.7000 - val_loss: 1.0136 - val_categorical_accuracy: 0.7766\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 0.7470 - categorical_accuracy: 0.6889 - val_loss: 0.9168 - val_categorical_accuracy: 0.7859\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 0.7608 - categorical_accuracy: 0.6931 - val_loss: 1.0260 - val_categorical_accuracy: 0.7766\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 0.7354 - categorical_accuracy: 0.7097 - val_loss: 1.0694 - val_categorical_accuracy: 0.7875\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 0.7476 - categorical_accuracy: 0.6861 - val_loss: 1.1322 - val_categorical_accuracy: 0.7688\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 0.7034 - categorical_accuracy: 0.7292 - val_loss: 1.1585 - val_categorical_accuracy: 0.7734\n",
      "23/23 [==============================] - 0s 9ms/step - loss: 0.7226 - categorical_accuracy: 0.6958 - val_loss: 1.1960 - val_categorical_accuracy: 0.7688\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 0.6792 - categorical_accuracy: 0.7153 - val_loss: 1.2206 - val_categorical_accuracy: 0.7688\n",
      "23/23 [==============================] - 0s 9ms/step - loss: 0.6837 - categorical_accuracy: 0.7431 - val_loss: 1.3787 - val_categorical_accuracy: 0.7641\n",
      "23/23 [==============================] - 0s 9ms/step - loss: 0.6799 - categorical_accuracy: 0.7292 - val_loss: 1.2812 - val_categorical_accuracy: 0.7828\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 0.7063 - categorical_accuracy: 0.7278 - val_loss: 1.3111 - val_categorical_accuracy: 0.7719\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 0.6629 - categorical_accuracy: 0.7194 - val_loss: 1.2677 - val_categorical_accuracy: 0.7766\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 0.6708 - categorical_accuracy: 0.7194 - val_loss: 1.3090 - val_categorical_accuracy: 0.7797\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 0.6457 - categorical_accuracy: 0.7375 - val_loss: 1.4246 - val_categorical_accuracy: 0.7750\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 0.6748 - categorical_accuracy: 0.7306 - val_loss: 1.3142 - val_categorical_accuracy: 0.7812\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 0.6393 - categorical_accuracy: 0.7403 - val_loss: 1.2764 - val_categorical_accuracy: 0.7688\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 0.6550 - categorical_accuracy: 0.7292 - val_loss: 1.3503 - val_categorical_accuracy: 0.7766\n",
      "23/23 [==============================] - 0s 9ms/step - loss: 0.6363 - categorical_accuracy: 0.7458 - val_loss: 1.2947 - val_categorical_accuracy: 0.7719\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 0.6450 - categorical_accuracy: 0.7444 - val_loss: 1.5176 - val_categorical_accuracy: 0.7578\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 0.6241 - categorical_accuracy: 0.7361 - val_loss: 1.4489 - val_categorical_accuracy: 0.7734\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 0.6384 - categorical_accuracy: 0.7181 - val_loss: 1.3948 - val_categorical_accuracy: 0.7734\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 0.6106 - categorical_accuracy: 0.7486 - val_loss: 1.4668 - val_categorical_accuracy: 0.7797\n",
      "23/23 [==============================] - 0s 9ms/step - loss: 0.6078 - categorical_accuracy: 0.7556 - val_loss: 1.3748 - val_categorical_accuracy: 0.7875\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 0.6236 - categorical_accuracy: 0.7375 - val_loss: 1.5418 - val_categorical_accuracy: 0.7734\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 0.6124 - categorical_accuracy: 0.7514 - val_loss: 1.5296 - val_categorical_accuracy: 0.7672\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 0.5874 - categorical_accuracy: 0.7528 - val_loss: 1.6004 - val_categorical_accuracy: 0.7672\n",
      "23/23 [==============================] - 0s 9ms/step - loss: 0.6067 - categorical_accuracy: 0.7486 - val_loss: 1.5733 - val_categorical_accuracy: 0.7719\n",
      "23/23 [==============================] - 0s 9ms/step - loss: 0.6006 - categorical_accuracy: 0.7528 - val_loss: 1.4848 - val_categorical_accuracy: 0.7797\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 0.6144 - categorical_accuracy: 0.7458 - val_loss: 1.5790 - val_categorical_accuracy: 0.7672\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 0.6208 - categorical_accuracy: 0.7306 - val_loss: 1.6409 - val_categorical_accuracy: 0.7437\n",
      "23/23 [==============================] - 0s 9ms/step - loss: 0.6434 - categorical_accuracy: 0.7486 - val_loss: 1.6894 - val_categorical_accuracy: 0.7406\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 0.5921 - categorical_accuracy: 0.7736 - val_loss: 1.7929 - val_categorical_accuracy: 0.7672\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 0.5884 - categorical_accuracy: 0.7639 - val_loss: 1.7635 - val_categorical_accuracy: 0.7609\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 0.5417 - categorical_accuracy: 0.7819 - val_loss: 1.7615 - val_categorical_accuracy: 0.7750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 0s 10ms/step - loss: 0.5889 - categorical_accuracy: 0.7611 - val_loss: 2.0192 - val_categorical_accuracy: 0.7297\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 0.5803 - categorical_accuracy: 0.7583 - val_loss: 1.8546 - val_categorical_accuracy: 0.7672\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 0.5402 - categorical_accuracy: 0.7958 - val_loss: 1.6753 - val_categorical_accuracy: 0.7719\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 0.5805 - categorical_accuracy: 0.7653 - val_loss: 1.7829 - val_categorical_accuracy: 0.7844\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 0.5446 - categorical_accuracy: 0.7944 - val_loss: 1.6157 - val_categorical_accuracy: 0.7547\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 0.5295 - categorical_accuracy: 0.7875 - val_loss: 1.6366 - val_categorical_accuracy: 0.7672\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 0.5548 - categorical_accuracy: 0.7722 - val_loss: 1.8145 - val_categorical_accuracy: 0.7625\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 0.5192 - categorical_accuracy: 0.7958 - val_loss: 1.8152 - val_categorical_accuracy: 0.7594\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 0.5495 - categorical_accuracy: 0.7750 - val_loss: 1.8588 - val_categorical_accuracy: 0.7797\n"
     ]
    }
   ],
   "source": [
    "train_acc = []\n",
    "valid_acc = []\n",
    "\n",
    "# Train the neural network\n",
    "epochs = 50\n",
    "\n",
    "inter_train = np.zeros(shape=(epochs, len(train_patients)))\n",
    "inter_valid = np.zeros(shape=(epochs, len(train_patients)))\n",
    "for i, patient_name in enumerate(train_patients):\n",
    "    print(\"Training {} ({}/{})...\".format(patient_name, i, len(train_patients)))\n",
    "    for epoch in range(epochs):\n",
    "        # Create training and validation dataset\n",
    "        train_data, train_labels = create_dataset(patient_name, diagnostic=False)\n",
    "        valid_data, valid_labels = create_dataset(valid_patients[0], diagnostic=False)\n",
    "        \n",
    "        # Convert to one-hot encoding\n",
    "        train_labels = utils.to_categorical(train_labels, num_classes=NUM_CLASSES)\n",
    "        valid_labels = utils.to_categorical(valid_labels, num_classes=NUM_CLASSES)\n",
    "\n",
    "        # Train model\n",
    "        history = model.fit(\n",
    "            x               = train_data,\n",
    "            y               = train_labels,\n",
    "            epochs          = 1,\n",
    "            validation_data = (\n",
    "                valid_data,\n",
    "                valid_labels\n",
    "            ),\n",
    "            callbacks       = [\n",
    "                tf.keras.callbacks.ReduceLROnPlateau(\n",
    "                    monitor='val_loss', \n",
    "                    factor=0.2,\n",
    "                    patience=5, min_lr=0.001\n",
    "                )\n",
    "            ],\n",
    "            verbose=1\n",
    "        )\n",
    "\n",
    "        # Append accuracies\n",
    "        inter_train[epoch][i] = history.history['categorical_accuracy'][0]\n",
    "        inter_valid[epoch][i] = history.history['val_categorical_accuracy'][0]\n",
    "\n",
    "train_acc = np.mean(inter_train, axis=1)\n",
    "valid_acc = np.mean(inter_valid, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x13ffffca0>"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Graph training accuracy\n",
    "plt.plot(train_acc, label='Training Accuracy')\n",
    "plt.plot(valid_acc, label='Validation Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim([0, 1])\n",
    "plt.legend(loc='lower right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (640, 10, 1, 1)\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 1.8588 - categorical_accuracy: 0.7797\n",
      "Testing accuracy = 77.97%\n"
     ]
    }
   ],
   "source": [
    "test_acc = []\n",
    "\n",
    "for patient_name in test_patients:\n",
    "    # Get test accuracy of the network\n",
    "    test_data, test_labels = create_dataset(patient_name, diagnostic=False)\n",
    "    pickle.dump(np.array(test_data), open(\"test_data.pkl\", \"wb\"))\n",
    "    pickle.dump(np.array(test_labels), open(\"test_labels.pkl\", \"wb\"))\n",
    "    print(\"shape:\", test_data.shape)\n",
    "    test_labels = utils.to_categorical(test_labels, num_classes=NUM_CLASSES)\n",
    "    _, acc = model.evaluate(test_data, test_labels)\n",
    "    test_acc.append(acc)\n",
    "    \n",
    "print(\"Testing accuracy = {:.2%}\".format(np.mean(test_acc)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Exporting Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_TF = 'model'\n",
    "MODEL_TFLITE = 'model.tflite'\n",
    "MODEL_TFLITE_MICRO = 'model.cc'\n",
    "\n",
    "model.save(MODEL_TF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "\n",
    "# Quantization\n",
    "def representative_dataset_gen():\n",
    "    for sample in train_data:\n",
    "        yield [np.expand_dims(sample, axis=0).astype(np.float32)]\n",
    "\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
    "converter.inference_input_type = tf.int8\n",
    "converter.inference_output_type = tf.int8\n",
    "converter.representative_dataset = representative_dataset_gen\n",
    "\n",
    "model_tflite = converter.convert()\n",
    "with open(MODEL_TFLITE, \"wb\") as f:\n",
    "    f.write(model_tflite)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!xxd -i {MODEL_TFLITE} > {MODEL_TFLITE_MICRO}\n",
    "\n",
    "REPLACE_TEXT = MODEL_TFLITE.replace('/', '_').replace('.', '_')\n",
    "!sed -i '' -e 's/'{REPLACE_TEXT}'/g_model/g' {MODEL_TFLITE_MICRO}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Rough Implementation",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
