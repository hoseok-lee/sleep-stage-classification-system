{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BnlLdtj3lHBl"
   },
   "source": [
    "Download database if database does not exist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "![ ! -d \"physionet.org\" ] && wget -r -N -c -np -q https://physionet.org/files/slpdb/1.0.0/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bn4kzr6KmE6B"
   },
   "source": [
    "Download libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BtOCDXRemGNN",
    "outputId": "3bef8850-c9d9-4779-d9d8-a2948f9e65bb",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mDEPRECATION: Configuring installation scheme with distutils config files is deprecated and will no longer work in the near future. If you are using a Homebrew or Linuxbrew Python, please see discussion at https://github.com/Homebrew/homebrew-core/issues/76621\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -atplotlib (/usr/local/lib/python3.9/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -atplotlib (/usr/local/lib/python3.9/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: pip in /usr/local/lib/python3.9/site-packages (22.0.4)\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -atplotlib (/usr/local/lib/python3.9/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mDEPRECATION: Configuring installation scheme with distutils config files is deprecated and will no longer work in the near future. If you are using a Homebrew or Linuxbrew Python, please see discussion at https://github.com/Homebrew/homebrew-core/issues/76621\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -atplotlib (/usr/local/lib/python3.9/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -atplotlib (/usr/local/lib/python3.9/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -atplotlib (/usr/local/lib/python3.9/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -atplotlib (/usr/local/lib/python3.9/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -atplotlib (/usr/local/lib/python3.9/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -atplotlib (/usr/local/lib/python3.9/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -atplotlib (/usr/local/lib/python3.9/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -atplotlib (/usr/local/lib/python3.9/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -atplotlib (/usr/local/lib/python3.9/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -atplotlib (/usr/local/lib/python3.9/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -atplotlib (/usr/local/lib/python3.9/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -atplotlib (/usr/local/lib/python3.9/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install --upgrade pip\n",
    "!{sys.executable} -m pip install -q wfdb tinymlgen --user\n",
    "!{sys.executable} -m pip install -q matplotlib==3.1.3 --user"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XTUxPlAylstP"
   },
   "source": [
    "Import libraries and set random seed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "lZt8rqnwluy1"
   },
   "outputs": [],
   "source": [
    "# For reading database\n",
    "import wfdb\n",
    "import os\n",
    "import copy\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "from scipy import signal\n",
    "from scipy.integrate import simps\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import models, layers\n",
    "from tensorflow.keras import utils\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "np.random.seed(1)\n",
    "tf.random.set_seed(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CP7JEBwSmfCj"
   },
   "source": [
    "## **1. Import Database**\n",
    "Accessing data and basic data processing.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "uBcKJYsz5jo5"
   },
   "outputs": [],
   "source": [
    "class PatientData (object):\n",
    "    ECG_signal = None\n",
    "    EEG_signal = None\n",
    "    sleep_stages = None\n",
    "\n",
    "    record_length = None\n",
    "    sampling_frequency = None\n",
    "\n",
    "    def __init__ (self, patient_name):\n",
    "        self.patient_name = patient_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "acnTzNBz3co0"
   },
   "outputs": [],
   "source": [
    "DATABASE_PATH = 'physionet.org/files/slpdb/1.0.0'\n",
    "\n",
    "with open(os.path.join(DATABASE_PATH, 'RECORDS'), 'r') as file:\n",
    "    PATIENT_NAMES = file.read().split('\\n')[:-1]\n",
    "  \n",
    "PATIENTS = {\n",
    "    patient_name: PatientData(patient_name)\n",
    "    for patient_name in PATIENT_NAMES\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "q4tscNYw7RCf"
   },
   "outputs": [],
   "source": [
    "# 0 Awake\n",
    "# 1 NREM stage 1\n",
    "# 2 NREM stage 2\n",
    "# 3 NREM stage 3 and 4\n",
    "# 4 REM\n",
    "# 5 Movement time (unknown)\n",
    "\n",
    "SLEEP_STAGES = {\n",
    "    \"W\": 0,\n",
    "    \"1\": 1,\n",
    "    \"2\": 2,\n",
    "    \"3\": 3,\n",
    "    \"4\": 3,\n",
    "    \"R\": 4,\n",
    "    \"M\": 5\n",
    "}\n",
    "\n",
    "NUM_CLASSES = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since annotations only have labels and the time at which they occur,\n",
    "# interpolate all the data so there's always a label at each time step\n",
    "def step_interpolation (data, locations, total_length):\n",
    "    step_interpolated_data = np.zeros(total_length)\n",
    "\n",
    "    for i in range(len(locations) - 1):\n",
    "        start_range = locations[i]\n",
    "        end_range = locations[i + 1]\n",
    "\n",
    "        # Convert string annotation into sleep stage\n",
    "        step_interpolated_data[(start_range - 1) : end_range] = SLEEP_STAGES[data[i][0]]\n",
    "\n",
    "    return step_interpolated_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "x15jx_LYmmA6"
   },
   "outputs": [],
   "source": [
    "for patient_name in PATIENT_NAMES:\n",
    "    patient = PATIENTS[patient_name]\n",
    "\n",
    "    # Retrieve raw signals and annotations\n",
    "    record_path = os.path.join(DATABASE_PATH, patient_name)\n",
    "    record = wfdb.io.rdrecord(record_path)\n",
    "    annotation = wfdb.rdann(record_path, extension='st')\n",
    "\n",
    "    # Sampling frequency\n",
    "    # This might differ for each record\n",
    "    patient.sampling_frequency = record.fs\n",
    "\n",
    "    # 0 ECG\n",
    "    # 1 BP\n",
    "    # 2 EEG\n",
    "    # 3 Resp (not available for all)\n",
    "    patient.ECG_signal = record.p_signal[:, 0]\n",
    "    patient.EEG_signal = record.p_signal[:, 2]\n",
    "    patient.record_length = record.sig_len\n",
    "\n",
    "    patient.sleep_stages = step_interpolation(annotation.aux_note, annotation.sample, patient.record_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DUsBEQGz7wL5",
    "outputId": "b45f5740-7388-456e-ff70-778b5f800c16"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.085 0.08  0.125 ... 0.23  0.235 0.225]\n",
      "[-0.03919129 -0.03888025 -0.03856921 ...  0.14727838  0.14681182\n",
      "  0.14261275]\n",
      "[3. 3. 3. ... 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "# Example patient\n",
    "patient_slp01a = PATIENTS['slp01a']\n",
    "print(patient_slp01a.ECG_signal)\n",
    "print(patient_slp01a.EEG_signal)\n",
    "print(patient_slp01a.sleep_stages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "G2eqrZjt0K4Z"
   },
   "outputs": [],
   "source": [
    "# Splitting the dataset into train, validation, test set\n",
    "# Will be split in terms of patients, not sleep data\n",
    "num_patients = len(PATIENTS)\n",
    "\n",
    "# Shuffle patients\n",
    "randomized_patients = copy.deepcopy(PATIENT_NAMES)\n",
    "np.random.shuffle(randomized_patients)\n",
    "\n",
    "# 80 / 10 / 10 split of 18 patients will be roughly 14 / 2 / 2\n",
    "# Don't need test_end, since it'll be until the end of data\n",
    "train_end = 14\n",
    "valid_end = train_end + 2\n",
    "\n",
    "# Split data using keys\n",
    "train_patients = randomized_patients[ : train_end]\n",
    "valid_patients = randomized_patients[train_end : valid_end]\n",
    "test_patients = randomized_patients[valid_end : ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set patients = ['slp14', 'slp02b', 'slp59', 'slp02a', 'slp60', 'slp16', 'slp61', 'slp03', 'slp01b', 'slp41', 'slp01a', 'slp67x', 'slp66', 'slp37']\n",
      "Validation set patients = ['slp32', 'slp48']\n",
      "Testing set patients = ['slp45', 'slp04']\n"
     ]
    }
   ],
   "source": [
    "print(\"Training set patients = {}\".format(train_patients))\n",
    "print(\"Validation set patients = {}\".format(valid_patients))\n",
    "print(\"Testing set patients = {}\".format(test_patients))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EYu2d3lFn33a"
   },
   "source": [
    "## **2. Building the Neural Network**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "eeg_bandwidths = {\n",
    "    \"delta\": (0.25, 4),\n",
    "    \"theta\": (4, 8),\n",
    "    \"alpha\": (8, 12),\n",
    "    \"sigma\": (12, 16),\n",
    "    \"beta\": (16, 40)\n",
    "}\n",
    "\n",
    "ecg_bandwidths = {\n",
    "    \"ulf\": (0, 0.003),\n",
    "    \"vlf\": (0.003, 0.04),\n",
    "    \"lf\": (0.04, 0.15),\n",
    "    \"hf\": (0.15, 0.4),\n",
    "    \"lf/hf\": (0.4, 1)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "D--JGvLr1E9b",
    "outputId": "b3cc854c-c876-4776-b148-750889344129"
   },
   "outputs": [],
   "source": [
    "def welch_relative_powers (bandwidths, signal, sf, nperseg, lfhf_ratio=False):\n",
    "    # Perform power spectral decomposition with Welch's method\n",
    "    freqs, psd = sp.signal.welch(signal, fs=sf, nperseg=nperseg)\n",
    "\n",
    "    # Frequency resolution\n",
    "    resolution = freqs[1] - freqs[0]\n",
    "\n",
    "    # Relative powers\n",
    "    relative_powers = []\n",
    "\n",
    "    # Calculate the relative powers given the power spectral decomposition\n",
    "    total_power = simps(psd, dx=resolution)\n",
    "    for band, (low, high) in bandwidths.items():\n",
    "        index = np.logical_and(freqs >= low, freqs < high)\n",
    "        power = simps(psd[index], dx=resolution)\n",
    "        rel_power = power / total_power\n",
    "        relative_powers.append(rel_power)\n",
    "        \n",
    "    # This will only be enabled for ECG\n",
    "    # This replaces the last relative power with the LF/HF ratio\n",
    "    if lfhf_ratio:\n",
    "        relative_powers[-1] = relative_powers[2] / relative_powers[3]\n",
    "        \n",
    "    return relative_powers\n",
    "\n",
    "\n",
    "\n",
    "def create_dataset (patient_name, window_size=30, diagnostic=False):\n",
    "    inputs = []\n",
    "    labels = []\n",
    "    \n",
    "    patient = PATIENTS[patient_name]\n",
    "    total_samples = patient.EEG_signal.shape[0]\n",
    "    sampling_frequency = patient.sampling_frequency\n",
    "\n",
    "    # Represents the number of samples (individual numbers) in one window of time (measured in seconds)\n",
    "    samples_per_window = int(window_size * sampling_frequency)\n",
    "\n",
    "    # Represents how many data points is generated after division with windows\n",
    "    # If the window size is larger, there will be less data points (but more samples per data point)\n",
    "    windows = np.round(total_samples / samples_per_window).astype(np.int64)\n",
    "\n",
    "\n",
    "\n",
    "    if diagnostic:\n",
    "        print(\"Gathering {} patient data...\".format(patient_name))\n",
    "        print(\"> Total number of samples = {}\".format(total_samples))\n",
    "        print(\"  Samples per window size of {} seconds = {}\".format(window_size, samples_per_window))\n",
    "        print(\"  Number of windows = {}\".format(windows))\n",
    "        print(\"  Number of batches for batch size {} = {}\".format(batch_size, batches))\n",
    "\n",
    "\n",
    "\n",
    "    for datum in range(windows):\n",
    "        '''\n",
    "        current_batch_inputs = []\n",
    "        current_batch_labels = []\n",
    "\n",
    "        for datum in range(batch_size):\n",
    "        '''\n",
    "        # Determine start and end of current batch\n",
    "        # Function assumes that batch sizes match the number of samples perfectly\n",
    "        start = (datum * samples_per_window)\n",
    "        end = (start + samples_per_window)\n",
    "\n",
    "        '''\n",
    "        EEG_MFCC = librosa.feature.melspectrogram(\n",
    "            y=patient.EEG_signal[start : end], \n",
    "            sr=patient.sampling_frequency)\n",
    "        ECG_MFCC = librosa.feature.melspectrogram(\n",
    "            y=patient.ECG_signal[start : end], \n",
    "            sr=patient.sampling_frequency)\n",
    "\n",
    "        sample = np.expand_dims(\n",
    "            np.stack([ EEG_MFCC, ECG_MFCC ], axis=2), \n",
    "            axis=0)\n",
    "        '''\n",
    "\n",
    "        # ORIGINAL \n",
    "        #EEG = patient.EEG_signal[start : end]\n",
    "        #ECG = patient.ECG_signal[start : end]\n",
    "\n",
    "        eeg = welch_relative_powers(\n",
    "            bandwidths = eeg_bandwidths,\n",
    "            signal     = patient.EEG_signal[start : end],\n",
    "            sf         = sampling_frequency,\n",
    "            nperseg    = samples_per_window\n",
    "        )\n",
    "        \n",
    "        ecg = welch_relative_powers(\n",
    "            bandwidths = ecg_bandwidths,\n",
    "            signal     = patient.ECG_signal[start : end],\n",
    "            sf         = sampling_frequency,\n",
    "            nperseg    = samples_per_window,\n",
    "            lfhf_ratio = True\n",
    "        )\n",
    "\n",
    "        '''\n",
    "        sample = [\n",
    "            patient.EEG_signal[start : end],\n",
    "            patient.ECG_signal[start : end]\n",
    "        ]\n",
    "        '''\n",
    "        sample = eeg + ecg\n",
    "        \n",
    "        # Only grab the label at the end of the current batch\n",
    "        # This is such that we're using all of the data in the current batch\n",
    "        # in order to predict the sleep stage by the end of the batch\n",
    "        sample_labels = patient.sleep_stages[end - 1]\n",
    "        '''\n",
    "            current_batch_inputs.append(sample)\n",
    "            current_batch_labels.append(sample_labels)\n",
    "        '''\n",
    "        inputs.append(sample)\n",
    "        labels.append(sample_labels)\n",
    "\n",
    "    return np.expand_dims(np.array(inputs), axis=(-1, -2)), np.expand_dims(np.array(labels), axis=(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inception layer\n",
    "# Three 1D convolution layers in parallel concatenate at the end\n",
    "# Left and right filter amounts can be modified\n",
    "class Inception1D (layers.Layer):\n",
    "\n",
    "    def __init__ (self, num_filter):\n",
    "        super(Inception1D, self).__init__()\n",
    "        \n",
    "        # Left-side convolution\n",
    "        self.left_conv = layers.Conv2D(\n",
    "            filters=num_filter, \n",
    "            kernel_size=(1, 1),\n",
    "            padding='same',\n",
    "            activation='relu'\n",
    "        )\n",
    "        \n",
    "        # Right convolution\n",
    "        self.right_conv = tf.keras.Sequential([\n",
    "            layers.Conv2D(\n",
    "                filters=num_filter,\n",
    "                kernel_size=(1, 1),\n",
    "                padding='same',\n",
    "                activation='relu'\n",
    "            ),\n",
    "            layers.Conv2D(\n",
    "                filters=num_filter,\n",
    "                kernel_size=(3, 1),\n",
    "                padding='same',\n",
    "                activation='relu'\n",
    "            )\n",
    "        ])\n",
    "        \n",
    "        # Pooling\n",
    "        self.pool = tf.keras.Sequential([\n",
    "            layers.MaxPooling2D(\n",
    "                pool_size=(2, 1),\n",
    "                strides=1,\n",
    "                padding='same'\n",
    "            ),\n",
    "            layers.Conv2D(\n",
    "                filters=num_filter,\n",
    "                kernel_size=(1, 1),\n",
    "                padding='same',\n",
    "                activation='relu'\n",
    "            )\n",
    "        ])\n",
    "        \n",
    "        \n",
    "        \n",
    "    def call (self, inputs, training=False):\n",
    "        left = self.left_conv(inputs)\n",
    "        right = self.right_conv(inputs)\n",
    "        pool = self.pool(inputs)\n",
    "        \n",
    "        x = layers.Concatenate()([left, right, pool])\n",
    "        if training:\n",
    "            x = layers.SpatialDropout2D(0.1)(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yo5vb_3VJXKC",
    "outputId": "31a97c49-f62c-47b2-b045-5c6be97fe94d"
   },
   "outputs": [],
   "source": [
    "class PCNN (tf.keras.Model):\n",
    "    \n",
    "    def __init__ (self):\n",
    "        super(PCNN, self).__init__()\n",
    "        \n",
    "        \n",
    "        \n",
    "    def build (self, input_shape):\n",
    "        self.base_cnn = tf.keras.Sequential([\n",
    "            Inception1D(16),\n",
    "            Inception1D(16),\n",
    "            layers.MaxPooling2D(\n",
    "                pool_size=(2, 1),\n",
    "                strides=1,\n",
    "                padding='same'\n",
    "            )\n",
    "        ])\n",
    "        \n",
    "        self.post_cnn = tf.keras.Sequential([\n",
    "            layers.Conv2D(\n",
    "                filters=128,\n",
    "                kernel_size=(3, 1),\n",
    "                padding='same',\n",
    "                activation='relu'\n",
    "            ),\n",
    "            layers.Conv2D(\n",
    "                filters=128,\n",
    "                kernel_size=(3, 1),\n",
    "                padding='same',\n",
    "                activation='relu'\n",
    "            ),\n",
    "            layers.Conv2D(\n",
    "                filters=128,\n",
    "                kernel_size=(3, 1),\n",
    "                padding='same',\n",
    "                activation='relu'\n",
    "            )\n",
    "        ])\n",
    "        \n",
    "        self.ANN = tf.keras.Sequential([\n",
    "            layers.Flatten(),\n",
    "            layers.Dense(64, activation='relu'),\n",
    "            layers.Dense(32, activation='relu'),\n",
    "            layers.Dense(NUM_CLASSES, activation='softmax')\n",
    "        ], name='ann_classifier')\n",
    "        \n",
    "        super(PCNN, self).build(input_shape)\n",
    "    \n",
    "    \n",
    "    \n",
    "    def call (self, inputs, training=False):\n",
    "        eeg = inputs[:,:5]\n",
    "        ecg = inputs[:,5:]\n",
    "        \n",
    "        \n",
    "        # Parallel convolutional networks\n",
    "        eeg = self.base_cnn(eeg)\n",
    "        ecg = self.base_cnn(ecg)\n",
    "        \n",
    "        eeg = self.post_cnn(eeg)\n",
    "        ecg = self.post_cnn(ecg)\n",
    "        \n",
    "        # Concatenate convolutional embedding\n",
    "        x = layers.Concatenate()([ eeg, ecg ])\n",
    "        \n",
    "        # Dropout layers\n",
    "        if training:\n",
    "            x = layers.Dropout(0.5)(x)\n",
    "        \n",
    "        # Fully-connected classifier\n",
    "        x = self.ANN(x)\n",
    "            \n",
    "        return x\n",
    "        \n",
    "\n",
    "\n",
    "model = PCNN()\n",
    "\n",
    "# Compile the model\n",
    "model.compile(\n",
    "    optimizer = tf.keras.optimizers.Adam(0.001),\n",
    "    loss      = tf.keras.losses.CategoricalCrossentropy(),\n",
    "    metrics   = tf.keras.metrics.CategoricalAccuracy()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "H9Ll4Jj4SEDJ",
    "outputId": "f841a15f-02b0-4c4a-df0d-daf429e10294",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0...\n",
      "Training slp14 (0/14)...\n",
      "Training slp02b (1/14)...\n",
      "Training slp59 (2/14)...\n",
      "Training slp02a (3/14)...\n",
      "Training slp60 (4/14)...\n",
      "Training slp16 (5/14)...\n",
      "Training slp61 (6/14)...\n",
      "Training slp03 (7/14)...\n",
      "Training slp01b (8/14)...\n",
      "Training slp41 (9/14)...\n",
      "Training slp01a (10/14)...\n",
      "Training slp67x (11/14)...\n",
      "Training slp66 (12/14)...\n",
      "Training slp37 (13/14)...\n",
      "Training accuracy = 42.48%\n",
      "Validation accuracy = 58.78%\n",
      "Epoch 1...\n",
      "Training slp14 (0/14)...\n",
      "Training slp02b (1/14)...\n",
      "Training slp59 (2/14)...\n",
      "Training slp02a (3/14)...\n",
      "Training slp60 (4/14)...\n",
      "Training slp16 (5/14)...\n",
      "Training slp61 (6/14)...\n",
      "Training slp03 (7/14)...\n",
      "Training slp01b (8/14)...\n",
      "Training slp41 (9/14)...\n",
      "Training slp01a (10/14)...\n",
      "Training slp67x (11/14)...\n",
      "Training slp66 (12/14)...\n",
      "Training slp37 (13/14)...\n",
      "Training accuracy = 50.86%\n",
      "Validation accuracy = 73.33%\n",
      "Epoch 2...\n",
      "Training slp14 (0/14)...\n",
      "Training slp02b (1/14)...\n",
      "Training slp59 (2/14)...\n",
      "Training slp02a (3/14)...\n",
      "Training slp60 (4/14)...\n",
      "Training slp16 (5/14)...\n",
      "Training slp61 (6/14)...\n",
      "Training slp03 (7/14)...\n",
      "Training slp01b (8/14)...\n",
      "Training slp41 (9/14)...\n",
      "Training slp01a (10/14)...\n",
      "Training slp67x (11/14)...\n",
      "Training slp66 (12/14)...\n",
      "Training slp37 (13/14)...\n",
      "Training accuracy = 52.94%\n",
      "Validation accuracy = 74.59%\n",
      "Epoch 3...\n",
      "Training slp14 (0/14)...\n",
      "Training slp02b (1/14)...\n",
      "Training slp59 (2/14)...\n",
      "Training slp02a (3/14)...\n",
      "Training slp60 (4/14)...\n",
      "Training slp16 (5/14)...\n",
      "Training slp61 (6/14)...\n",
      "Training slp03 (7/14)...\n",
      "Training slp01b (8/14)...\n",
      "Training slp41 (9/14)...\n",
      "Training slp01a (10/14)...\n",
      "Training slp67x (11/14)...\n",
      "Training slp66 (12/14)...\n",
      "Training slp37 (13/14)...\n",
      "Training accuracy = 52.69%\n",
      "Validation accuracy = 73.06%\n",
      "Epoch 4...\n",
      "Training slp14 (0/14)...\n",
      "Training slp02b (1/14)...\n",
      "Training slp59 (2/14)...\n",
      "Training slp02a (3/14)...\n",
      "Training slp60 (4/14)...\n",
      "Training slp16 (5/14)...\n",
      "Training slp61 (6/14)...\n",
      "Training slp03 (7/14)...\n",
      "Training slp01b (8/14)...\n",
      "Training slp41 (9/14)...\n",
      "Training slp01a (10/14)...\n",
      "Training slp67x (11/14)...\n",
      "Training slp66 (12/14)...\n",
      "Training slp37 (13/14)...\n",
      "Training accuracy = 51.54%\n",
      "Validation accuracy = 71.23%\n"
     ]
    }
   ],
   "source": [
    "train_acc = []\n",
    "valid_acc = []\n",
    "\n",
    "# Train the neural network\n",
    "for epoch in range(5):\n",
    "    inter_train = []\n",
    "    inter_valid = []\n",
    "    \n",
    "    print(\"Epoch {}...\".format(epoch))\n",
    "    for i, patient_name in enumerate(train_patients):\n",
    "        print(\"Training {} ({}/{})...\".format(patient_name, i, len(train_patients)))\n",
    "        # Create training and validation dataset\n",
    "        train_data, train_labels = create_dataset(patient_name, diagnostic=False)\n",
    "        valid_data, valid_labels = create_dataset(valid_patients[0], diagnostic=False)\n",
    "        \n",
    "        # Convert to one-hot encoding\n",
    "        train_labels = utils.to_categorical(train_labels, num_classes=NUM_CLASSES)\n",
    "        valid_labels = utils.to_categorical(valid_labels, num_classes=NUM_CLASSES)\n",
    "\n",
    "        # Train model\n",
    "        history = model.fit(\n",
    "            x               = train_data,\n",
    "            y               = train_labels,\n",
    "            epochs          = 1,\n",
    "            validation_data = (\n",
    "                valid_data,\n",
    "                valid_labels\n",
    "            ),\n",
    "            callbacks       = [\n",
    "                tf.keras.callbacks.ReduceLROnPlateau(\n",
    "                    monitor='val_loss', \n",
    "                    factor=0.2,\n",
    "                    patience=5, min_lr=0.001\n",
    "                )\n",
    "            ],\n",
    "            verbose=0\n",
    "        )\n",
    "\n",
    "        # Append accuracies\n",
    "        inter_train.append(history.history['categorical_accuracy'][0])\n",
    "        inter_valid.append(history.history['val_categorical_accuracy'][0])\n",
    "\n",
    "    train_acc.append(np.mean(np.array(inter_train)))\n",
    "    valid_acc.append(np.mean(np.array(inter_valid)))\n",
    "    \n",
    "    print(\"Training accuracy = {:.2%}\".format(train_acc[-1]))\n",
    "    print(\"Validation accuracy = {:.2%}\".format(valid_acc[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x140c35730>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Graph training accuracy\n",
    "plt.plot(train_acc, label='Training Accuracy')\n",
    "plt.plot(valid_acc, label='Validation Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim([0, 1])\n",
    "plt.legend(loc='lower right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 0s 3ms/step - loss: 0.9741 - categorical_accuracy: 0.6958\n",
      "Testing accuracy = 69.58%\n"
     ]
    }
   ],
   "source": [
    "test_acc = []\n",
    "\n",
    "for patient_name in test_patients[1:]:\n",
    "    # Get test accuracy of the network\n",
    "    test_data, test_labels = create_dataset(patient_name, diagnostic=False)\n",
    "    test_labels = utils.to_categorical(test_labels, num_classes=NUM_CLASSES)\n",
    "    _, acc = model.evaluate(test_data, test_labels)\n",
    "    test_acc.append(acc)\n",
    "    \n",
    "print(\"Testing accuracy = {:.2%}\".format(np.mean(test_acc)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Exporting Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as conv2d_layer_call_and_return_conditional_losses, conv2d_layer_call_fn, conv2d_4_layer_call_and_return_conditional_losses, conv2d_4_layer_call_fn, conv2d_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model/assets\n"
     ]
    }
   ],
   "source": [
    "MODEL_TF = 'model'\n",
    "MODEL_TFLITE = 'model.tflite'\n",
    "MODEL_TFLITE_MICRO = 'model.cc'\n",
    "\n",
    "model.save(MODEL_TF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as conv2d_layer_call_and_return_conditional_losses, conv2d_layer_call_fn, conv2d_4_layer_call_and_return_conditional_losses, conv2d_4_layer_call_fn, conv2d_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/gq/h37vcf3132q7y2scnlvy177r0000gn/T/tmptv9um7ng/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/gq/h37vcf3132q7y2scnlvy177r0000gn/T/tmptv9um7ng/assets\n",
      "2022-04-09 21:30:42.910095: I tensorflow/core/grappler/devices.cc:75] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0 (Note: TensorFlow was not compiled with CUDA or ROCm support)\n",
      "2022-04-09 21:30:42.910183: I tensorflow/core/grappler/clusters/single_machine.cc:357] Starting new session\n",
      "2022-04-09 21:30:42.912442: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:1137] Optimization results for grappler item: graph_to_optimize\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.002ms.\n",
      "  function_optimizer: function_optimizer did nothing. time = 0ms.\n",
      "\n",
      "2022-04-09 21:30:43.562816: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:351] Ignored output_format.\n",
      "2022-04-09 21:30:43.562831: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:354] Ignored drop_control_dependency.\n",
      "fully_quantize: 0, inference_type: 6, input_inference_type: 9, output_inference_type: 9\n"
     ]
    }
   ],
   "source": [
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "\n",
    "# Quantization\n",
    "def representative_dataset_gen():\n",
    "    for sample in train_data:\n",
    "        yield [np.expand_dims(sample, axis=0).astype(np.float32)]\n",
    "\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
    "converter.inference_input_type = tf.int8\n",
    "converter.inference_output_type = tf.int8\n",
    "converter.representative_dataset = representative_dataset_gen\n",
    "\n",
    "model_tflite = converter.convert()\n",
    "with open(MODEL_TFLITE, \"wb\") as f:\n",
    "    f.write(model_tflite)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "!xxd -i {MODEL_TFLITE} > {MODEL_TFLITE_MICRO}\n",
    "\n",
    "REPLACE_TEXT = MODEL_TFLITE.replace('/', '_').replace('.', '_')\n",
    "!sed -i '' -e 's/'{REPLACE_TEXT}'/g_model/g' {MODEL_TFLITE_MICRO}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Rough Implementation",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
