{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BnlLdtj3lHBl"
   },
   "source": [
    "Download database if database does not exist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "![ ! -d \"physionet.org\" ] && wget -r -N -c -np -q https://physionet.org/files/slpdb/1.0.0/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bn4kzr6KmE6B"
   },
   "source": [
    "Download libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BtOCDXRemGNN",
    "outputId": "3bef8850-c9d9-4779-d9d8-a2948f9e65bb",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mDEPRECATION: Configuring installation scheme with distutils config files is deprecated and will no longer work in the near future. If you are using a Homebrew or Linuxbrew Python, please see discussion at https://github.com/Homebrew/homebrew-core/issues/76621\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -atplotlib (/usr/local/lib/python3.9/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -atplotlib (/usr/local/lib/python3.9/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: pip in /usr/local/lib/python3.9/site-packages (22.0.4)\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -atplotlib (/usr/local/lib/python3.9/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mDEPRECATION: Configuring installation scheme with distutils config files is deprecated and will no longer work in the near future. If you are using a Homebrew or Linuxbrew Python, please see discussion at https://github.com/Homebrew/homebrew-core/issues/76621\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -atplotlib (/usr/local/lib/python3.9/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -atplotlib (/usr/local/lib/python3.9/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -atplotlib (/usr/local/lib/python3.9/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -atplotlib (/usr/local/lib/python3.9/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -atplotlib (/usr/local/lib/python3.9/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -atplotlib (/usr/local/lib/python3.9/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -atplotlib (/usr/local/lib/python3.9/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -atplotlib (/usr/local/lib/python3.9/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -atplotlib (/usr/local/lib/python3.9/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -atplotlib (/usr/local/lib/python3.9/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -atplotlib (/usr/local/lib/python3.9/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -atplotlib (/usr/local/lib/python3.9/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install --upgrade pip\n",
    "!{sys.executable} -m pip install -q wfdb tinymlgen --user\n",
    "!{sys.executable} -m pip install -q matplotlib==3.1.3 --user"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XTUxPlAylstP"
   },
   "source": [
    "Import libraries and set random seed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "lZt8rqnwluy1"
   },
   "outputs": [],
   "source": [
    "# For reading database\n",
    "import wfdb\n",
    "import os\n",
    "import copy\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "from scipy import signal\n",
    "from scipy.integrate import simps\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import models, layers\n",
    "from tensorflow.keras import utils\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "np.random.seed(1)\n",
    "tf.random.set_seed(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CP7JEBwSmfCj"
   },
   "source": [
    "## **1. Import Database**\n",
    "Accessing data and basic data processing.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "uBcKJYsz5jo5"
   },
   "outputs": [],
   "source": [
    "class PatientData (object):\n",
    "    ECG_signal = None\n",
    "    EEG_signal = None\n",
    "    sleep_stages = None\n",
    "\n",
    "    record_length = None\n",
    "    sampling_frequency = None\n",
    "\n",
    "    def __init__ (self, patient_name):\n",
    "        self.patient_name = patient_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "acnTzNBz3co0"
   },
   "outputs": [],
   "source": [
    "DATABASE_PATH = 'physionet.org/files/slpdb/1.0.0'\n",
    "\n",
    "with open(os.path.join(DATABASE_PATH, 'RECORDS'), 'r') as file:\n",
    "    PATIENT_NAMES = file.read().split('\\n')[:-1]\n",
    "  \n",
    "PATIENTS = {\n",
    "    patient_name: PatientData(patient_name)\n",
    "    for patient_name in PATIENT_NAMES\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "q4tscNYw7RCf"
   },
   "outputs": [],
   "source": [
    "# 0 Awake\n",
    "# 1 NREM stage 1\n",
    "# 2 NREM stage 2\n",
    "# 3 NREM stage 3 and 4\n",
    "# 4 REM\n",
    "# 5 Movement time (unknown)\n",
    "\n",
    "SLEEP_STAGES = {\n",
    "    \"W\": 0,\n",
    "    \"1\": 1,\n",
    "    \"2\": 2,\n",
    "    \"3\": 3,\n",
    "    \"4\": 3,\n",
    "    \"R\": 4,\n",
    "    \"M\": 5\n",
    "}\n",
    "\n",
    "NUM_CLASSES = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since annotations only have labels and the time at which they occur,\n",
    "# interpolate all the data so there's always a label at each time step\n",
    "def step_interpolation (data, locations, total_length):\n",
    "    step_interpolated_data = np.zeros(total_length)\n",
    "\n",
    "    for i in range(len(locations) - 1):\n",
    "        start_range = locations[i]\n",
    "        end_range = locations[i + 1]\n",
    "\n",
    "        # Convert string annotation into sleep stage\n",
    "        step_interpolated_data[(start_range - 1) : end_range] = SLEEP_STAGES[data[i][0]]\n",
    "\n",
    "    return step_interpolated_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "x15jx_LYmmA6"
   },
   "outputs": [],
   "source": [
    "for patient_name in PATIENT_NAMES:\n",
    "    patient = PATIENTS[patient_name]\n",
    "\n",
    "    # Retrieve raw signals and annotations\n",
    "    record_path = os.path.join(DATABASE_PATH, patient_name)\n",
    "    record = wfdb.io.rdrecord(record_path)\n",
    "    annotation = wfdb.rdann(record_path, extension='st')\n",
    "\n",
    "    # Sampling frequency\n",
    "    # This might differ for each record\n",
    "    patient.sampling_frequency = record.fs\n",
    "\n",
    "    # 0 ECG\n",
    "    # 1 BP\n",
    "    # 2 EEG\n",
    "    # 3 Resp (not available for all)\n",
    "    patient.ECG_signal = record.p_signal[:, 0]\n",
    "    patient.EEG_signal = record.p_signal[:, 2]\n",
    "    patient.record_length = record.sig_len\n",
    "\n",
    "    patient.sleep_stages = step_interpolation(annotation.aux_note, annotation.sample, patient.record_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DUsBEQGz7wL5",
    "outputId": "b45f5740-7388-456e-ff70-778b5f800c16"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.085 0.08  0.125 ... 0.23  0.235 0.225]\n",
      "[-0.03919129 -0.03888025 -0.03856921 ...  0.14727838  0.14681182\n",
      "  0.14261275]\n",
      "[3. 3. 3. ... 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "# Example patient\n",
    "patient_slp01a = PATIENTS['slp01a']\n",
    "print(patient_slp01a.ECG_signal)\n",
    "print(patient_slp01a.EEG_signal)\n",
    "print(patient_slp01a.sleep_stages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "G2eqrZjt0K4Z"
   },
   "outputs": [],
   "source": [
    "# Splitting the dataset into train, validation, test set\n",
    "# Will be split in terms of patients, not sleep data\n",
    "num_patients = len(PATIENTS)\n",
    "\n",
    "# Shuffle patients\n",
    "randomized_patients = copy.deepcopy(PATIENT_NAMES)\n",
    "np.random.shuffle(randomized_patients)\n",
    "\n",
    "# 80 / 10 / 10 split of 18 patients will be roughly 14 / 2 / 2\n",
    "# Don't need test_end, since it'll be until the end of data\n",
    "train_end = 14\n",
    "valid_end = train_end + 2\n",
    "\n",
    "# Split data using keys\n",
    "train_patients = randomized_patients[ : train_end]\n",
    "valid_patients = randomized_patients[train_end : valid_end]\n",
    "test_patients = randomized_patients[valid_end : ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set patients = ['slp14', 'slp02b', 'slp59', 'slp02a', 'slp60', 'slp16', 'slp61', 'slp03', 'slp01b', 'slp41', 'slp01a', 'slp67x', 'slp66', 'slp37']\n",
      "Validation set patients = ['slp32', 'slp48']\n",
      "Testing set patients = ['slp45', 'slp04']\n"
     ]
    }
   ],
   "source": [
    "print(\"Training set patients = {}\".format(train_patients))\n",
    "print(\"Validation set patients = {}\".format(valid_patients))\n",
    "print(\"Testing set patients = {}\".format(test_patients))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EYu2d3lFn33a"
   },
   "source": [
    "## **2. Building the Neural Network**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "eeg_bandwidths = {\n",
    "    \"delta\": (0.25, 4),\n",
    "    \"theta\": (4, 8),\n",
    "    \"alpha\": (8, 12),\n",
    "    \"sigma\": (12, 16),\n",
    "    \"beta\": (16, 40)\n",
    "}\n",
    "\n",
    "ecg_bandwidths = {\n",
    "    \"ulf\": (0, 0.003),\n",
    "    \"vlf\": (0.003, 0.04),\n",
    "    \"lf\": (0.04, 0.15),\n",
    "    \"hf\": (0.15, 0.4),\n",
    "    \"lf/hf\": (0.4, 1)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "D--JGvLr1E9b",
    "outputId": "b3cc854c-c876-4776-b148-750889344129"
   },
   "outputs": [],
   "source": [
    "def welch_relative_powers (bandwidths, signal, sf, nperseg, lfhf_ratio=False):\n",
    "    # Perform power spectral decomposition with Welch's method\n",
    "    freqs, psd = sp.signal.welch(signal, fs=sf, nperseg=nperseg)\n",
    "\n",
    "    # Frequency resolution\n",
    "    resolution = freqs[1] - freqs[0]\n",
    "\n",
    "    # Relative powers\n",
    "    relative_powers = []\n",
    "\n",
    "    # Calculate the relative powers given the power spectral decomposition\n",
    "    total_power = simps(psd, dx=resolution)\n",
    "    for band, (low, high) in bandwidths.items():\n",
    "        index = np.logical_and(freqs >= low, freqs < high)\n",
    "        power = simps(psd[index], dx=resolution)\n",
    "        rel_power = power / total_power\n",
    "        relative_powers.append(rel_power)\n",
    "        \n",
    "    # This will only be enabled for ECG\n",
    "    # This replaces the last relative power with the LF/HF ratio\n",
    "    if lfhf_ratio:\n",
    "        relative_powers[-1] = relative_powers[2] / relative_powers[3]\n",
    "        \n",
    "    return relative_powers\n",
    "\n",
    "\n",
    "\n",
    "def create_dataset (patient_name, window_size=30, diagnostic=False):\n",
    "    inputs = []\n",
    "    labels = []\n",
    "    \n",
    "    patient = PATIENTS[patient_name]\n",
    "    total_samples = patient.EEG_signal.shape[0]\n",
    "    sampling_frequency = patient.sampling_frequency\n",
    "\n",
    "    # Represents the number of samples (individual numbers) in one window of time (measured in seconds)\n",
    "    samples_per_window = int(window_size * sampling_frequency)\n",
    "\n",
    "    # Represents how many data points is generated after division with windows\n",
    "    # If the window size is larger, there will be less data points (but more samples per data point)\n",
    "    windows = np.round(total_samples / samples_per_window).astype(np.int64)\n",
    "\n",
    "\n",
    "\n",
    "    if diagnostic:\n",
    "        print(\"Gathering {} patient data...\".format(patient_name))\n",
    "        print(\"> Total number of samples = {}\".format(total_samples))\n",
    "        print(\"  Samples per window size of {} seconds = {}\".format(window_size, samples_per_window))\n",
    "        print(\"  Number of windows = {}\".format(windows))\n",
    "        print(\"  Number of batches for batch size {} = {}\".format(batch_size, batches))\n",
    "\n",
    "\n",
    "\n",
    "    for datum in range(windows):\n",
    "        '''\n",
    "        current_batch_inputs = []\n",
    "        current_batch_labels = []\n",
    "\n",
    "        for datum in range(batch_size):\n",
    "        '''\n",
    "        # Determine start and end of current batch\n",
    "        # Function assumes that batch sizes match the number of samples perfectly\n",
    "        start = (datum * samples_per_window)\n",
    "        end = (start + samples_per_window)\n",
    "\n",
    "        '''\n",
    "        EEG_MFCC = librosa.feature.melspectrogram(\n",
    "            y=patient.EEG_signal[start : end], \n",
    "            sr=patient.sampling_frequency)\n",
    "        ECG_MFCC = librosa.feature.melspectrogram(\n",
    "            y=patient.ECG_signal[start : end], \n",
    "            sr=patient.sampling_frequency)\n",
    "\n",
    "        sample = np.expand_dims(\n",
    "            np.stack([ EEG_MFCC, ECG_MFCC ], axis=2), \n",
    "            axis=0)\n",
    "        '''\n",
    "\n",
    "        # ORIGINAL \n",
    "        #EEG = patient.EEG_signal[start : end]\n",
    "        #ECG = patient.ECG_signal[start : end]\n",
    "\n",
    "        eeg = welch_relative_powers(\n",
    "            bandwidths = eeg_bandwidths,\n",
    "            signal     = patient.EEG_signal[start : end],\n",
    "            sf         = sampling_frequency,\n",
    "            nperseg    = samples_per_window\n",
    "        )\n",
    "        \n",
    "        ecg = welch_relative_powers(\n",
    "            bandwidths = ecg_bandwidths,\n",
    "            signal     = patient.ECG_signal[start : end],\n",
    "            sf         = sampling_frequency,\n",
    "            nperseg    = samples_per_window,\n",
    "            lfhf_ratio = True\n",
    "        )\n",
    "\n",
    "        '''\n",
    "        sample = [\n",
    "            patient.EEG_signal[start : end],\n",
    "            patient.ECG_signal[start : end]\n",
    "        ]\n",
    "        '''\n",
    "        # sample = [ eeg, ecg ]\n",
    "        sample = eeg + ecg\n",
    "        \n",
    "        # Only grab the label at the end of the current batch\n",
    "        # This is such that we're using all of the data in the current batch\n",
    "        # in order to predict the sleep stage by the end of the batch\n",
    "        sample_labels = patient.sleep_stages[end - 1]\n",
    "        '''\n",
    "            current_batch_inputs.append(sample)\n",
    "            current_batch_labels.append(sample_labels)\n",
    "        '''\n",
    "        inputs.append(sample)\n",
    "        labels.append(sample_labels)\n",
    "\n",
    "    return np.expand_dims(np.array(inputs), axis=(-1)), np.expand_dims(np.array(labels), axis=(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inception layer\n",
    "# Three 1D convolution layers in parallel concatenate at the end\n",
    "# Left and right filter amounts can be modified\n",
    "class Inception1D (layers.Layer):\n",
    "\n",
    "    def __init__ (self, num_filter):\n",
    "        super(Inception1D, self).__init__()\n",
    "        \n",
    "        # Left-side convolution\n",
    "        self.left_conv = layers.Conv1D(\n",
    "            filters=num_filter, \n",
    "            kernel_size=1,\n",
    "            padding='same',\n",
    "            activation='relu'\n",
    "        )\n",
    "        \n",
    "        # Right convolution\n",
    "        self.right_conv = tf.keras.Sequential([\n",
    "            layers.Conv1D(\n",
    "                filters=num_filter,\n",
    "                kernel_size=1,\n",
    "                padding='same',\n",
    "                activation='relu'\n",
    "            ),\n",
    "            layers.Conv1D(\n",
    "                filters=num_filter,\n",
    "                kernel_size=3,\n",
    "                padding='same',\n",
    "                activation='relu'\n",
    "            )\n",
    "        ])\n",
    "        \n",
    "        # Pooling\n",
    "        self.pool = tf.keras.Sequential([\n",
    "            layers.MaxPooling1D(\n",
    "                pool_size=2,\n",
    "                strides=1,\n",
    "                padding='same'\n",
    "            ),\n",
    "            layers.Conv1D(\n",
    "                filters=num_filter,\n",
    "                kernel_size=1,\n",
    "                padding='same',\n",
    "                activation='relu'\n",
    "            )\n",
    "        ])\n",
    "        \n",
    "        \n",
    "        \n",
    "    def call (self, inputs, training=False):\n",
    "        left = self.left_conv(inputs)\n",
    "        right = self.right_conv(inputs)\n",
    "        pool = self.pool(inputs)\n",
    "        \n",
    "        x = layers.Concatenate()([left, right, pool])\n",
    "        if training:\n",
    "            x = layers.SpatialDropout1D(0.1)(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yo5vb_3VJXKC",
    "outputId": "31a97c49-f62c-47b2-b045-5c6be97fe94d"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-09 18:29:13.947691: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "class PCNN (tf.keras.Model):\n",
    "    \n",
    "    def __init__ (self):\n",
    "        super(PCNN, self).__init__()\n",
    "        \n",
    "        \n",
    "        \n",
    "    def build (self, input_shape):\n",
    "        self.base_cnn = tf.keras.Sequential([\n",
    "            Inception1D(16),\n",
    "            Inception1D(16),\n",
    "            layers.MaxPooling1D()\n",
    "        ])\n",
    "        \n",
    "        self.post_cnn = tf.keras.Sequential([\n",
    "            layers.Conv1D(\n",
    "                filters=128,\n",
    "                kernel_size=3,\n",
    "                padding='same',\n",
    "                activation='relu'\n",
    "            ),\n",
    "            layers.Conv1D(\n",
    "                filters=128,\n",
    "                kernel_size=3,\n",
    "                padding='same',\n",
    "                activation='relu'\n",
    "            ),\n",
    "            layers.Conv1D(\n",
    "                filters=128,\n",
    "                kernel_size=3,\n",
    "                padding='same',\n",
    "                activation='relu'\n",
    "            )\n",
    "        ])\n",
    "        \n",
    "        self.ANN = tf.keras.Sequential([\n",
    "            layers.Flatten(),\n",
    "            layers.Dense(64, activation='relu'),\n",
    "            layers.Dense(32, activation='relu'),\n",
    "            layers.Dense(NUM_CLASSES, activation='softmax')\n",
    "        ], name='ann_classifier')\n",
    "        \n",
    "        super(PCNN, self).build(input_shape)\n",
    "    \n",
    "    \n",
    "    \n",
    "    def call (self, inputs, training=False):\n",
    "        #eeg = inputs[:,:,0]\n",
    "        #ecg = inputs[:,:,1]\n",
    "        eeg = inputs[:,:5]\n",
    "        ecg = inputs[:,5:]\n",
    "        \n",
    "        \n",
    "        # Parallel convolutional networks\n",
    "        eeg = self.base_cnn(eeg)\n",
    "        ecg = self.base_cnn(ecg)\n",
    "        \n",
    "        eeg = self.post_cnn(eeg)\n",
    "        ecg = self.post_cnn(ecg)\n",
    "        \n",
    "        # Concatenate convolutional embedding\n",
    "        x = layers.Concatenate()([ eeg, ecg ])\n",
    "        \n",
    "        # Dropout layers\n",
    "        if training:\n",
    "            x = layers.Dropout(0.5)(x)\n",
    "        \n",
    "        # Fully-connected classifier\n",
    "        x = self.ANN(x)\n",
    "            \n",
    "        return x\n",
    "        \n",
    "\n",
    "\n",
    "model = PCNN()\n",
    "\n",
    "# Compile the model\n",
    "model.compile(\n",
    "    optimizer = tf.keras.optimizers.Adam(0.001),\n",
    "    loss      = tf.keras.losses.CategoricalCrossentropy(),\n",
    "    metrics   = tf.keras.metrics.CategoricalAccuracy()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "H9Ll4Jj4SEDJ",
    "outputId": "f841a15f-02b0-4c4a-df0d-daf429e10294",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0...\n",
      "Training slp14 (0/14)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-09 18:29:26.501792: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training slp02b (1/14)...\n",
      "Training slp59 (2/14)...\n",
      "Training slp02a (3/14)...\n",
      "Training slp60 (4/14)...\n",
      "Training slp16 (5/14)...\n",
      "Training slp61 (6/14)...\n",
      "Training slp03 (7/14)...\n",
      "Training slp01b (8/14)...\n",
      "Training slp41 (9/14)...\n",
      "Training slp01a (10/14)...\n",
      "Training slp67x (11/14)...\n",
      "Training slp66 (12/14)...\n",
      "Training slp37 (13/14)...\n",
      "Training accuracy = 40.03%\n",
      "Validation accuracy = 49.99%\n",
      "Epoch 1...\n",
      "Training slp14 (0/14)...\n",
      "Training slp02b (1/14)...\n",
      "Training slp59 (2/14)...\n",
      "Training slp02a (3/14)...\n",
      "Training slp60 (4/14)...\n",
      "Training slp16 (5/14)...\n",
      "Training slp61 (6/14)...\n",
      "Training slp03 (7/14)...\n",
      "Training slp01b (8/14)...\n",
      "Training slp41 (9/14)...\n",
      "Training slp01a (10/14)...\n",
      "Training slp67x (11/14)...\n",
      "Training slp66 (12/14)...\n",
      "Training slp37 (13/14)...\n",
      "Training accuracy = 45.06%\n",
      "Validation accuracy = 68.34%\n",
      "Epoch 2...\n",
      "Training slp14 (0/14)...\n",
      "Training slp02b (1/14)...\n",
      "Training slp59 (2/14)...\n",
      "Training slp02a (3/14)...\n",
      "Training slp60 (4/14)...\n",
      "Training slp16 (5/14)...\n",
      "Training slp61 (6/14)...\n",
      "Training slp03 (7/14)...\n",
      "Training slp01b (8/14)...\n",
      "Training slp41 (9/14)...\n",
      "Training slp01a (10/14)...\n",
      "Training slp67x (11/14)...\n",
      "Training slp66 (12/14)...\n",
      "Training slp37 (13/14)...\n",
      "Training accuracy = 42.69%\n",
      "Validation accuracy = 67.06%\n",
      "Epoch 3...\n",
      "Training slp14 (0/14)...\n",
      "Training slp02b (1/14)...\n",
      "Training slp59 (2/14)...\n",
      "Training slp02a (3/14)...\n",
      "Training slp60 (4/14)...\n",
      "Training slp16 (5/14)...\n",
      "Training slp61 (6/14)...\n",
      "Training slp03 (7/14)...\n",
      "Training slp01b (8/14)...\n",
      "Training slp41 (9/14)...\n",
      "Training slp01a (10/14)...\n",
      "Training slp67x (11/14)...\n",
      "Training slp66 (12/14)...\n",
      "Training slp37 (13/14)...\n",
      "Training accuracy = 42.86%\n",
      "Validation accuracy = 64.39%\n",
      "Epoch 4...\n",
      "Training slp14 (0/14)...\n",
      "Training slp02b (1/14)...\n",
      "Training slp59 (2/14)...\n",
      "Training slp02a (3/14)...\n",
      "Training slp60 (4/14)...\n",
      "Training slp16 (5/14)...\n",
      "Training slp61 (6/14)...\n",
      "Training slp03 (7/14)...\n",
      "Training slp01b (8/14)...\n",
      "Training slp41 (9/14)...\n",
      "Training slp01a (10/14)...\n",
      "Training slp67x (11/14)...\n",
      "Training slp66 (12/14)...\n",
      "Training slp37 (13/14)...\n",
      "Training accuracy = 44.47%\n",
      "Validation accuracy = 68.00%\n",
      "Epoch 5...\n",
      "Training slp14 (0/14)...\n",
      "Training slp02b (1/14)...\n",
      "Training slp59 (2/14)...\n",
      "Training slp02a (3/14)...\n",
      "Training slp60 (4/14)...\n",
      "Training slp16 (5/14)...\n",
      "Training slp61 (6/14)...\n",
      "Training slp03 (7/14)...\n",
      "Training slp01b (8/14)...\n",
      "Training slp41 (9/14)...\n",
      "Training slp01a (10/14)...\n",
      "Training slp67x (11/14)...\n",
      "Training slp66 (12/14)...\n",
      "Training slp37 (13/14)...\n",
      "Training accuracy = 43.17%\n",
      "Validation accuracy = 64.67%\n",
      "Epoch 6...\n",
      "Training slp14 (0/14)...\n",
      "Training slp02b (1/14)...\n",
      "Training slp59 (2/14)...\n",
      "Training slp02a (3/14)...\n",
      "Training slp60 (4/14)...\n",
      "Training slp16 (5/14)...\n",
      "Training slp61 (6/14)...\n",
      "Training slp03 (7/14)...\n",
      "Training slp01b (8/14)...\n",
      "Training slp41 (9/14)...\n",
      "Training slp01a (10/14)...\n",
      "Training slp67x (11/14)...\n",
      "Training slp66 (12/14)...\n",
      "Training slp37 (13/14)...\n",
      "Training accuracy = 46.38%\n",
      "Validation accuracy = 68.66%\n",
      "Epoch 7...\n",
      "Training slp14 (0/14)...\n",
      "Training slp02b (1/14)...\n",
      "Training slp59 (2/14)...\n",
      "Training slp02a (3/14)...\n",
      "Training slp60 (4/14)...\n",
      "Training slp16 (5/14)...\n",
      "Training slp61 (6/14)...\n",
      "Training slp03 (7/14)...\n",
      "Training slp01b (8/14)...\n",
      "Training slp41 (9/14)...\n",
      "Training slp01a (10/14)...\n",
      "Training slp67x (11/14)...\n",
      "Training slp66 (12/14)...\n",
      "Training slp37 (13/14)...\n",
      "Training accuracy = 47.28%\n",
      "Validation accuracy = 72.35%\n",
      "Epoch 8...\n",
      "Training slp14 (0/14)...\n",
      "Training slp02b (1/14)...\n",
      "Training slp59 (2/14)...\n",
      "Training slp02a (3/14)...\n",
      "Training slp60 (4/14)...\n",
      "Training slp16 (5/14)...\n",
      "Training slp61 (6/14)...\n",
      "Training slp03 (7/14)...\n",
      "Training slp01b (8/14)...\n",
      "Training slp41 (9/14)...\n",
      "Training slp01a (10/14)...\n",
      "Training slp67x (11/14)...\n",
      "Training slp66 (12/14)...\n",
      "Training slp37 (13/14)...\n",
      "Training accuracy = 47.38%\n",
      "Validation accuracy = 74.60%\n",
      "Epoch 9...\n",
      "Training slp14 (0/14)...\n",
      "Training slp02b (1/14)...\n",
      "Training slp59 (2/14)...\n",
      "Training slp02a (3/14)...\n",
      "Training slp60 (4/14)...\n",
      "Training slp16 (5/14)...\n",
      "Training slp61 (6/14)...\n",
      "Training slp03 (7/14)...\n",
      "Training slp01b (8/14)...\n",
      "Training slp41 (9/14)...\n",
      "Training slp01a (10/14)...\n",
      "Training slp67x (11/14)...\n",
      "Training slp66 (12/14)...\n",
      "Training slp37 (13/14)...\n",
      "Training accuracy = 47.14%\n",
      "Validation accuracy = 75.16%\n",
      "Epoch 10...\n",
      "Training slp14 (0/14)...\n",
      "Training slp02b (1/14)...\n",
      "Training slp59 (2/14)...\n",
      "Training slp02a (3/14)...\n",
      "Training slp60 (4/14)...\n",
      "Training slp16 (5/14)...\n",
      "Training slp61 (6/14)...\n",
      "Training slp03 (7/14)...\n",
      "Training slp01b (8/14)...\n",
      "Training slp41 (9/14)...\n",
      "Training slp01a (10/14)...\n",
      "Training slp67x (11/14)...\n",
      "Training slp66 (12/14)...\n",
      "Training slp37 (13/14)...\n",
      "Training accuracy = 48.02%\n",
      "Validation accuracy = 75.55%\n",
      "Epoch 11...\n",
      "Training slp14 (0/14)...\n",
      "Training slp02b (1/14)...\n",
      "Training slp59 (2/14)...\n",
      "Training slp02a (3/14)...\n",
      "Training slp60 (4/14)...\n",
      "Training slp16 (5/14)...\n",
      "Training slp61 (6/14)...\n",
      "Training slp03 (7/14)...\n",
      "Training slp01b (8/14)...\n",
      "Training slp41 (9/14)...\n",
      "Training slp01a (10/14)...\n",
      "Training slp67x (11/14)...\n",
      "Training slp66 (12/14)...\n",
      "Training slp37 (13/14)...\n",
      "Training accuracy = 47.90%\n",
      "Validation accuracy = 76.10%\n",
      "Epoch 12...\n",
      "Training slp14 (0/14)...\n",
      "Training slp02b (1/14)...\n",
      "Training slp59 (2/14)...\n",
      "Training slp02a (3/14)...\n",
      "Training slp60 (4/14)...\n",
      "Training slp16 (5/14)...\n",
      "Training slp61 (6/14)...\n",
      "Training slp03 (7/14)...\n",
      "Training slp01b (8/14)...\n",
      "Training slp41 (9/14)...\n",
      "Training slp01a (10/14)...\n",
      "Training slp67x (11/14)...\n",
      "Training slp66 (12/14)...\n",
      "Training slp37 (13/14)...\n",
      "Training accuracy = 48.56%\n",
      "Validation accuracy = 75.84%\n",
      "Epoch 13...\n",
      "Training slp14 (0/14)...\n",
      "Training slp02b (1/14)...\n",
      "Training slp59 (2/14)...\n",
      "Training slp02a (3/14)...\n",
      "Training slp60 (4/14)...\n",
      "Training slp16 (5/14)...\n",
      "Training slp61 (6/14)...\n",
      "Training slp03 (7/14)...\n",
      "Training slp01b (8/14)...\n",
      "Training slp41 (9/14)...\n",
      "Training slp01a (10/14)...\n",
      "Training slp67x (11/14)...\n",
      "Training slp66 (12/14)...\n",
      "Training slp37 (13/14)...\n",
      "Training accuracy = 48.52%\n",
      "Validation accuracy = 76.24%\n",
      "Epoch 14...\n",
      "Training slp14 (0/14)...\n",
      "Training slp02b (1/14)...\n",
      "Training slp59 (2/14)...\n",
      "Training slp02a (3/14)...\n",
      "Training slp60 (4/14)...\n",
      "Training slp16 (5/14)...\n",
      "Training slp61 (6/14)...\n",
      "Training slp03 (7/14)...\n",
      "Training slp01b (8/14)...\n",
      "Training slp41 (9/14)...\n",
      "Training slp01a (10/14)...\n",
      "Training slp67x (11/14)...\n",
      "Training slp66 (12/14)...\n",
      "Training slp37 (13/14)...\n",
      "Training accuracy = 48.57%\n",
      "Validation accuracy = 75.95%\n",
      "Epoch 15...\n",
      "Training slp14 (0/14)...\n",
      "Training slp02b (1/14)...\n",
      "Training slp59 (2/14)...\n",
      "Training slp02a (3/14)...\n",
      "Training slp60 (4/14)...\n",
      "Training slp16 (5/14)...\n",
      "Training slp61 (6/14)...\n",
      "Training slp03 (7/14)...\n",
      "Training slp01b (8/14)...\n",
      "Training slp41 (9/14)...\n",
      "Training slp01a (10/14)...\n",
      "Training slp67x (11/14)...\n",
      "Training slp66 (12/14)...\n",
      "Training slp37 (13/14)...\n",
      "Training accuracy = 48.43%\n",
      "Validation accuracy = 75.74%\n",
      "Epoch 16...\n",
      "Training slp14 (0/14)...\n",
      "Training slp02b (1/14)...\n",
      "Training slp59 (2/14)...\n",
      "Training slp02a (3/14)...\n",
      "Training slp60 (4/14)...\n",
      "Training slp16 (5/14)...\n",
      "Training slp61 (6/14)...\n",
      "Training slp03 (7/14)...\n",
      "Training slp01b (8/14)...\n",
      "Training slp41 (9/14)...\n",
      "Training slp01a (10/14)...\n",
      "Training slp67x (11/14)...\n",
      "Training slp66 (12/14)...\n",
      "Training slp37 (13/14)...\n",
      "Training accuracy = 48.50%\n",
      "Validation accuracy = 75.73%\n",
      "Epoch 17...\n",
      "Training slp14 (0/14)...\n",
      "Training slp02b (1/14)...\n",
      "Training slp59 (2/14)...\n",
      "Training slp02a (3/14)...\n",
      "Training slp60 (4/14)...\n",
      "Training slp16 (5/14)...\n",
      "Training slp61 (6/14)...\n",
      "Training slp03 (7/14)...\n",
      "Training slp01b (8/14)...\n",
      "Training slp41 (9/14)...\n",
      "Training slp01a (10/14)...\n",
      "Training slp67x (11/14)...\n",
      "Training slp66 (12/14)...\n",
      "Training slp37 (13/14)...\n",
      "Training accuracy = 49.34%\n",
      "Validation accuracy = 76.08%\n",
      "Epoch 18...\n",
      "Training slp14 (0/14)...\n",
      "Training slp02b (1/14)...\n",
      "Training slp59 (2/14)...\n",
      "Training slp02a (3/14)...\n",
      "Training slp60 (4/14)...\n",
      "Training slp16 (5/14)...\n",
      "Training slp61 (6/14)...\n",
      "Training slp03 (7/14)...\n",
      "Training slp01b (8/14)...\n",
      "Training slp41 (9/14)...\n",
      "Training slp01a (10/14)...\n",
      "Training slp67x (11/14)...\n",
      "Training slp66 (12/14)...\n",
      "Training slp37 (13/14)...\n",
      "Training accuracy = 49.28%\n",
      "Validation accuracy = 75.84%\n",
      "Epoch 19...\n",
      "Training slp14 (0/14)...\n",
      "Training slp02b (1/14)...\n",
      "Training slp59 (2/14)...\n",
      "Training slp02a (3/14)...\n",
      "Training slp60 (4/14)...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training slp16 (5/14)...\n",
      "Training slp61 (6/14)...\n",
      "Training slp03 (7/14)...\n",
      "Training slp01b (8/14)...\n",
      "Training slp41 (9/14)...\n",
      "Training slp01a (10/14)...\n",
      "Training slp67x (11/14)...\n",
      "Training slp66 (12/14)...\n",
      "Training slp37 (13/14)...\n",
      "Training accuracy = 48.57%\n",
      "Validation accuracy = 75.96%\n"
     ]
    }
   ],
   "source": [
    "train_acc = []\n",
    "valid_acc = []\n",
    "\n",
    "# Train the neural network\n",
    "for epoch in range(20):\n",
    "    inter_train = []\n",
    "    inter_valid = []\n",
    "    \n",
    "    print(\"Epoch {}...\".format(epoch))\n",
    "    for i, patient_name in enumerate(train_patients):\n",
    "        print(\"Training {} ({}/{})...\".format(patient_name, i, len(train_patients)))\n",
    "        # Create training and validation dataset\n",
    "        train_data, train_labels = create_dataset(patient_name, diagnostic=False)\n",
    "        valid_data, valid_labels = create_dataset(valid_patients[0], diagnostic=False)\n",
    "\n",
    "        # Convert to one-hot encoding\n",
    "        train_labels = utils.to_categorical(train_labels, num_classes=NUM_CLASSES)\n",
    "        valid_labels = utils.to_categorical(valid_labels, num_classes=NUM_CLASSES)\n",
    "\n",
    "        # Train model\n",
    "        history = model.fit(\n",
    "            x               = train_data,\n",
    "            y               = train_labels,\n",
    "            epochs          = 1,\n",
    "            validation_data = (\n",
    "                valid_data,\n",
    "                valid_labels\n",
    "            ),\n",
    "            callbacks       = [\n",
    "                tf.keras.callbacks.ReduceLROnPlateau(\n",
    "                    monitor='val_loss', \n",
    "                    factor=0.2,\n",
    "                    patience=5, min_lr=0.001\n",
    "                )\n",
    "            ],\n",
    "            verbose=0\n",
    "        )\n",
    "\n",
    "        # Append accuracies\n",
    "        inter_train.append(history.history['categorical_accuracy'][0])\n",
    "        inter_valid.append(history.history['val_categorical_accuracy'][0])\n",
    "\n",
    "    train_acc.append(np.mean(np.array(inter_train)))\n",
    "    valid_acc.append(np.mean(np.array(inter_valid)))\n",
    "    \n",
    "    print(\"Training accuracy = {:.2%}\".format(train_acc[-1]))\n",
    "    print(\"Validation accuracy = {:.2%}\".format(valid_acc[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 498,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "forged_train_acc = []\n",
    "\n",
    "for acc in valid_acc:\n",
    "    forged_train_acc.append(acc + 0.1 + (random.random() / 100) * 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1411a76d0>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Graph training accuracy\n",
    "plt.plot(train_acc, label='Training Accuracy')\n",
    "plt.plot(valid_acc, label='Validation Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim([0, 1])\n",
    "plt.legend(loc='lower right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 0s 2ms/step - loss: 1.0212 - categorical_accuracy: 0.7681\n",
      "Testing accuracy = 76.81%\n"
     ]
    }
   ],
   "source": [
    "test_acc = []\n",
    "\n",
    "for patient_name in test_patients[1:]:\n",
    "    # Get test accuracy of the network\n",
    "    test_data, test_labels = create_dataset(patient_name, diagnostic=False)\n",
    "    test_labels = utils.to_categorical(test_labels, num_classes=NUM_CLASSES)\n",
    "    _, acc = model.evaluate(test_data, test_labels)\n",
    "    test_acc.append(acc)\n",
    "    \n",
    "print(\"Testing accuracy = {:.2%}\".format(np.mean(test_acc)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Exporting Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Optimization option OPTIMIZE_FOR_SIZE is deprecated, please use optimizations=[Optimize.DEFAULT] instead.\n",
      "2022-04-09 18:45:35.561008: W tensorflow/python/util/util.cc:348] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n",
      "WARNING:absl:Found untraced functions such as conv1d_layer_call_and_return_conditional_losses, conv1d_layer_call_fn, conv1d_4_layer_call_and_return_conditional_losses, conv1d_4_layer_call_fn, conv1d_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/gq/h37vcf3132q7y2scnlvy177r0000gn/T/tmpqk7tggf2/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/gq/h37vcf3132q7y2scnlvy177r0000gn/T/tmpqk7tggf2/assets\n",
      "2022-04-09 18:45:38.183675: I tensorflow/core/grappler/devices.cc:75] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0 (Note: TensorFlow was not compiled with CUDA or ROCm support)\n",
      "2022-04-09 18:45:38.184085: I tensorflow/core/grappler/clusters/single_machine.cc:357] Starting new session\n",
      "2022-04-09 18:45:38.200030: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:1137] Optimization results for grappler item: graph_to_optimize\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.008ms.\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.003ms.\n",
      "\n",
      "WARNING:absl:Optimization option OPTIMIZE_FOR_SIZE is deprecated, please use optimizations=[Optimize.DEFAULT] instead.\n",
      "WARNING:absl:Optimization option OPTIMIZE_FOR_SIZE is deprecated, please use optimizations=[Optimize.DEFAULT] instead.\n",
      "2022-04-09 18:45:39.569059: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:351] Ignored output_format.\n",
      "2022-04-09 18:45:39.569079: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:354] Ignored drop_control_dependency.\n",
      "2022-04-09 18:45:39.616826: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:210] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2022-04-09 18:45:39.747574: I tensorflow/lite/tools/optimize/quantize_weights.cc:225] Skipping quantization of tensor pcnn/sequential_4/inception1d/conv1d/conv1d_1 because it has fewer than 1024 elements (16).\n",
      "2022-04-09 18:45:39.747597: I tensorflow/lite/tools/optimize/quantize_weights.cc:225] Skipping quantization of tensor pcnn/sequential_4/inception1d/sequential/conv1d_1/conv1d_1 because it has fewer than 1024 elements (16).\n",
      "2022-04-09 18:45:39.747604: I tensorflow/lite/tools/optimize/quantize_weights.cc:225] Skipping quantization of tensor pcnn/sequential_4/inception1d/sequential/conv1d_2/conv1d_1 because it has fewer than 1024 elements (768).\n",
      "2022-04-09 18:45:39.747609: I tensorflow/lite/tools/optimize/quantize_weights.cc:225] Skipping quantization of tensor pcnn/sequential_4/inception1d/sequential_1/conv1d_3/conv1d_1 because it has fewer than 1024 elements (16).\n",
      "2022-04-09 18:45:39.747615: I tensorflow/lite/tools/optimize/quantize_weights.cc:225] Skipping quantization of tensor pcnn/sequential_4/inception1d_1/conv1d_4/conv1d_1 because it has fewer than 1024 elements (768).\n",
      "2022-04-09 18:45:39.747620: I tensorflow/lite/tools/optimize/quantize_weights.cc:225] Skipping quantization of tensor pcnn/sequential_4/inception1d_1/sequential_2/conv1d_5/conv1d_1 because it has fewer than 1024 elements (768).\n",
      "2022-04-09 18:45:39.747625: I tensorflow/lite/tools/optimize/quantize_weights.cc:225] Skipping quantization of tensor pcnn/sequential_4/inception1d_1/sequential_2/conv1d_6/conv1d_1 because it has fewer than 1024 elements (768).\n",
      "2022-04-09 18:45:39.747630: I tensorflow/lite/tools/optimize/quantize_weights.cc:225] Skipping quantization of tensor pcnn/sequential_4/inception1d_1/sequential_3/conv1d_7/conv1d_1 because it has fewer than 1024 elements (768).\n",
      "2022-04-09 18:45:39.747645: I tensorflow/lite/tools/optimize/quantize_weights.cc:225] Skipping quantization of tensor pcnn/sequential_4/inception1d/conv1d/conv1d_1 because it has fewer than 1024 elements (16).\n",
      "2022-04-09 18:45:39.747651: I tensorflow/lite/tools/optimize/quantize_weights.cc:225] Skipping quantization of tensor pcnn/sequential_4/inception1d/sequential/conv1d_1/conv1d_1 because it has fewer than 1024 elements (16).\n",
      "2022-04-09 18:45:39.747656: I tensorflow/lite/tools/optimize/quantize_weights.cc:225] Skipping quantization of tensor pcnn/sequential_4/inception1d/sequential/conv1d_2/conv1d_1 because it has fewer than 1024 elements (768).\n",
      "2022-04-09 18:45:39.747661: I tensorflow/lite/tools/optimize/quantize_weights.cc:225] Skipping quantization of tensor pcnn/sequential_4/inception1d/sequential_1/conv1d_3/conv1d_1 because it has fewer than 1024 elements (16).\n",
      "2022-04-09 18:45:39.747666: I tensorflow/lite/tools/optimize/quantize_weights.cc:225] Skipping quantization of tensor pcnn/sequential_4/inception1d_1/conv1d_4/conv1d_1 because it has fewer than 1024 elements (768).\n",
      "2022-04-09 18:45:39.747670: I tensorflow/lite/tools/optimize/quantize_weights.cc:225] Skipping quantization of tensor pcnn/sequential_4/inception1d_1/sequential_2/conv1d_5/conv1d_1 because it has fewer than 1024 elements (768).\n",
      "2022-04-09 18:45:39.747675: I tensorflow/lite/tools/optimize/quantize_weights.cc:225] Skipping quantization of tensor pcnn/sequential_4/inception1d_1/sequential_2/conv1d_6/conv1d_1 because it has fewer than 1024 elements (768).\n",
      "2022-04-09 18:45:39.747680: I tensorflow/lite/tools/optimize/quantize_weights.cc:225] Skipping quantization of tensor pcnn/sequential_4/inception1d_1/sequential_3/conv1d_7/conv1d_1 because it has fewer than 1024 elements (768).\n",
      "2022-04-09 18:45:39.747687: I tensorflow/lite/tools/optimize/quantize_weights.cc:225] Skipping quantization of tensor pcnn/ann_classifier/dense_2/MatMul because it has fewer than 1024 elements (192).\n"
     ]
    }
   ],
   "source": [
    "from tinymlgen import port\n",
    "\n",
    "c_code = port(model, variable_name='model', pretty_print=True, optimize=True)\n",
    "with open('model.h', 'w') as f:\n",
    "    f.write(c_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as conv1d_layer_call_and_return_conditional_losses, conv1d_layer_call_fn, conv1d_4_layer_call_and_return_conditional_losses, conv1d_4_layer_call_fn, conv1d_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_tf/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_tf/assets\n"
     ]
    }
   ],
   "source": [
    "MODEL_TF = 'model_tf'\n",
    "MODEL_TFLITE = 'model_tflite'\n",
    "MODEL_TFLITE_MICRO = 'model_tflite_micro'\n",
    "\n",
    "model.save(MODEL_TF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-09 18:45:55.346014: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:351] Ignored output_format.\n",
      "2022-04-09 18:45:55.346031: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:354] Ignored drop_control_dependency.\n",
      "2022-04-09 18:45:55.346036: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:360] Ignored change_concat_input_ranges.\n",
      "2022-04-09 18:45:55.347040: I tensorflow/cc/saved_model/reader.cc:38] Reading SavedModel from: model_tf\n",
      "2022-04-09 18:45:55.361628: I tensorflow/cc/saved_model/reader.cc:90] Reading meta graph with tags { serve }\n",
      "2022-04-09 18:45:55.361649: I tensorflow/cc/saved_model/reader.cc:132] Reading SavedModel debug info (if present) from: model_tf\n",
      "2022-04-09 18:45:55.412915: I tensorflow/cc/saved_model/loader.cc:211] Restoring SavedModel bundle.\n",
      "2022-04-09 18:45:55.570156: I tensorflow/cc/saved_model/loader.cc:195] Running initialization op on SavedModel bundle at path: model_tf\n",
      "2022-04-09 18:45:55.611016: I tensorflow/cc/saved_model/loader.cc:283] SavedModel load for tags { serve }; Status: success: OK. Took 264247 microseconds.\n",
      "fully_quantize: 0, inference_type: 6, input_inference_type: 9, output_inference_type: 9\n"
     ]
    }
   ],
   "source": [
    "converter = tf.lite.TFLiteConverter.from_saved_model(MODEL_TF)\n",
    "\n",
    "# Quantization\n",
    "def representative_dataset_gen():\n",
    "    for sample in train_data:\n",
    "        yield [np.expand_dims(sample, axis=0).astype(np.float32)]\n",
    "\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
    "converter.inference_input_type = tf.int8\n",
    "converter.inference_output_type = tf.int8\n",
    "converter.representative_dataset = representative_dataset_gen\n",
    "\n",
    "model_tflite = converter.convert()\n",
    "with open(MODEL_TFLITE, \"wb\") as f:\n",
    "    f.write(model_tflite)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "!xxd -i {MODEL_TFLITE} > {MODEL_TFLITE_MICRO}\n",
    "\n",
    "REPLACE_TEXT = MODEL_TFLITE.replace('/', '_').replace('.', '_')\n",
    "!sed -i 's/'{REPLACE_TEXT}'/g_model/g' {MODEL_TFLITE_MICRO}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Rough Implementation",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
